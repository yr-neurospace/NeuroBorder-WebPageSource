[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mathematics",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nProbability and statistics with Julia\n\n\n\n\n\n\nprobability\n\n\nstatistics\n\n\njulia\n\n\n\n\n\n\n\n\n\nSep 22, 2024\n\n\nRui Yang\n\n\n\n\n\n\n\n\n\n\n\n\nProbability and statistics (misc)\n\n\n\n\n\n\nprobability\n\n\nstatistics\n\n\nmisc\n\n\n\n\n\n\n\n\n\nSep 22, 2024\n\n\nRui Yang\n\n\n\n\n\n\n\n\n\n\n\n\nStatistical inference concepts of binomial distribution\n\n\n\n\n\n\nstatistical inference\n\n\nbinomial distribution\n\n\n\n\n\n\n\n\n\nSep 21, 2024\n\n\nRui Yang\n\n\n\n\n\n\n\n\n\n\n\n\nLogistic function\n\n\n\n\n\n\nlogistic function\n\n\n\n\n\n\n\n\n\nSep 18, 2024\n\n\nRui Yang\n\n\n\n\n\n\n\n\n\n\n\n\nLorenz curve and Gini index\n\n\n\n\n\n\nlorenz curve\n\n\ngini index\n\n\n\n\n\n\n\n\n\nSep 15, 2024\n\n\nRui Yang\n\n\n\n\n\n\n\n\n\n\n\n\nBinomial distribution approximations\n\n\n\n\n\n\nbinomial distribution\n\n\napproximation\n\n\n\n\n\n\n\n\n\nSep 15, 2024\n\n\nRui Yang\n\n\n\n\n\n\n\n\n\n\n\n\nTrigonometric functions\n\n\n\n\n\n\ntrigonometric functions\n\n\n\n\n\n\n\n\n\nSep 15, 2024\n\n\nRui Yang\n\n\n\n\n\n\n\n\n\n\n\n\nP-P plot and Q-Q plot\n\n\n\n\n\n\np-p plot\n\n\nq-q plot\n\n\n\n\n\n\n\n\n\nSep 15, 2024\n\n\nRui Yang\n\n\n\n\n\n\n\n\n\n\n\n\nROC and AUC\n\n\n\n\n\n\nroc\n\n\nauc\n\n\n\n\n\n\n\n\n\nSep 15, 2024\n\n\nRui Yang\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Probability and Statistics/roc_and_auc/index.html",
    "href": "posts/Probability and Statistics/roc_and_auc/index.html",
    "title": "ROC and AUC",
    "section": "",
    "text": "A receiver operating characteristic curve (ROC curve) is a graphical plot that illustrates the performance of a binary classifier (two-class prediction) model at varying threshold values.\nThe ROC curve is the plot of the true positive rate (TPR) against the false positive rate (FPR) at each threshold seeting.\nROC analysis provides tools to select possibly optimal models and to discard suboptimal ones independently from the cost context or the class distribution. ROC analysis is related in a direct and natural way to the cost/benefit analysis of diagnostic decision making.\nA classification model (classifier or diagnosis) is a mapping of instances between certain classes/groups. Because the classifier or diagnosis result can be an arbitrary real value (continuous output), the classifier boundary between classes must be determined by a threshold value. Or it can be a discrete class label, indicating one of the classes.\nConsider an experiment from \\(\\mathbf{P}\\) positive instances and \\(\\mathbf{N}\\) negative instances for some condition. The four outcomes\n\nTrue positive (TP): the outcome from a prediction is positve and the actual value is positive.\nFlase positive (FP): the outcome from a prediction is positive but the actual value is negative.\nTrue negative (TN): the outcome from a prediction is negative and the actual value is negative.\nFalse negative (FN): the outcome from a prediction is negative but the actual value is positive.\n\ncan be formulated in a \\(2 \\times 2\\) contingency table or confusion matrix, as follows:\n\n\n\n\n\n\n\n\nTo draw a ROC curve, only TPR and FPR are needed (as functions of some classifier parameter).\nA ROC space is defined by FPR and TPR as \\(x\\) and \\(y\\) axes, respectively, which depicts relative trade-offs between true positive (benefits) and false positive (costs).\nThe best possible prediction method would yield a point in the upper left corner or coordinate \\((0, 1)\\) of the ROC space, representing \\(100\\%\\) sensitivity (no false negatives) and \\(100\\%\\) specificity (no false positives). The \\((0, 1)\\) point is also called a perfect classification. A random guess would give a point along a diagonal line (the so-called line of no-discrimination) from the bottom left to the top right corners.\nThe diagonal line divides the ROC space into two parts. Points above the diagonal line represent good clasification results (better than random); points below the line represent bad results (worse than random). Note that the output of a consistently bad predictor could simply be inverted to obtain a good predictor.\n\n\n\nIn binary classification, the class prediction for each instance is often made based on a continuous random variable \\(\\mathbf{X}\\), which is a “score” computed for the instance. Given a threshold \\(\\mathbf{T}\\), the instance is classified as “positive” if \\(\\mathbf{X} &gt; \\mathbf{T}\\), and “negative” otherwise. \\(\\mathbf{X}\\) follows a probability density \\(f_1(x)\\) if the instance actually belongs to class “positive”, and \\(f_0(x)\\) if otherwise.\nTherefore, the true positive rate is given by \\(\\mathbf{TPR(T)} = \\int_{T}^{\\infty} f_1(x) dx\\) and the false positive rate is given by \\(\\mathbf{FPR(T)} = \\int_{T}^{\\infty} f_0(x) dx\\).\nThe ROC curve plots parametrically \\(\\mathbf{TPR(T)}\\) versus \\(\\mathbf{FPR(T)}\\) with \\(\\mathbf{T}\\) as the varying parameter.\nIn the hypothesis testing perspective, we can consider the power as TPR (the probability of correctly rejecting \\(H_0\\)), and the type I error as FPR (the probability of wrongly rejecting \\(H_0\\)), then the ROC curve is the power as a function of the type I error:\n\nusing Random, Distributions, CairoMakie\n\nRandom.seed!(1234)\n\n# assume that under both H0 and H1\n# the random variable X is distributed as some normal distributions\nmu0, sigma0 = 10, 2\nmu1, sigma1 = 14, 1\n\ndist0 = Normal(mu0, sigma0)\ndist1 = Normal(mu1, sigma1)\n\nalphas = 0:0.01:1\npowers = @. ccdf(dist1, quantile(dist0, 1 - alphas))\n\nfig, ax = lines(alphas, powers; color=:red, label=\"ROC curve (power vs. alpha)\")\nvlines!(ax, [0.05]; color=:black, label=\"alpha = 0.05\")\naxislegend(ax; position=:rb)\nax.xlabel = \"Alpha\"\nax.ylabel = \"Power\"\nfig\n\n\n\n\nAs shown above, as the type I error grows up to \\(1\\), the power also increases up to \\(1\\). But we wish to reach a balance point where we have a larger power and an acceptable type I error rate (e.g. \\(0.05\\))."
  },
  {
    "objectID": "posts/Probability and Statistics/roc_and_auc/index.html#receiver-operating-characteristic-roc",
    "href": "posts/Probability and Statistics/roc_and_auc/index.html#receiver-operating-characteristic-roc",
    "title": "ROC and AUC",
    "section": "",
    "text": "A receiver operating characteristic curve (ROC curve) is a graphical plot that illustrates the performance of a binary classifier (two-class prediction) model at varying threshold values.\nThe ROC curve is the plot of the true positive rate (TPR) against the false positive rate (FPR) at each threshold seeting.\nROC analysis provides tools to select possibly optimal models and to discard suboptimal ones independently from the cost context or the class distribution. ROC analysis is related in a direct and natural way to the cost/benefit analysis of diagnostic decision making.\nA classification model (classifier or diagnosis) is a mapping of instances between certain classes/groups. Because the classifier or diagnosis result can be an arbitrary real value (continuous output), the classifier boundary between classes must be determined by a threshold value. Or it can be a discrete class label, indicating one of the classes.\nConsider an experiment from \\(\\mathbf{P}\\) positive instances and \\(\\mathbf{N}\\) negative instances for some condition. The four outcomes\n\nTrue positive (TP): the outcome from a prediction is positve and the actual value is positive.\nFlase positive (FP): the outcome from a prediction is positive but the actual value is negative.\nTrue negative (TN): the outcome from a prediction is negative and the actual value is negative.\nFalse negative (FN): the outcome from a prediction is negative but the actual value is positive.\n\ncan be formulated in a \\(2 \\times 2\\) contingency table or confusion matrix, as follows:\n\n\n\n\n\n\n\n\nTo draw a ROC curve, only TPR and FPR are needed (as functions of some classifier parameter).\nA ROC space is defined by FPR and TPR as \\(x\\) and \\(y\\) axes, respectively, which depicts relative trade-offs between true positive (benefits) and false positive (costs).\nThe best possible prediction method would yield a point in the upper left corner or coordinate \\((0, 1)\\) of the ROC space, representing \\(100\\%\\) sensitivity (no false negatives) and \\(100\\%\\) specificity (no false positives). The \\((0, 1)\\) point is also called a perfect classification. A random guess would give a point along a diagonal line (the so-called line of no-discrimination) from the bottom left to the top right corners.\nThe diagonal line divides the ROC space into two parts. Points above the diagonal line represent good clasification results (better than random); points below the line represent bad results (worse than random). Note that the output of a consistently bad predictor could simply be inverted to obtain a good predictor.\n\n\n\nIn binary classification, the class prediction for each instance is often made based on a continuous random variable \\(\\mathbf{X}\\), which is a “score” computed for the instance. Given a threshold \\(\\mathbf{T}\\), the instance is classified as “positive” if \\(\\mathbf{X} &gt; \\mathbf{T}\\), and “negative” otherwise. \\(\\mathbf{X}\\) follows a probability density \\(f_1(x)\\) if the instance actually belongs to class “positive”, and \\(f_0(x)\\) if otherwise.\nTherefore, the true positive rate is given by \\(\\mathbf{TPR(T)} = \\int_{T}^{\\infty} f_1(x) dx\\) and the false positive rate is given by \\(\\mathbf{FPR(T)} = \\int_{T}^{\\infty} f_0(x) dx\\).\nThe ROC curve plots parametrically \\(\\mathbf{TPR(T)}\\) versus \\(\\mathbf{FPR(T)}\\) with \\(\\mathbf{T}\\) as the varying parameter.\nIn the hypothesis testing perspective, we can consider the power as TPR (the probability of correctly rejecting \\(H_0\\)), and the type I error as FPR (the probability of wrongly rejecting \\(H_0\\)), then the ROC curve is the power as a function of the type I error:\n\nusing Random, Distributions, CairoMakie\n\nRandom.seed!(1234)\n\n# assume that under both H0 and H1\n# the random variable X is distributed as some normal distributions\nmu0, sigma0 = 10, 2\nmu1, sigma1 = 14, 1\n\ndist0 = Normal(mu0, sigma0)\ndist1 = Normal(mu1, sigma1)\n\nalphas = 0:0.01:1\npowers = @. ccdf(dist1, quantile(dist0, 1 - alphas))\n\nfig, ax = lines(alphas, powers; color=:red, label=\"ROC curve (power vs. alpha)\")\nvlines!(ax, [0.05]; color=:black, label=\"alpha = 0.05\")\naxislegend(ax; position=:rb)\nax.xlabel = \"Alpha\"\nax.ylabel = \"Power\"\nfig\n\n\n\n\nAs shown above, as the type I error grows up to \\(1\\), the power also increases up to \\(1\\). But we wish to reach a balance point where we have a larger power and an acceptable type I error rate (e.g. \\(0.05\\))."
  },
  {
    "objectID": "posts/Probability and Statistics/roc_and_auc/index.html#area-under-the-curve-auc",
    "href": "posts/Probability and Statistics/roc_and_auc/index.html#area-under-the-curve-auc",
    "title": "ROC and AUC",
    "section": "2 Area under the curve (AUC)",
    "text": "2 Area under the curve (AUC)\nIn addition to those evaluation metrics mentioned in the above table, another evaluation metric, called AUC (area under the ROC curve), defined as\n\\[\n\\begin{align}\nTPR(T)&: T \\to y(x) \\\\\nFPR(T)&: T \\to x \\\\\nA &= \\int_{x = 0}^{1} TPR(FPR^{-1}(x)) dx \\\\\n&= \\int_{\\infty}^{-\\infty} TPR(T) \\cdot FPR'(T) dT\n\\end{align}\n\\]\ncan be used to summarize sensitivity and specificity, but it does not inform regarding precision and negative predictive value.\nIn fact, AUC is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one (assuming “positive” ranks higher than “negative”). In other words, when given one randomly selected positive instance and one randomly selected negative instance, AUC is the probability that the classifier will be able to tell which one is which."
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_misc/index.html",
    "href": "posts/Probability and Statistics/probability_and_statistics_misc/index.html",
    "title": "Probability and statistics (misc)",
    "section": "",
    "text": "Probability is the branch of mathematics that deals with events whose individual outcomes are unpredictable, but whose outcomes on average are predictable.\nExperiments can be divided into two types:\n\nDeterministic: whose individual outcomes are predictable;\nNondeterministic (random): whose individual outcomes are unpredictable.\n\n\n\nNext, all experiments we’ll deal with are repeatable (it can be performed repeatedly any number of times) and random (any single performance of the experiment is unpredictable).\nIn this section, we’ll deal with experiments having a finite number of possible outcomes. We denote the number of possible outcomes by \\(n\\), and number them from \\(1\\) to \\(n\\).\n\n\nIn a random and repeatable experiment, if we denote \\(S_j\\) by the number of instances among the first \\(N\\) experiments where the \\(j\\)th outcome was observed to occur, then the frequency \\(\\frac{S_j}{N}\\) with which the \\(j\\)th outcome has been observed to occur tends to a limit as \\(N\\) tends to infinity. We call this limit the probability of the \\(j\\)th outcome and denote it by \\(p_j\\):\n\\[\np_j = \\lim\\limits_{N \\to \\infty} \\frac{S_j}{N}\n\\]\nThese probabilities have the following properties:\n\n\\(0 \\leq p_j \\leq 1\\);\n\n\n\n\n\n\n\nNote\n\n\n\nFor \\(\\frac{S_j}{N}\\) lies between \\(0\\) and \\(1\\), and therefore so does its limit \\(p_j\\).\n\n\n\n\\(\\sum_{j=1}^{n} p_j = 1\\).\n\n\n\n\n\n\n\nNote\n\n\n\nWe have\n\\[\nS_1 + S_2 + \\cdots + S_n = N\n\\]\nDividing by \\(N\\), we get\n\\[\n\\frac{S_1}{N} + \\frac{S_2}{N} + \\cdots + \\frac{S_n}{N} = 1\n\\]\nAs \\(N\\) tends to infinity, we have\n\\[\n\\lim\\limits_{N \\to \\infty} \\sum_{j=1}^{n} \\frac{S_j}{N} = \\lim\\limits_{N \\to \\infty} \\sum_{j=1}^{n} p_j = 1\n\\]\n\n\n\n\n\nIn fact very often, we are not interested in all the details of the outcome of an experiment, but merely in a particular aspect of it (e.g. throwing a die, we may be interested only in whether the outcome is even or odd).\nAn occurrence such as throwing an even number is called an event, which is defined as the following:\n\nAn event \\(E\\) is defined as any collection of possible outcomes.\n\nNote: we say that an event \\(E\\) occurred whenever any outcome belonging to \\(E\\) occurred.\nThe probability \\(p(E)\\) of an event \\(E\\) is\n\\[\np(E) = \\lim\\limits_{N \\to \\infty} \\frac{S(E)}{N}\n\\]\nwhere \\(S(E)\\) is the number of instances among the first \\(N\\) experiments when the event \\(E\\) took place.\n\n\n\n\n\n\nNote\n\n\n\nWe have\n\\[\nS(E) = \\sum_{j\\ \\text{in}\\ E} S_j\n\\]\nDividing by \\(N\\)\n\\[\n\\frac{S(E)}{N} = \\sum_{j\\ \\text{in}\\ E} \\frac{S_j}{N}\n\\]\nAs \\(N\\) tends to infinity, we have\n\\[\np(E) = \\sum_{j\\ \\text{in}\\ E} p_j\n\\]\n\n\n\n\n\nAddition rule for disjoint events\n\nTwo events \\(E_1\\) and \\(E_2\\) are called disjoint if both cannot take place simultaneously (i.e. \\(E_1 \\cap E_2 = \\emptyset\\)).\nThen we have\n\\[\np(E_1 \\cup E_2) = p(E_1) + p(E_2)\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\\[\np(E_1 \\cup E_2) = \\sum_{j\\ \\text{in}\\ E_1\\ \\text{or}\\ E_2} p_j\n\\]\nDisjointness means that an outcome \\(j\\) may belong either to \\(E_1\\) or to \\(E_2\\) but not to both; therefore,\n\\[\np(E_1 \\cup E_2) = \\sum_{j\\ \\text{in}\\ E_1\\ \\text{or}\\ E_2} p_j = \\sum_{j\\ \\text{in}\\ E_1} p_j + \\sum_{j\\ \\text{in}\\ E_2} p_j = p(E_1) + p(E_2)\n\\]\n\n\n\nProduct rule for independent events\n\nTwo events \\(E\\) and \\(F\\) are called independent if the outcome of one cannot influence the other, nor is the outcome of both under the influence of a common cause.\nThen we have\n\\[\np(E \\cap F) = p(E)p(F)\n\\]\n\n\n\n\n\n\nNote\n\n\n\nAmong the first \\(N\\) experiments, count the number of times \\(E\\) has occurred (\\(S(E)\\)), F has occurred (\\(S(F)\\)), and \\(E \\cap F\\) has occurred (\\(S(E \\cap F)\\)). Then we have\n\\[\np(E) = \\lim\\limits_{N \\to \\infty} \\frac{S(E)}{N}\n\\]\n\\[\np(F) = \\lim\\limits_{N \\to \\infty} \\frac{S(F)}{N}\n\\]\n\\[\np(E \\cap F) = \\lim\\limits_{N \\to \\infty} \\frac{S(E \\cap F)}{N}\n\\]\nSuppose that we single out from the sequence of combined experiments the subsequence of those where \\(E\\) occurred. The frequency of occurrence of \\(F\\) in this subsequence is \\(\\frac{S(E \\cap F)}{S(E)}\\). If the two events \\(E\\) and \\(F\\) are truly independent, the frequency with which \\(F\\) occurs in this subsequence should be the same as the frequency with which \\(F\\) occurs in the original sequence, i.e.\n\\[\n\\lim\\limits_{N \\to \\infty} \\frac{S(E \\cap F)}{S(E)} = \\lim\\limits_{N \\to \\infty} \\frac{S(F)}{N} = p(F)\n\\]\nWe write the frequency of \\(\\frac{S(E \\cap F)}{N}\\) as the product\n\\[\n\\frac{S(E \\cap F)}{N} = \\frac{S(E \\cap F)}{S(E)}\\frac{S(E)}{N}\n\\]\nThen we have\n\\[\np(E \\cap F) = \\lim\\limits_{N \\to \\infty} \\frac{S(E \\cap F)}{N} = \\lim\\limits_{N \\to \\infty} \\frac{S(E \\cap F)}{S(E)} \\cdot \\lim\\limits_{N \\to \\infty} \\frac{S(E)}{N} = p(F)p(E)\n\\]\n\n\n\n\n\n\n\nNumerical outcome\n\nThe numerical outcome of an experiment means the assignment of a real number \\(x_j\\) to each of the possible outcomes.\nNote that different outcomes may be assigned the same number so we have to re-calculate the probability \\(p(x_j)\\) for each \\(x_j\\) with which \\(x_j\\) occurred.\n\nExpectation\n\nIn a random experiment with \\(n\\) possible outcomes of probability \\(p_j\\) and numerical outcome \\(x_j\\), the average numerical outcome, called the mean of \\(x\\) or expectation of \\(x\\), denoted by \\(\\bar{x}\\) or \\(E(x)\\), is given by the formula\n\\[\n\\bar{x} = E(x) = p_1x_1 + p_2x_2 + \\cdots + p_nx_n\n\\]\n\n\n\n\n\n\nNote\n\n\n\nAmong the first \\(N\\) experiments, denote by \\(S_j\\) the number of instances with which the \\(j\\)th outcome was observed. Then, the average numerical outcome is\n\\[\n\\frac{S_1x_1 + S_2x_2 + \\cdots + S_nx_n}{N}\n\\]\nAs \\(N \\to \\infty\\), we have\n\\[\n\\bar{x} = E(x) = \\lim\\limits_{N \\to \\infty} \\frac{S_1x_1 + S_2x_2 + \\cdots + S_nx_n}{N} = p_1x_1 + p_2x_2 + \\cdots + p_nx_n\n\\]\n\n\n\nVariance\n\nNext we are tempted to know such a fact: by how much do the numerical outcomes differ on average from the mean?\nThis is characterized by the variance, the expectation of the square of the difference of the numerical outcome and its mean:\n\\[\nV = \\overline{(x - \\bar{x})^2} = E((x - \\bar{x})^2)\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\\[\n\\begin{aligned}\nV & = \\overline{(x - \\bar{x})^2} \\\\\n  & = E((x - \\bar{x})^2) \\\\\n  & = \\sum_{j=1}^{n} p_j (x_j - \\bar{x})^2 \\\\\n  & = p_1x_1^2 + \\cdots + p_nx_n^2 - 2(p_1x_1 + \\cdots + p_nx_n)\\bar{x} + (\\bar{x})^2 \\\\\n  & = \\bar{x^2} - (\\bar{x})^2 \\\\\n  & = E(x^2) - (E(x))^2\n\\end{aligned}\n\\]\n\n\nNote: the square root of the variance \\(\\sqrt{V}\\) is called the standard deviation.\n\n\n\n\nThe binomial distribution\n\nSuppose a random experiment has two possible outcomes \\(A\\) and \\(B\\), with probabilities \\(p\\) and \\(q\\) respectively, where \\(p + q = 1\\).\nSuppose we repeat the experiment \\(N\\) times, and the repeated experiments are independent of each other.\nIf we let \\(k\\) (\\(k = 0, 1, ..., N\\)) denote the number of times with which A occurs, then the probability that A occurs exactly \\(k\\) times is given by the formula\n\\[\nb_k(N) = \\dbinom{N}{k} p^k q^{N-k}\n\\]\n\n\n\n\n\n\nNote\n\n\n\nSince the outcomes of the experiments are independent of each other, the probability of a particular sequence of \\(k\\) \\(A\\)’s and \\(N - k\\) \\(B\\)’s is \\(p^k q^{N-k}\\).\nIn addition, there are exactly \\(\\dbinom{N}{k}\\) arrangements of \\(k\\) \\(A\\)’s and \\(N - k\\) \\(B\\)’s, which are disjoint of each other.\n\n\nIn addition, we have\n\\[\nE(x) = \\sum_{k=0}^{N} kp(x = k) = Np\n\\]\nNote: the binomial theorem is \\((a + b)^N = \\sum_{k=0}^{N} \\dbinom{N}{k} a^k b^{N-k}\\).\n\nThe Poisson distribution\n\nSuppose each week there are a large number of vehicles through a busy intersection and there are on average \\(\\mu\\) accidents.\nSuppose the probability of a vehicle having an accident is independent of the occurrence of previous accidents.\nThen we use a binomial distribution to determine the probability of \\(k\\) accidents in a week:\nSetting \\(p = \\frac{\\mu}{N}\\), then we have\n\\[\n\\begin{aligned}\nb_k(N) & = \\dbinom{N}{k} p^k q^{N-k} \\\\\n       & = \\frac{N(N-1) \\cdots (N-k+1)}{k!} p^k q^{N-k} \\\\\n       & = (1-\\frac{1}{N}) \\cdots (1-\\frac{k-1}{N}) \\frac{N^kp^k(1-p)^{N-k}}{k!} \\\\\n       & = \\frac{(1-\\frac{1}{N}) \\cdots (1-\\frac{k-1}{N})}{(1-p)^k} \\frac{\\mu^k}{k!} (1-\\frac{\\mu}{N})^N\n\\end{aligned}\n\\]\nSince \\(e^{-x} = \\lim\\limits_{n \\to \\infty} (1-\\frac{x}{n})^n\\) (\\(e^x = \\lim\\limits_{n \\to \\infty} (1+\\frac{x}{n})^n\\)), then we have\n\\[\n\\lim\\limits_{N \\to \\infty,\\ \\mu = Np} b_k(N) = \\frac{\\mu^k}{k!} e^{-\\mu}\n\\]\nThis gives us an estimate for \\(b_k(N)\\) when \\(N\\) is large, \\(p\\) is small, and \\(Np = \\mu\\).\nThe Poisson distribution is defined as\n\\[\np_k(\\mu) = \\frac{\\mu^k}{k!} e^{-\\mu}\n\\]\nwhere \\(\\mu\\) is a parameter. \\(p_k\\) is the probability of \\(k\\) favorable outcomes, \\(k = 0, 1, ...\\).\nIn addition, the combination of two Poisson processes is again a Poisson process.\nDenote by \\(p_k(\\mu)\\) and \\(p_k(\\nu)\\) the probability of \\(k\\) favorable outcomes in these two processes. We claim that the probability of \\(k\\) favorable outcomes when both experiments are performed is \\(p_k(\\mu + \\nu)\\).\n\n\n\n\n\n\nNote\n\n\n\nThere will be \\(k\\) favorable outcomes for the combined experiment if the first experiment has \\(j\\) (\\(j = 0, 1, ..., k\\)) favorable outcomes and the second experiment has \\(k - j\\).\nIf the experiments are independent, the probability of such a combined outcome is the product of the probabilities \\(p_j(\\mu) p_{k-j}(\\nu)\\).\nSo the probability of the combined experiment to have \\(k\\) favorable outcomes is the sum\n\\[\n\\begin{aligned}\n\\sum_j p_j(\\mu) p_{k-j}(\\nu) & = \\sum_j \\frac{\\mu^j}{j!} e^{-\\mu} \\frac{\\nu^{k-j}}{(k-j)!} e^{-\\nu} \\\\\n                             & = \\frac{1}{k!} e^{-(\\mu + \\nu)} \\sum_j \\frac{k!}{j!(k-j)!} \\mu^j \\nu^{(k-j)} \\\\\n                             & = \\frac{(\\mu + \\nu)^k}{k!} e^{-(\\mu + \\nu)}\n\\end{aligned}\n\\]\nwhich is the Poisson distribution \\(p_k(\\mu + \\nu)\\).\n\n\n\n\n\n\nSuppose we have such an experiment making a physical measurement with an apparatus subject to random disturbances that can be reduced but not totally eliminated. Then every real number is a possible numerical outcome of such an experiment.\nRepeat the experiment as many times as we wish and denote by \\(S(x)\\) the number of instances among the first \\(N\\) performances for which the numerical outcome was less than \\(x\\).Then the frequency \\(\\frac{S(x)}{N}\\) with which this event occurs tends to a limit as \\(N\\) tends to infinity. This limit is the probability that the outcome is less than \\(\\mathbfcal{x}\\), and is denoted by \\(P(x)\\):\n\\[\nP(x) = \\lim\\limits_{N \\to \\infty} \\frac{S(x)}{N}\n\\]\nThe probability \\(P(x)\\) has the following properties:\n\n\\(0 \\leq P(x) \\leq 1\\): \\(0 \\leq S(x) \\leq N \\implies 0 \\leq \\frac{S(x)}{N} \\leq 1 \\implies 0 \\leq P(x) \\leq 1\\).\n\\(P(x)\\) is a nondecreasing function of \\(x\\): \\(S(x)\\) is a nondecreasing function of \\(x\\), so that \\(\\frac{S(x)}{N}\\) is a nondecreasing function of \\(x\\); then so is the limit \\(P(x)\\).\n\\(P(x) \\to 0\\ (x \\to -\\infty)\\).\n\\(P(x) \\to 1\\ (x \\to \\infty)\\).\n\\(P(x)\\) is a continuously differentiable function (denote the derivative of \\(P\\) by \\(p\\)): \\(\\frac{\\mathrm{d}P(x)}{dx} = p(x)\\).\n\nThe function \\(p(x)\\) is called the probability density function.\n\n\n\n\n\n\nAddition rule for disjoint events\n\n\n\nSuppose \\(E\\) and \\(F\\) are two events with probabilities \\(P(E)\\) and \\(P(F)\\) respectively.\nSuppose they are disjoint (i.e. \\(E \\cap F = \\emptyset\\)).\nThen we have\n\\[\nP(E \\cup F) = P(E) + P(F)\n\\]\nLet \\(E: x &lt; a\\), \\(F: a \\leq x &lt; b\\), then we have \\(E \\cup F: x &lt; b\\).\nThen we have\n\\[\nP(E) = P(a),\\ P(E \\cup F) = P(b)\n\\]\nWe conclude that\n\\[\nP(F) = P(b) - P(a)\n\\]\nis the probability of \\(a \\leq x &lt; b\\).\n\n\nAccording to the mean value theorem, for every \\(a\\) and \\(b\\), there is a number \\(c\\) lying between \\(a\\) and \\(b\\) such that\n\\[\nP(b) - P(a) = p(c)(b - a)\n\\]\nAccording to the fundamental theorem of calculus\n\\[\nP(b) - P(a) = \\int_a^b p(x)\\mathrm{d}x\n\\]\nAccording to \\(P(a) \\to 0\\ (a \\to -\\infty)\\)\n\\[\nP(b) = \\int_{-\\infty}^b p(x)\\mathrm{d}x\n\\]\nAccording to \\(P(b) \\to 1\\ (b \\to \\infty)\\)\n\\[\n1 = \\int_{-\\infty}^{\\infty} p(x)\\mathrm{d}x\n\\]\nThis is the continuous analogue of the basic fact that \\(p_1 + p_2 + \\cdots + p_n = 1\\) in discrete probability.\n\n\\(p(x) \\geq 0\\): \\(P(x)\\) is a nondecreasing function of \\(x\\).\nThe expectation is:\n\n\\[\n\\bar{x} = \\int_{-\\infty}^{\\infty} xp(x)\\mathrm{d}x\n\\]\n\n\n\n\n\n\nNote\n\n\n\nImagine the experiment performed as many times as we wish, and denote the sequence of outcomes by\n\\[\na_1, a_2, ..., a_N, ...\n\\]\nDivide the interval \\(I\\) in which all outcomes lie into \\(n\\) subintervals \\(I_1, ..., I_n\\). Denote the endpoints by\n\\[\ne_0 &lt; e_1 &lt; \\cdots &lt; e_n\n\\]\nThe probability of \\(e_{j-1} \\leq x &lt; e_j\\) (i.e. \\(x\\) lies in the interval \\(I_j\\)) is\n\\[\nP_j = P(e_j) - P(e_{j-1}) = p(x_j)(e_j - e_{j-1})\n\\]\nwhere \\(x_j\\) is a point in \\(I_j\\) guaranteed by the mean value theorem, and \\(e_j - e_{j-1}\\) denotes the length of \\(I_j\\).\nWe now simplify the original experiment by recording merely the intervals \\(I_j\\) in which the outcome falls, and calling the numerical outcome in this case \\(x_j\\), the point in \\(I_j\\) appears in the above formula; therefore, the actual outcome falling into \\(I_j\\) differs from \\(x_j\\) by at most \\(e_j - e_{j-1}\\).\nNow consider the sequence of outcomes \\(a_1, a_2, ...\\) of the original experiment. Denote the corresponding outcomes of the simplified experiment by \\(b_1, b_2, ...\\). The simplified experiment has a finite number of outcomes. For such discrete experiments, we have the expectation\n\\[\n\\bar{x}_n = \\lim\\limits_{N \\to \\infty} \\frac{b_1 + \\cdots + b_N}{N}\n\\]\nwhere \\(n\\) is the number of subintervals of \\(I\\).\nIn fact, the expectation \\(\\bar{x}_n\\) of the simplified experiment can also be calculated by formula\n\\[\n\\bar{x}_n = P_1x_1 + \\cdots + P_nx_n\n\\]\nThen we have\n\\[\n\\bar{x}_n = p(x_1)x_1(e_1 - e_0) + \\cdots + p(x_n)x_n(e_n - e_{n-1})\n\\]\nAs \\(n \\to \\infty\\), we have\n\\[\n\\bar{x} = \\lim\\limits_{n \\to \\infty} \\sum_{i=1}^n x_ip(x_i)\\Delta x_i = \\int_{e_0}^{e_n} xp(x)\\mathrm{d}x\n\\]\nSo we conclude\n\\[\n\\bar{x} = \\int_{-\\infty}^{\\infty} xp(x)\\mathrm{d}x\n\\]\n\n\n\nThe probability density of a combined experiment of two experiments independent of each other:\n\n\nCase 1: the outcome of the first experiment may be any real number, but the second experiment can have only a finite number of outcomes.\n\nDenote by \\(P(a)\\) the probability of \\(x &lt; a\\). The second experiment has \\(n\\) possible outcomes \\(a_1, ..., a_n\\) with probabilities \\(Q_1, ..., Q_n\\).\nWe define the numerical outcome of the combined experiment to be the sum of the separate numerical outcomes of the two experiments that constitute it.\nWe denote by \\(E(x)\\) the event that the numerical outcome of the combined experiment is less than \\(x\\), and denote its probability by \\(U(x)\\).\nThen we have\n\\[\nU(x) = Q_1P(x-a_1) + \\cdots + Q_nP(x-a_n)\n\\]\n\n\n\n\n\n\nNote\n\n\n\nWe denote by \\(E_j(x)\\) the event that the numerical outcome of the second experiment is \\(a_j\\). The numerical outcome of the combined experiment is then less than \\(x\\) if and only if the numerical outcome of the first experiment is less than \\(x - a_j\\).\nThen we have\n\\[\nE(x) = E_1(x) \\cup \\cdots \\cup E_n(x)\n\\]\nwhere the events \\(E_j(x)\\) are disjoint.\nIt follows from the addition rule for disjoint events that\n\\[\nU(x) = P(E_1(x)) + \\cdots + P(E_n(x))\n\\]\nSince the two experiments are independent, we have \\(P(E_j(x)) = Q_j P(x-a_j)\\).\nSo we have\n\\[\nU(x) = Q_1P(x-a_1) + \\cdots + Q_nP(x-a_n)\n\\]\n\n\n\nCase 2: both experiments can have any real number as outcome.\n\nDenote by \\(P(a)\\) and \\(Q(a)\\) the probabilities that the outcome is less than \\(a\\) in each of the two experiments, respectively.\nAssume the outcome of the second experiment always lies in some finite interval \\(I\\). Then we subdivide \\(I\\) into a finite number \\(n\\) of subintervals \\(I_j = [e_{j-1}, e_j)\\). Let \\(Q_j\\) denote the probability of the outcome of the experiment lying in \\(I_j\\).\nSuppose \\(Q(x)\\) is continuously differentiable and denote its derivative by \\(q(x)\\).\nAccording to the mean value theorem, we have\n\\[\nQ_j = Q(e_j) - Q(e_{j-1}) = q(a_j)(e_j - e_{j-1})\n\\]\nwhere \\(a_j\\) is some point in \\(I_j\\).\nWe discretize the second experiment by lumping together all outcomes that lie in \\(I_j\\) and redefine the numerical outcome in that case to be \\(a_j\\).\nThen we have\n\\[\n\\begin{aligned}\nU_n(x) & = q(a_1)P(x-a_1)(e_1-e_0) + \\cdots + q(a_n)P(x-a_n)(e_n-e_{n-1}) \\\\\n       & = \\sum_{i=1}^{n} q(a_i)p(x-a_i)\\Delta a_i\n\\end{aligned}\n\\]\nAs \\(n \\to \\infty\\), we have\n\\[\n\\begin{aligned}\nU(x) & = \\lim\\limits_{n \\to \\infty} U_n(x) \\\\\n     & = \\lim\\limits_{n \\to \\infty} \\sum_{i=1}^{n} q(a_i)p(x-a_i)\\Delta a_i \\\\\n     & = \\int\\limits_{I} q(a)P(x-a)\\mathrm{d}a\n\\end{aligned}\n\\]\nThen we have\n\\[\nU(x) = \\int_{-\\infty}^{\\infty} q(a)P(x-a)\\mathrm{d}a\n\\]\nFurther, let us suppose \\(P(x)\\) is continuously differentiable, and denote its derivative by \\(p(x)\\).\nThen we have\n\\[\nu(x) = \\int_{-\\infty}^{\\infty} q(a)p(x-a)\\mathrm{d}a\n\\]\nwhere \\(u(x)\\) is the derivative of \\(U(x)\\).\nIn a word, we have proved the following fact:\n\n\n\n\n\n\nNote\n\n\n\nConsider two independent experiments whose outcomes lie in some finite interval and have probability \\(p\\) and \\(q\\) respectively.\nIn the combined experiment of the two experiments, define the outcome of the combined experiment to be the sum of the outcomes of the individual experiments.\nThen the combined experiment has the probability density:\n\\[\nu(x) = \\int_{-\\infty}^{\\infty} q(a)p(x-a)\\mathrm{d}a\n\\]\n\n\n\nThe convolution of the functions \\(q\\) and \\(p\\):\n\nThe function \\(u\\) defined by \\(u(x) = \\int_{-\\infty}^{\\infty} q(a)p(x-a)\\mathrm{d}a\\) is called the convolution of the functions \\(q\\) and \\(p\\). This relation is denoted by \\(u = q*p\\).\nThe convolution has the following properties:\n\n\n\n\n\n\nNote\n\n\n\nLet \\(q_1\\), \\(q_2\\), and \\(p\\) be continuous functions defined for all real numbers \\(x\\), and assume the functions are \\(0\\) outside a finite interval. Then we have\n\nConvolution is distributive: \\((q_1+q_2)*p = q_1*p + q_2*p\\).\nLet \\(k\\) be any constant. Then \\((kq)*p = k(q*p)\\).\nConvolution is commutative: \\(q*p = p*q\\).\nThe integral of the convolution is the product of the integrals of the factors:\n\n\\[\n\\int_{-\\infty}^{\\infty} u(x) \\mathrm{d}x = \\int_{-\\infty}^{\\infty} p(x) \\mathrm{d}x \\int_{-\\infty}^{\\infty} q(a) \\mathrm{d}a\n\\]"
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_misc/index.html#from-the-book-calculus-with-applications-by-peter-d.-lax",
    "href": "posts/Probability and Statistics/probability_and_statistics_misc/index.html#from-the-book-calculus-with-applications-by-peter-d.-lax",
    "title": "Probability and statistics (misc)",
    "section": "",
    "text": "Probability is the branch of mathematics that deals with events whose individual outcomes are unpredictable, but whose outcomes on average are predictable.\nExperiments can be divided into two types:\n\nDeterministic: whose individual outcomes are predictable;\nNondeterministic (random): whose individual outcomes are unpredictable.\n\n\n\nNext, all experiments we’ll deal with are repeatable (it can be performed repeatedly any number of times) and random (any single performance of the experiment is unpredictable).\nIn this section, we’ll deal with experiments having a finite number of possible outcomes. We denote the number of possible outcomes by \\(n\\), and number them from \\(1\\) to \\(n\\).\n\n\nIn a random and repeatable experiment, if we denote \\(S_j\\) by the number of instances among the first \\(N\\) experiments where the \\(j\\)th outcome was observed to occur, then the frequency \\(\\frac{S_j}{N}\\) with which the \\(j\\)th outcome has been observed to occur tends to a limit as \\(N\\) tends to infinity. We call this limit the probability of the \\(j\\)th outcome and denote it by \\(p_j\\):\n\\[\np_j = \\lim\\limits_{N \\to \\infty} \\frac{S_j}{N}\n\\]\nThese probabilities have the following properties:\n\n\\(0 \\leq p_j \\leq 1\\);\n\n\n\n\n\n\n\nNote\n\n\n\nFor \\(\\frac{S_j}{N}\\) lies between \\(0\\) and \\(1\\), and therefore so does its limit \\(p_j\\).\n\n\n\n\\(\\sum_{j=1}^{n} p_j = 1\\).\n\n\n\n\n\n\n\nNote\n\n\n\nWe have\n\\[\nS_1 + S_2 + \\cdots + S_n = N\n\\]\nDividing by \\(N\\), we get\n\\[\n\\frac{S_1}{N} + \\frac{S_2}{N} + \\cdots + \\frac{S_n}{N} = 1\n\\]\nAs \\(N\\) tends to infinity, we have\n\\[\n\\lim\\limits_{N \\to \\infty} \\sum_{j=1}^{n} \\frac{S_j}{N} = \\lim\\limits_{N \\to \\infty} \\sum_{j=1}^{n} p_j = 1\n\\]\n\n\n\n\n\nIn fact very often, we are not interested in all the details of the outcome of an experiment, but merely in a particular aspect of it (e.g. throwing a die, we may be interested only in whether the outcome is even or odd).\nAn occurrence such as throwing an even number is called an event, which is defined as the following:\n\nAn event \\(E\\) is defined as any collection of possible outcomes.\n\nNote: we say that an event \\(E\\) occurred whenever any outcome belonging to \\(E\\) occurred.\nThe probability \\(p(E)\\) of an event \\(E\\) is\n\\[\np(E) = \\lim\\limits_{N \\to \\infty} \\frac{S(E)}{N}\n\\]\nwhere \\(S(E)\\) is the number of instances among the first \\(N\\) experiments when the event \\(E\\) took place.\n\n\n\n\n\n\nNote\n\n\n\nWe have\n\\[\nS(E) = \\sum_{j\\ \\text{in}\\ E} S_j\n\\]\nDividing by \\(N\\)\n\\[\n\\frac{S(E)}{N} = \\sum_{j\\ \\text{in}\\ E} \\frac{S_j}{N}\n\\]\nAs \\(N\\) tends to infinity, we have\n\\[\np(E) = \\sum_{j\\ \\text{in}\\ E} p_j\n\\]\n\n\n\n\n\nAddition rule for disjoint events\n\nTwo events \\(E_1\\) and \\(E_2\\) are called disjoint if both cannot take place simultaneously (i.e. \\(E_1 \\cap E_2 = \\emptyset\\)).\nThen we have\n\\[\np(E_1 \\cup E_2) = p(E_1) + p(E_2)\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\\[\np(E_1 \\cup E_2) = \\sum_{j\\ \\text{in}\\ E_1\\ \\text{or}\\ E_2} p_j\n\\]\nDisjointness means that an outcome \\(j\\) may belong either to \\(E_1\\) or to \\(E_2\\) but not to both; therefore,\n\\[\np(E_1 \\cup E_2) = \\sum_{j\\ \\text{in}\\ E_1\\ \\text{or}\\ E_2} p_j = \\sum_{j\\ \\text{in}\\ E_1} p_j + \\sum_{j\\ \\text{in}\\ E_2} p_j = p(E_1) + p(E_2)\n\\]\n\n\n\nProduct rule for independent events\n\nTwo events \\(E\\) and \\(F\\) are called independent if the outcome of one cannot influence the other, nor is the outcome of both under the influence of a common cause.\nThen we have\n\\[\np(E \\cap F) = p(E)p(F)\n\\]\n\n\n\n\n\n\nNote\n\n\n\nAmong the first \\(N\\) experiments, count the number of times \\(E\\) has occurred (\\(S(E)\\)), F has occurred (\\(S(F)\\)), and \\(E \\cap F\\) has occurred (\\(S(E \\cap F)\\)). Then we have\n\\[\np(E) = \\lim\\limits_{N \\to \\infty} \\frac{S(E)}{N}\n\\]\n\\[\np(F) = \\lim\\limits_{N \\to \\infty} \\frac{S(F)}{N}\n\\]\n\\[\np(E \\cap F) = \\lim\\limits_{N \\to \\infty} \\frac{S(E \\cap F)}{N}\n\\]\nSuppose that we single out from the sequence of combined experiments the subsequence of those where \\(E\\) occurred. The frequency of occurrence of \\(F\\) in this subsequence is \\(\\frac{S(E \\cap F)}{S(E)}\\). If the two events \\(E\\) and \\(F\\) are truly independent, the frequency with which \\(F\\) occurs in this subsequence should be the same as the frequency with which \\(F\\) occurs in the original sequence, i.e.\n\\[\n\\lim\\limits_{N \\to \\infty} \\frac{S(E \\cap F)}{S(E)} = \\lim\\limits_{N \\to \\infty} \\frac{S(F)}{N} = p(F)\n\\]\nWe write the frequency of \\(\\frac{S(E \\cap F)}{N}\\) as the product\n\\[\n\\frac{S(E \\cap F)}{N} = \\frac{S(E \\cap F)}{S(E)}\\frac{S(E)}{N}\n\\]\nThen we have\n\\[\np(E \\cap F) = \\lim\\limits_{N \\to \\infty} \\frac{S(E \\cap F)}{N} = \\lim\\limits_{N \\to \\infty} \\frac{S(E \\cap F)}{S(E)} \\cdot \\lim\\limits_{N \\to \\infty} \\frac{S(E)}{N} = p(F)p(E)\n\\]\n\n\n\n\n\n\n\nNumerical outcome\n\nThe numerical outcome of an experiment means the assignment of a real number \\(x_j\\) to each of the possible outcomes.\nNote that different outcomes may be assigned the same number so we have to re-calculate the probability \\(p(x_j)\\) for each \\(x_j\\) with which \\(x_j\\) occurred.\n\nExpectation\n\nIn a random experiment with \\(n\\) possible outcomes of probability \\(p_j\\) and numerical outcome \\(x_j\\), the average numerical outcome, called the mean of \\(x\\) or expectation of \\(x\\), denoted by \\(\\bar{x}\\) or \\(E(x)\\), is given by the formula\n\\[\n\\bar{x} = E(x) = p_1x_1 + p_2x_2 + \\cdots + p_nx_n\n\\]\n\n\n\n\n\n\nNote\n\n\n\nAmong the first \\(N\\) experiments, denote by \\(S_j\\) the number of instances with which the \\(j\\)th outcome was observed. Then, the average numerical outcome is\n\\[\n\\frac{S_1x_1 + S_2x_2 + \\cdots + S_nx_n}{N}\n\\]\nAs \\(N \\to \\infty\\), we have\n\\[\n\\bar{x} = E(x) = \\lim\\limits_{N \\to \\infty} \\frac{S_1x_1 + S_2x_2 + \\cdots + S_nx_n}{N} = p_1x_1 + p_2x_2 + \\cdots + p_nx_n\n\\]\n\n\n\nVariance\n\nNext we are tempted to know such a fact: by how much do the numerical outcomes differ on average from the mean?\nThis is characterized by the variance, the expectation of the square of the difference of the numerical outcome and its mean:\n\\[\nV = \\overline{(x - \\bar{x})^2} = E((x - \\bar{x})^2)\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\\[\n\\begin{aligned}\nV & = \\overline{(x - \\bar{x})^2} \\\\\n  & = E((x - \\bar{x})^2) \\\\\n  & = \\sum_{j=1}^{n} p_j (x_j - \\bar{x})^2 \\\\\n  & = p_1x_1^2 + \\cdots + p_nx_n^2 - 2(p_1x_1 + \\cdots + p_nx_n)\\bar{x} + (\\bar{x})^2 \\\\\n  & = \\bar{x^2} - (\\bar{x})^2 \\\\\n  & = E(x^2) - (E(x))^2\n\\end{aligned}\n\\]\n\n\nNote: the square root of the variance \\(\\sqrt{V}\\) is called the standard deviation.\n\n\n\n\nThe binomial distribution\n\nSuppose a random experiment has two possible outcomes \\(A\\) and \\(B\\), with probabilities \\(p\\) and \\(q\\) respectively, where \\(p + q = 1\\).\nSuppose we repeat the experiment \\(N\\) times, and the repeated experiments are independent of each other.\nIf we let \\(k\\) (\\(k = 0, 1, ..., N\\)) denote the number of times with which A occurs, then the probability that A occurs exactly \\(k\\) times is given by the formula\n\\[\nb_k(N) = \\dbinom{N}{k} p^k q^{N-k}\n\\]\n\n\n\n\n\n\nNote\n\n\n\nSince the outcomes of the experiments are independent of each other, the probability of a particular sequence of \\(k\\) \\(A\\)’s and \\(N - k\\) \\(B\\)’s is \\(p^k q^{N-k}\\).\nIn addition, there are exactly \\(\\dbinom{N}{k}\\) arrangements of \\(k\\) \\(A\\)’s and \\(N - k\\) \\(B\\)’s, which are disjoint of each other.\n\n\nIn addition, we have\n\\[\nE(x) = \\sum_{k=0}^{N} kp(x = k) = Np\n\\]\nNote: the binomial theorem is \\((a + b)^N = \\sum_{k=0}^{N} \\dbinom{N}{k} a^k b^{N-k}\\).\n\nThe Poisson distribution\n\nSuppose each week there are a large number of vehicles through a busy intersection and there are on average \\(\\mu\\) accidents.\nSuppose the probability of a vehicle having an accident is independent of the occurrence of previous accidents.\nThen we use a binomial distribution to determine the probability of \\(k\\) accidents in a week:\nSetting \\(p = \\frac{\\mu}{N}\\), then we have\n\\[\n\\begin{aligned}\nb_k(N) & = \\dbinom{N}{k} p^k q^{N-k} \\\\\n       & = \\frac{N(N-1) \\cdots (N-k+1)}{k!} p^k q^{N-k} \\\\\n       & = (1-\\frac{1}{N}) \\cdots (1-\\frac{k-1}{N}) \\frac{N^kp^k(1-p)^{N-k}}{k!} \\\\\n       & = \\frac{(1-\\frac{1}{N}) \\cdots (1-\\frac{k-1}{N})}{(1-p)^k} \\frac{\\mu^k}{k!} (1-\\frac{\\mu}{N})^N\n\\end{aligned}\n\\]\nSince \\(e^{-x} = \\lim\\limits_{n \\to \\infty} (1-\\frac{x}{n})^n\\) (\\(e^x = \\lim\\limits_{n \\to \\infty} (1+\\frac{x}{n})^n\\)), then we have\n\\[\n\\lim\\limits_{N \\to \\infty,\\ \\mu = Np} b_k(N) = \\frac{\\mu^k}{k!} e^{-\\mu}\n\\]\nThis gives us an estimate for \\(b_k(N)\\) when \\(N\\) is large, \\(p\\) is small, and \\(Np = \\mu\\).\nThe Poisson distribution is defined as\n\\[\np_k(\\mu) = \\frac{\\mu^k}{k!} e^{-\\mu}\n\\]\nwhere \\(\\mu\\) is a parameter. \\(p_k\\) is the probability of \\(k\\) favorable outcomes, \\(k = 0, 1, ...\\).\nIn addition, the combination of two Poisson processes is again a Poisson process.\nDenote by \\(p_k(\\mu)\\) and \\(p_k(\\nu)\\) the probability of \\(k\\) favorable outcomes in these two processes. We claim that the probability of \\(k\\) favorable outcomes when both experiments are performed is \\(p_k(\\mu + \\nu)\\).\n\n\n\n\n\n\nNote\n\n\n\nThere will be \\(k\\) favorable outcomes for the combined experiment if the first experiment has \\(j\\) (\\(j = 0, 1, ..., k\\)) favorable outcomes and the second experiment has \\(k - j\\).\nIf the experiments are independent, the probability of such a combined outcome is the product of the probabilities \\(p_j(\\mu) p_{k-j}(\\nu)\\).\nSo the probability of the combined experiment to have \\(k\\) favorable outcomes is the sum\n\\[\n\\begin{aligned}\n\\sum_j p_j(\\mu) p_{k-j}(\\nu) & = \\sum_j \\frac{\\mu^j}{j!} e^{-\\mu} \\frac{\\nu^{k-j}}{(k-j)!} e^{-\\nu} \\\\\n                             & = \\frac{1}{k!} e^{-(\\mu + \\nu)} \\sum_j \\frac{k!}{j!(k-j)!} \\mu^j \\nu^{(k-j)} \\\\\n                             & = \\frac{(\\mu + \\nu)^k}{k!} e^{-(\\mu + \\nu)}\n\\end{aligned}\n\\]\nwhich is the Poisson distribution \\(p_k(\\mu + \\nu)\\).\n\n\n\n\n\n\nSuppose we have such an experiment making a physical measurement with an apparatus subject to random disturbances that can be reduced but not totally eliminated. Then every real number is a possible numerical outcome of such an experiment.\nRepeat the experiment as many times as we wish and denote by \\(S(x)\\) the number of instances among the first \\(N\\) performances for which the numerical outcome was less than \\(x\\).Then the frequency \\(\\frac{S(x)}{N}\\) with which this event occurs tends to a limit as \\(N\\) tends to infinity. This limit is the probability that the outcome is less than \\(\\mathbfcal{x}\\), and is denoted by \\(P(x)\\):\n\\[\nP(x) = \\lim\\limits_{N \\to \\infty} \\frac{S(x)}{N}\n\\]\nThe probability \\(P(x)\\) has the following properties:\n\n\\(0 \\leq P(x) \\leq 1\\): \\(0 \\leq S(x) \\leq N \\implies 0 \\leq \\frac{S(x)}{N} \\leq 1 \\implies 0 \\leq P(x) \\leq 1\\).\n\\(P(x)\\) is a nondecreasing function of \\(x\\): \\(S(x)\\) is a nondecreasing function of \\(x\\), so that \\(\\frac{S(x)}{N}\\) is a nondecreasing function of \\(x\\); then so is the limit \\(P(x)\\).\n\\(P(x) \\to 0\\ (x \\to -\\infty)\\).\n\\(P(x) \\to 1\\ (x \\to \\infty)\\).\n\\(P(x)\\) is a continuously differentiable function (denote the derivative of \\(P\\) by \\(p\\)): \\(\\frac{\\mathrm{d}P(x)}{dx} = p(x)\\).\n\nThe function \\(p(x)\\) is called the probability density function.\n\n\n\n\n\n\nAddition rule for disjoint events\n\n\n\nSuppose \\(E\\) and \\(F\\) are two events with probabilities \\(P(E)\\) and \\(P(F)\\) respectively.\nSuppose they are disjoint (i.e. \\(E \\cap F = \\emptyset\\)).\nThen we have\n\\[\nP(E \\cup F) = P(E) + P(F)\n\\]\nLet \\(E: x &lt; a\\), \\(F: a \\leq x &lt; b\\), then we have \\(E \\cup F: x &lt; b\\).\nThen we have\n\\[\nP(E) = P(a),\\ P(E \\cup F) = P(b)\n\\]\nWe conclude that\n\\[\nP(F) = P(b) - P(a)\n\\]\nis the probability of \\(a \\leq x &lt; b\\).\n\n\nAccording to the mean value theorem, for every \\(a\\) and \\(b\\), there is a number \\(c\\) lying between \\(a\\) and \\(b\\) such that\n\\[\nP(b) - P(a) = p(c)(b - a)\n\\]\nAccording to the fundamental theorem of calculus\n\\[\nP(b) - P(a) = \\int_a^b p(x)\\mathrm{d}x\n\\]\nAccording to \\(P(a) \\to 0\\ (a \\to -\\infty)\\)\n\\[\nP(b) = \\int_{-\\infty}^b p(x)\\mathrm{d}x\n\\]\nAccording to \\(P(b) \\to 1\\ (b \\to \\infty)\\)\n\\[\n1 = \\int_{-\\infty}^{\\infty} p(x)\\mathrm{d}x\n\\]\nThis is the continuous analogue of the basic fact that \\(p_1 + p_2 + \\cdots + p_n = 1\\) in discrete probability.\n\n\\(p(x) \\geq 0\\): \\(P(x)\\) is a nondecreasing function of \\(x\\).\nThe expectation is:\n\n\\[\n\\bar{x} = \\int_{-\\infty}^{\\infty} xp(x)\\mathrm{d}x\n\\]\n\n\n\n\n\n\nNote\n\n\n\nImagine the experiment performed as many times as we wish, and denote the sequence of outcomes by\n\\[\na_1, a_2, ..., a_N, ...\n\\]\nDivide the interval \\(I\\) in which all outcomes lie into \\(n\\) subintervals \\(I_1, ..., I_n\\). Denote the endpoints by\n\\[\ne_0 &lt; e_1 &lt; \\cdots &lt; e_n\n\\]\nThe probability of \\(e_{j-1} \\leq x &lt; e_j\\) (i.e. \\(x\\) lies in the interval \\(I_j\\)) is\n\\[\nP_j = P(e_j) - P(e_{j-1}) = p(x_j)(e_j - e_{j-1})\n\\]\nwhere \\(x_j\\) is a point in \\(I_j\\) guaranteed by the mean value theorem, and \\(e_j - e_{j-1}\\) denotes the length of \\(I_j\\).\nWe now simplify the original experiment by recording merely the intervals \\(I_j\\) in which the outcome falls, and calling the numerical outcome in this case \\(x_j\\), the point in \\(I_j\\) appears in the above formula; therefore, the actual outcome falling into \\(I_j\\) differs from \\(x_j\\) by at most \\(e_j - e_{j-1}\\).\nNow consider the sequence of outcomes \\(a_1, a_2, ...\\) of the original experiment. Denote the corresponding outcomes of the simplified experiment by \\(b_1, b_2, ...\\). The simplified experiment has a finite number of outcomes. For such discrete experiments, we have the expectation\n\\[\n\\bar{x}_n = \\lim\\limits_{N \\to \\infty} \\frac{b_1 + \\cdots + b_N}{N}\n\\]\nwhere \\(n\\) is the number of subintervals of \\(I\\).\nIn fact, the expectation \\(\\bar{x}_n\\) of the simplified experiment can also be calculated by formula\n\\[\n\\bar{x}_n = P_1x_1 + \\cdots + P_nx_n\n\\]\nThen we have\n\\[\n\\bar{x}_n = p(x_1)x_1(e_1 - e_0) + \\cdots + p(x_n)x_n(e_n - e_{n-1})\n\\]\nAs \\(n \\to \\infty\\), we have\n\\[\n\\bar{x} = \\lim\\limits_{n \\to \\infty} \\sum_{i=1}^n x_ip(x_i)\\Delta x_i = \\int_{e_0}^{e_n} xp(x)\\mathrm{d}x\n\\]\nSo we conclude\n\\[\n\\bar{x} = \\int_{-\\infty}^{\\infty} xp(x)\\mathrm{d}x\n\\]\n\n\n\nThe probability density of a combined experiment of two experiments independent of each other:\n\n\nCase 1: the outcome of the first experiment may be any real number, but the second experiment can have only a finite number of outcomes.\n\nDenote by \\(P(a)\\) the probability of \\(x &lt; a\\). The second experiment has \\(n\\) possible outcomes \\(a_1, ..., a_n\\) with probabilities \\(Q_1, ..., Q_n\\).\nWe define the numerical outcome of the combined experiment to be the sum of the separate numerical outcomes of the two experiments that constitute it.\nWe denote by \\(E(x)\\) the event that the numerical outcome of the combined experiment is less than \\(x\\), and denote its probability by \\(U(x)\\).\nThen we have\n\\[\nU(x) = Q_1P(x-a_1) + \\cdots + Q_nP(x-a_n)\n\\]\n\n\n\n\n\n\nNote\n\n\n\nWe denote by \\(E_j(x)\\) the event that the numerical outcome of the second experiment is \\(a_j\\). The numerical outcome of the combined experiment is then less than \\(x\\) if and only if the numerical outcome of the first experiment is less than \\(x - a_j\\).\nThen we have\n\\[\nE(x) = E_1(x) \\cup \\cdots \\cup E_n(x)\n\\]\nwhere the events \\(E_j(x)\\) are disjoint.\nIt follows from the addition rule for disjoint events that\n\\[\nU(x) = P(E_1(x)) + \\cdots + P(E_n(x))\n\\]\nSince the two experiments are independent, we have \\(P(E_j(x)) = Q_j P(x-a_j)\\).\nSo we have\n\\[\nU(x) = Q_1P(x-a_1) + \\cdots + Q_nP(x-a_n)\n\\]\n\n\n\nCase 2: both experiments can have any real number as outcome.\n\nDenote by \\(P(a)\\) and \\(Q(a)\\) the probabilities that the outcome is less than \\(a\\) in each of the two experiments, respectively.\nAssume the outcome of the second experiment always lies in some finite interval \\(I\\). Then we subdivide \\(I\\) into a finite number \\(n\\) of subintervals \\(I_j = [e_{j-1}, e_j)\\). Let \\(Q_j\\) denote the probability of the outcome of the experiment lying in \\(I_j\\).\nSuppose \\(Q(x)\\) is continuously differentiable and denote its derivative by \\(q(x)\\).\nAccording to the mean value theorem, we have\n\\[\nQ_j = Q(e_j) - Q(e_{j-1}) = q(a_j)(e_j - e_{j-1})\n\\]\nwhere \\(a_j\\) is some point in \\(I_j\\).\nWe discretize the second experiment by lumping together all outcomes that lie in \\(I_j\\) and redefine the numerical outcome in that case to be \\(a_j\\).\nThen we have\n\\[\n\\begin{aligned}\nU_n(x) & = q(a_1)P(x-a_1)(e_1-e_0) + \\cdots + q(a_n)P(x-a_n)(e_n-e_{n-1}) \\\\\n       & = \\sum_{i=1}^{n} q(a_i)p(x-a_i)\\Delta a_i\n\\end{aligned}\n\\]\nAs \\(n \\to \\infty\\), we have\n\\[\n\\begin{aligned}\nU(x) & = \\lim\\limits_{n \\to \\infty} U_n(x) \\\\\n     & = \\lim\\limits_{n \\to \\infty} \\sum_{i=1}^{n} q(a_i)p(x-a_i)\\Delta a_i \\\\\n     & = \\int\\limits_{I} q(a)P(x-a)\\mathrm{d}a\n\\end{aligned}\n\\]\nThen we have\n\\[\nU(x) = \\int_{-\\infty}^{\\infty} q(a)P(x-a)\\mathrm{d}a\n\\]\nFurther, let us suppose \\(P(x)\\) is continuously differentiable, and denote its derivative by \\(p(x)\\).\nThen we have\n\\[\nu(x) = \\int_{-\\infty}^{\\infty} q(a)p(x-a)\\mathrm{d}a\n\\]\nwhere \\(u(x)\\) is the derivative of \\(U(x)\\).\nIn a word, we have proved the following fact:\n\n\n\n\n\n\nNote\n\n\n\nConsider two independent experiments whose outcomes lie in some finite interval and have probability \\(p\\) and \\(q\\) respectively.\nIn the combined experiment of the two experiments, define the outcome of the combined experiment to be the sum of the outcomes of the individual experiments.\nThen the combined experiment has the probability density:\n\\[\nu(x) = \\int_{-\\infty}^{\\infty} q(a)p(x-a)\\mathrm{d}a\n\\]\n\n\n\nThe convolution of the functions \\(q\\) and \\(p\\):\n\nThe function \\(u\\) defined by \\(u(x) = \\int_{-\\infty}^{\\infty} q(a)p(x-a)\\mathrm{d}a\\) is called the convolution of the functions \\(q\\) and \\(p\\). This relation is denoted by \\(u = q*p\\).\nThe convolution has the following properties:\n\n\n\n\n\n\nNote\n\n\n\nLet \\(q_1\\), \\(q_2\\), and \\(p\\) be continuous functions defined for all real numbers \\(x\\), and assume the functions are \\(0\\) outside a finite interval. Then we have\n\nConvolution is distributive: \\((q_1+q_2)*p = q_1*p + q_2*p\\).\nLet \\(k\\) be any constant. Then \\((kq)*p = k(q*p)\\).\nConvolution is commutative: \\(q*p = p*q\\).\nThe integral of the convolution is the product of the integrals of the factors:\n\n\\[\n\\int_{-\\infty}^{\\infty} u(x) \\mathrm{d}x = \\int_{-\\infty}^{\\infty} p(x) \\mathrm{d}x \\int_{-\\infty}^{\\infty} q(a) \\mathrm{d}a\n\\]"
  },
  {
    "objectID": "posts/Probability and Statistics/statistical_inference_concepts_of_binomial_distribution/index.html",
    "href": "posts/Probability and Statistics/statistical_inference_concepts_of_binomial_distribution/index.html",
    "title": "Statistical inference concepts of binomial distribution",
    "section": "",
    "text": "In an experiment, there are only two outcomes: success \\(A\\) (\\(X = 1\\)) and failure \\(\\overline{A}\\) (\\(X = 0\\)), and the probability of success is \\(p\\). Such an experiment is called a Bernoulli experiment.\nIn a Bernoulli experiment, the number of success, denoted by \\(X\\), is a random variable and its distribution is called a Bernoulli distribution or a two-point distribution.\nClearly, the PMF of a Bernoulli distribution is\n\\[\np(x) = P(X = x) = \\begin{cases}\np &\\text{if } x = 1 \\\\\n1 - p &\\text{if } x = 0\n\\end{cases}\n\\]\nThen \\(E(X) = \\sum_{i=1}^{\\infty} x_i p(x_i) = 1 \\times p + 0 \\times (1 - p) = p\\), and \\(Var(X) = E[(X - E(X))^2] = \\sum_{i=1}^{\\infty} (x_i - E(X))^2 p(x_i) = (1 - p)^2 \\times p + (0 - p)^2 \\times (1 - p) = p(1 - p)\\)."
  },
  {
    "objectID": "posts/Probability and Statistics/statistical_inference_concepts_of_binomial_distribution/index.html#bernoulli-distribution",
    "href": "posts/Probability and Statistics/statistical_inference_concepts_of_binomial_distribution/index.html#bernoulli-distribution",
    "title": "Statistical inference concepts of binomial distribution",
    "section": "",
    "text": "In an experiment, there are only two outcomes: success \\(A\\) (\\(X = 1\\)) and failure \\(\\overline{A}\\) (\\(X = 0\\)), and the probability of success is \\(p\\). Such an experiment is called a Bernoulli experiment.\nIn a Bernoulli experiment, the number of success, denoted by \\(X\\), is a random variable and its distribution is called a Bernoulli distribution or a two-point distribution.\nClearly, the PMF of a Bernoulli distribution is\n\\[\np(x) = P(X = x) = \\begin{cases}\np &\\text{if } x = 1 \\\\\n1 - p &\\text{if } x = 0\n\\end{cases}\n\\]\nThen \\(E(X) = \\sum_{i=1}^{\\infty} x_i p(x_i) = 1 \\times p + 0 \\times (1 - p) = p\\), and \\(Var(X) = E[(X - E(X))^2] = \\sum_{i=1}^{\\infty} (x_i - E(X))^2 p(x_i) = (1 - p)^2 \\times p + (0 - p)^2 \\times (1 - p) = p(1 - p)\\)."
  },
  {
    "objectID": "posts/Probability and Statistics/statistical_inference_concepts_of_binomial_distribution/index.html#binomial-distribution",
    "href": "posts/Probability and Statistics/statistical_inference_concepts_of_binomial_distribution/index.html#binomial-distribution",
    "title": "Statistical inference concepts of binomial distribution",
    "section": "2 Binomial distribution",
    "text": "2 Binomial distribution\nIn \\(n\\) independent Bernoulli trials, each with the probability of success \\(p\\), the number of success \\(Y\\) is distributed as a binomial distribution.\nThe PMF of a binomial distribution is\n\\[\np(k) = P(Y = k) = \\binom{n}{k} p^k (1-p)^{n - k}, k = 0, 1, ..., n\n\\]\nClearly, a binomial distribution can be regarded as the sum of \\(n\\) independent Bernoulli distributions, i.e., \\(Y = X_1 + \\cdots + X_n\\). Then, by using the arithmetic properties of expectation and variance, we have \\(E(Y) = np\\) and \\(Var(Y) = np(1 - p)\\).\nDue to \\(Y\\) is the sum of \\(n\\) independent Bernoulli random variables, we have \\(Y\\ \\ \\widetilde{\\text{approx}}\\ \\ N(np, np(1 - p))\\) as \\(n \\to \\infty\\) based on the central limit theorem. We also have \\(\\frac{Y}{n}\\ \\ \\widetilde{\\text{approx}}\\ \\ N(p, \\frac{p(1 - p)}{n})\\)."
  },
  {
    "objectID": "posts/Probability and Statistics/statistical_inference_concepts_of_binomial_distribution/index.html#introduction",
    "href": "posts/Probability and Statistics/statistical_inference_concepts_of_binomial_distribution/index.html#introduction",
    "title": "Statistical inference concepts of binomial distribution",
    "section": "3 Introduction",
    "text": "3 Introduction\nAssume that we repeat a Bernoulli trial \\(n\\) times, each of which has the same success probability \\(p\\), and that the number of successes is \\(n_s\\). Then, the random variable (denoted by \\(X_i\\), with value \\(1\\) (success) or \\(0\\) (failure)) in the \\(i\\)th Bernoulli trial is distributed as a Bernoulli distribution with the probability of success \\(p\\). According to the central limit theorem, the random variable \\(Y_n = \\sum_{i=1}^{n} X_i\\) distributed as a Binomial distribution with parameters \\(n\\) and \\(p\\) can be approximately distributed as a normal distribution (i.e. \\(Y_n \\sim N(np, np(1-p))\\)). And similarly, we have \\(\\hat{p} = \\frac{Y_n}{n} \\sim N(p, \\frac{p(1-p)}{n})\\)."
  },
  {
    "objectID": "posts/Probability and Statistics/statistical_inference_concepts_of_binomial_distribution/index.html#point-estimates-of-p",
    "href": "posts/Probability and Statistics/statistical_inference_concepts_of_binomial_distribution/index.html#point-estimates-of-p",
    "title": "Statistical inference concepts of binomial distribution",
    "section": "4 Point estimates of \\(p\\)",
    "text": "4 Point estimates of \\(p\\)\n\n4.1 Method of Moments (MM)\n\\[\n\\begin{align}\n\\hat{m} &= \\frac{1}{n} \\sum_{i=1}^{n} X_i = \\frac{k}{n} \\\\\nm &= p \\\\\n\\hat{m} &= m\n\\end{align}\n\\]\nHence\n\\[\np = \\frac{k}{n}\n\\]\n\n\n4.2 Maximum likelihood estimate (MLE)\nFor given \\(n\\) and \\(k\\), we need to find a \\(p\\) to maximize the likelihood function (to make the likelihood of observing \\(k\\) successes among \\(n\\) experiments in total maximized):\n\\[\n\\begin{align}\nL(p) &= \\binom{n}{k} p^k (1 - p)^{n - k} \\\\\n\\log{L(p)} &= \\log{\\binom{n}{k} + k\\log{p} + (n - k)\\log{(1 - p)}} \\\\\n\\frac{d\\log{L(p)}}{dp} &= \\frac{k}{p} - \\frac{n - k}{1 - p} = 0 \\\\\np &= \\frac{k}{n}\n\\end{align}\n\\]\nThere is a point \\(p = \\frac{k}{n}\\) that maximizes \\(L(p)\\)."
  },
  {
    "objectID": "posts/Probability and Statistics/statistical_inference_concepts_of_binomial_distribution/index.html#confidence-intervals-of-p",
    "href": "posts/Probability and Statistics/statistical_inference_concepts_of_binomial_distribution/index.html#confidence-intervals-of-p",
    "title": "Statistical inference concepts of binomial distribution",
    "section": "5 Confidence intervals of \\(p\\)",
    "text": "5 Confidence intervals of \\(p\\)\n\n  It appears you don't have a PDF plugin for this browser. No biggie. You can click here to download the PDF file.\n\nWe can use the standard logistic curve to check the overshoot and zero-width of the normal confidence interval:\n\nusing CairoMakie, Statistics, Distributions\n\n# the standard logistic curve can be regareded as a CDF\n# for each p-value, given specific n, we can calculate its normal confidence interval\n# we can easily see that there is a overshoot or zero-width situation\n# when p → 0 or 1\nfunction standard_logistic(x)\n    1 / (1 + exp(-x))\nend\n\nxGrid = -10:0.1:10\npVals = standard_logistic.(xGrid)\n\nalpha = 0.05\nz = quantile(Normal(), 1 - alpha / 2)\n\nns = [10, 100]\ncolors = [:blue, :green]\n\nfig, ax = lines(xGrid, pVals; color=:red, label=\"Standard logistic (true p-value)\")\nfor i in 1:length(ns)\n    pValLowerCIs = similar(pVals)\n    pValUpperCIs = similar(pVals)\n\n    @. pValLowerCIs = pVals - z * sqrt(pVals * (1 - pVals) / ns[i])\n    @. pValUpperCIs = pVals + z * sqrt(pVals * (1 - pVals) / ns[i])\n\n    lines!(ax, xGrid, pValLowerCIs; color=colors[i], linestyle=:dash, label=string(\"CI (n: \", ns[i], \")\"))\n    lines!(ax, xGrid, pValUpperCIs; color=colors[i], linestyle=:dash)\nend\naxislegend(ax; position=:rb)\nfig"
  },
  {
    "objectID": "posts/Probability and Statistics/binomial_distribution_approximatrions/index.html",
    "href": "posts/Probability and Statistics/binomial_distribution_approximatrions/index.html",
    "title": "Binomial distribution approximations",
    "section": "",
    "text": "It appears you don't have a PDF plugin for this browser. No biggie. You can click here to download the PDF file."
  },
  {
    "objectID": "posts/Probability and Statistics/binomial_distribution_approximatrions/index.html#introduction",
    "href": "posts/Probability and Statistics/binomial_distribution_approximatrions/index.html#introduction",
    "title": "Binomial distribution approximations",
    "section": "",
    "text": "It appears you don't have a PDF plugin for this browser. No biggie. You can click here to download the PDF file."
  },
  {
    "objectID": "posts/Probability and Statistics/binomial_distribution_approximatrions/index.html#normal-approximation",
    "href": "posts/Probability and Statistics/binomial_distribution_approximatrions/index.html#normal-approximation",
    "title": "Binomial distribution approximations",
    "section": "2 Normal approximation",
    "text": "2 Normal approximation\n\nusing Random, Distributions, CairoMakie\n\nRandom.seed!(1234)\n\n# the probability of success\nps = [0.1, 0.3, 0.5, 0.9]\n# the number of experiments\nns = [10, 100, 1000]\nlayouts = [[1, 1], [1, 2], [2, 1], [2, 2]]\ncolors = [:blue, :green, :red]\nnormalDist = Normal(0, 1)\nN = 10^6\n\nfig = Figure(size=(1400, 1200))\nfor i in 1:length(ps)\n    p = ps[i]\n    ax = Axis(fig[layouts[i][1], layouts[i][2]])\n    totalBins = []\n    for j in 1:length(ns)\n        n = ns[j]\n        binomialDist = Binomial(n, p)\n        samples = rand(binomialDist, N)\n        # normal standardization\n        normSamples = @. (samples - n * p) / sqrt(n * p * (1 - p))\n        bins = sort(unique(normSamples))\n        stephist!(ax, normSamples; color=colors[j], normalization=:pdf, bins=bins, label=string(\"n = \", n))\n        totalBins = vcat(totalBins, bins)\n    end\n    xGrid = round(minimum(totalBins), RoundDown; digits=0):0.01:round(maximum(totalBins), RoundUp; digits=0)\n    lines!(ax, xGrid, pdf.(normalDist, xGrid); color=:black, label=\"N(0, 1)\")\n    axislegend(ax)\n    ax.xlabel = string(\"x\\n(p = \", p, \")\")\n    ax.ylabel = \"Density\"\nend\nfig"
  },
  {
    "objectID": "posts/Probability and Statistics/binomial_distribution_approximatrions/index.html#poisson-approximation",
    "href": "posts/Probability and Statistics/binomial_distribution_approximatrions/index.html#poisson-approximation",
    "title": "Binomial distribution approximations",
    "section": "3 Poisson approximation",
    "text": "3 Poisson approximation\n\nusing Random, Distributions, CairoMakie\n\nRandom.seed!(1234)\n\nlambda = 5\nns = [10, 20, 200]\nN = 10^6\ncolors = [:red, :blue, :green]\n\nfig = Figure()\nax = Axis(fig[1, 1]; xlabel=\"x\", ylabel=\"Density\")\npoissonDist = Poisson(lambda)\nsamples = rand(poissonDist, N)\nbins = sort(unique(samples))\nstephist!(ax, samples; linewidth=3, linestyle=:dot, normalization=:pdf, bins=bins, color=:black, label=\"λ = $(lambda)\")\nfor i in 1:length(ns)\n    p = lambda / ns[i]\n    binomialDist = Binomial(ns[i], p)\n    samples = rand(binomialDist, N)\n    bins = sort(unique(samples))\n    stephist!(ax, samples; normalization=:pdf, bins=bins, color=colors[i], label=\"n = $(ns[i]), p = $(p)\")\nend\naxislegend(ax)\nfig"
  },
  {
    "objectID": "posts/Probability and Statistics/lorenz_curve_and_gini_index/index.html",
    "href": "posts/Probability and Statistics/lorenz_curve_and_gini_index/index.html",
    "title": "Lorenz curve and Gini index",
    "section": "",
    "text": "In economics, the Lorenz curve is a graphical representation of the distribution of income or of wealth.\nThe curve is a graph showing the proportion of overall income or wealth assumed by the bottom \\(\\mathbf{x\\%}\\) of the people. It is often used to represent income distribution, where it shows for the bottom \\(x\\%\\) of households, what percentage \\(y\\%\\) of the total income they have.\n\n\n\n\n\n\n\nA typical Lorenz curve\n\n\nA perfectly equal income distribution would be in which everyone has the same income. In this case, the bottom \\(N\\%\\) of society would always have \\(N\\%\\) of the income. This can be depicted by the straight line \\(y = x\\), called the “line of perfect equality”.\nBy contrast, a perfectly unequal distribution would be one in which one person has all the income and everyone else has none. In that case, the curve would be at \\(y = 0\\%\\) for all \\(x &lt; 100\\%\\), and \\(y = 100\\%\\) when \\(x = 100\\%\\). This curve is called the “line of perfect inequality”.\n\n\n\nThe Lorenz curve can usually be represented by a function \\(L(F)\\), where \\(F\\), the cumulative portion of the population, is represented by the horizontal axis, and \\(L\\), the cumulative portion of the total wealth or income, is represented by the vertical axis.\nThe curve \\(L\\) need not be a smoothly increasing function of \\(F\\). For wealth distributions there may be oligarchies or people with negative wealth for instance.\n\nDiscrete distribution\n\nFor a discrete distribution of \\(Y\\) given by values \\(y_1, ..., y_n\\) in non-decresing order (\\(y_i \\le y_{i+1}\\)) and their probabilities \\(f(y_i) := Pr(Y = y_i)\\), the Lorenz curve is a continuous piecewise linear function connecting the points \\((F_i, L_i)\\) for \\(i=1\\) to \\(n\\), where \\(F_0 = 0, L_0 = 0\\).\n\\[\n\\begin{align}\nF_i &:= \\sum_{j=1}^{i} f(y_j) \\\\\nS_i &:= \\sum_{j=1}^{i} y_i f(y_i) \\\\\nS &:= \\sum_{i=1}^{n} y_i f(y_i) \\\\\nL_i &:= \\frac{S_i}{S}\n\\end{align}\n\\]\n\nContinuous distribution\n\nFor a continuous distribution with the PDF \\(f\\) and the CDF \\(F\\), the Lorenz curve \\(L\\) is given by\n\\[\nL(F(x)) = \\frac{\\int_{-\\infty}^{x} t f(t) dt}{\\int_{-\\infty}^\\infty t f(t) dt} = \\frac{\\int_{-\\infty}^{x} t f(t) dt}{\\mu}\n\\]\nwhere \\(\\mu\\) denotes the average.\nThe Lorenz curve \\(L(F)\\) may then be plotted as a function parametric in \\(x\\): \\(L(x) \\text{ vs. } F(x)\\)."
  },
  {
    "objectID": "posts/Probability and Statistics/lorenz_curve_and_gini_index/index.html#lorenz-curve",
    "href": "posts/Probability and Statistics/lorenz_curve_and_gini_index/index.html#lorenz-curve",
    "title": "Lorenz curve and Gini index",
    "section": "",
    "text": "In economics, the Lorenz curve is a graphical representation of the distribution of income or of wealth.\nThe curve is a graph showing the proportion of overall income or wealth assumed by the bottom \\(\\mathbf{x\\%}\\) of the people. It is often used to represent income distribution, where it shows for the bottom \\(x\\%\\) of households, what percentage \\(y\\%\\) of the total income they have.\n\n\n\n\n\n\n\nA typical Lorenz curve\n\n\nA perfectly equal income distribution would be in which everyone has the same income. In this case, the bottom \\(N\\%\\) of society would always have \\(N\\%\\) of the income. This can be depicted by the straight line \\(y = x\\), called the “line of perfect equality”.\nBy contrast, a perfectly unequal distribution would be one in which one person has all the income and everyone else has none. In that case, the curve would be at \\(y = 0\\%\\) for all \\(x &lt; 100\\%\\), and \\(y = 100\\%\\) when \\(x = 100\\%\\). This curve is called the “line of perfect inequality”.\n\n\n\nThe Lorenz curve can usually be represented by a function \\(L(F)\\), where \\(F\\), the cumulative portion of the population, is represented by the horizontal axis, and \\(L\\), the cumulative portion of the total wealth or income, is represented by the vertical axis.\nThe curve \\(L\\) need not be a smoothly increasing function of \\(F\\). For wealth distributions there may be oligarchies or people with negative wealth for instance.\n\nDiscrete distribution\n\nFor a discrete distribution of \\(Y\\) given by values \\(y_1, ..., y_n\\) in non-decresing order (\\(y_i \\le y_{i+1}\\)) and their probabilities \\(f(y_i) := Pr(Y = y_i)\\), the Lorenz curve is a continuous piecewise linear function connecting the points \\((F_i, L_i)\\) for \\(i=1\\) to \\(n\\), where \\(F_0 = 0, L_0 = 0\\).\n\\[\n\\begin{align}\nF_i &:= \\sum_{j=1}^{i} f(y_j) \\\\\nS_i &:= \\sum_{j=1}^{i} y_i f(y_i) \\\\\nS &:= \\sum_{i=1}^{n} y_i f(y_i) \\\\\nL_i &:= \\frac{S_i}{S}\n\\end{align}\n\\]\n\nContinuous distribution\n\nFor a continuous distribution with the PDF \\(f\\) and the CDF \\(F\\), the Lorenz curve \\(L\\) is given by\n\\[\nL(F(x)) = \\frac{\\int_{-\\infty}^{x} t f(t) dt}{\\int_{-\\infty}^\\infty t f(t) dt} = \\frac{\\int_{-\\infty}^{x} t f(t) dt}{\\mu}\n\\]\nwhere \\(\\mu\\) denotes the average.\nThe Lorenz curve \\(L(F)\\) may then be plotted as a function parametric in \\(x\\): \\(L(x) \\text{ vs. } F(x)\\)."
  },
  {
    "objectID": "posts/Probability and Statistics/lorenz_curve_and_gini_index/index.html#gini-index",
    "href": "posts/Probability and Statistics/lorenz_curve_and_gini_index/index.html#gini-index",
    "title": "Lorenz curve and Gini index",
    "section": "2 Gini index",
    "text": "2 Gini index\n\n2.1 Definition\nThe Gini coefficient is the ratio of the area between the line of perfect equality and the observed Lorenz curve to the area between the line of pefect equality and the line of perfect inequality. The higher the coefficient, the more unequal the distribution. In the diagram above, this is given by the ratio \\(\\frac{A}{A+B} = 2A = 1-2B\\) due to the fact that \\(A + B = 0.5\\).\nAssuming non-negative income or wealth for all, the Gini coefficient’s theoretical range is from \\(0\\) (total equality) to \\(1\\) (absolute inequality).\nAn alternative approach is to define the Gini coefficient as half of the relative mean absolute difference, which is equivalent to the definition based on the Lorenz curve. The mean absolute difference is the average absolute difference of all pairs of items of the population, and the relative mean absolute difference is the mean absolute difference divided by the average \\(\\bar{x}\\) to normalize for scale.\nIf \\(x_i\\) is the income or wealth of person \\(i\\), and there are \\(n\\) persons, then the Gini coefficient \\(G\\) is given by\n\\[\nG = \\frac{\\sum_{i=1}^{n}\\sum_{j=1}^{n} |x_i - x_j|}{2n^2\\bar{x}} = \\frac{\\sum_{i=1}^{n}\\sum_{j=1}^{n} |x_i - x_j|}{2n \\sum_{i=1}^{n} \\bar{x}}\n\\]\nWhen the wealth or income distribution is given as a continuous PDF \\(p(x)\\), the Gini coefficient is again half of the relative mean absolute difference:\n\\[\nG = \\frac{1}{2\\mu} \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} p(x)p(y) |x-y| dxdy\n\\]\nwhere \\(\\mu = \\int_{-\\infty}^{\\infty} xp(x) dx\\) is the mean of the distribution, and the lower limits of integration may be replaced by zero when all incomes are positive.\n\n\n2.2 Calculation\nIf the values are first placed in ascending order, such that each \\(x\\) has rank \\(i\\), some of the comparisons above can be avoided and the computation can be quicker:\n\\[\n\\begin{align}\nG &= \\frac{2}{n^2\\bar{x}} \\sum_{i=1}^{n} i(x_i - \\bar{x}) \\\\\nG &= \\frac{\\sum_{i=1}^{n} (2i-n-1)x_i}{n \\sum_{i=1}^{n} x_i}\n\\end{align}\n\\]\nwhere \\(x\\) is an observed value, \\(n\\) is the number of values observed and \\(i\\) is the rank of values in ascending order.\nNote that only positive non-zero values are used.\n\nJulia code\n\n\nusing Random, Distributions\n\nRandom.seed!(1234)\n\n@doc raw\"\"\"\n    gini(A::AbstractArray)\n\nCalculate the Gini coefficient of an array of numbers using the formula:\n\n``G = \\frac{\\sum_{i=1}^{n} (2i-n-1)x_i}{n \\sum_{i=1}^{n} x_i}``\n\"\"\"\nfunction gini(A::AbstractArray)\n    A = vec(A)\n\n    # values cannot be negative\n    if minimum(A) &lt; 0\n        A = A .- minimum(A)\n    end\n    # values cannot be 0\n    A = A .+ 1e-7\n\n    A = sort(A)\n    n = length(A)\n    index = collect(1:n)\n\n    sum(@. (2 * index - n - 1) * A) / (n * sum(A))\nend\n\n\nA = zeros(1000)\nA[1] = 1\nprintln(gini(A))\n\nB = ones(1000)\nprintln(gini(B))\n\nC = rand(Normal(0, 10), 1000)\nprintln(gini(C))\n\n0.998900109989001\n-1.0004440719058136e-17\n0.1756229561649242"
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html",
    "href": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html",
    "title": "Probability and statistics with Julia",
    "section": "",
    "text": "Statistics with Julia by Yoni Nazarathy (2021)."
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#references",
    "href": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#references",
    "title": "Probability and statistics with Julia",
    "section": "",
    "text": "Statistics with Julia by Yoni Nazarathy (2021)."
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#pseudorandom-number-generation",
    "href": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#pseudorandom-number-generation",
    "title": "Probability and statistics with Julia",
    "section": "2 Pseudorandom number generation",
    "text": "2 Pseudorandom number generation\nFor pseudorandom number generation, there is some deterministic (non-random and well defined) sequence \\(\\{x_n\\}\\), specified by\n\\[\nx_{n+1} = f(x_n, x_{n-1}, ...)\n\\]\noriginating from some specified seed \\(x_0\\). The mathematical function \\(f(\\cdot)\\) is designed to yield desirable properties for the sequence \\(\\{x_n\\}\\) that make it appear random.\nThose properties include:\n\nElements \\(x_i\\) and \\(x_j\\) for \\(i \\neq j\\) should appear statistically independent. That is, knowing the value of \\(x_i\\) should not yield any information about the value \\(x_j\\).\nThe distribution of \\(\\{x_n\\}\\) should appear uniform. That is, there shouldn’t be values (or ranges of values) where elements of \\(\\{x_n\\}\\) occur more frequently than others.\nThe range covered by \\(\\{x_n\\}\\) should be well defined.\nThe sequence should repeat itself as rarely as possible.\n\nIn Julia, the main player for pseudorandom number generation is the function rand(), which generates a random number in each call without giving any arguments once a seed is set (it is usually set to the current time by default). You can set the seed yourself by using the Random.seed!() function from the Random package.\n\nusing Random\n\nRandom.seed!(2023)\nprintln(\"Seed 2023: \", rand(), \"\\t\", rand(), \"\\t\", rand())\nRandom.seed!(2024)\nprintln(\"Seed 2024: \", rand(), \"\\t\", rand(), \"\\t\", rand())\nRandom.seed!(2023)\nprintln(\"Seed 2023: \", rand(), \"\\t\", rand(), \"\\t\", rand())\n\nSeed 2023: 0.1321419481484759   0.37179020701747134 0.9005132318421792\nSeed 2024: 0.10884245939837256  0.7189031628453905  0.5826662196960152\nSeed 2023: 0.1321419481484759   0.37179020701747134 0.9005132318421792\n\n\nAs can be seen from the output, setting the same seed will generate the same sequence.\n\n2.1 Creating a simple pseudorandom number generator\nHere, we create a Linear Congruential Generator (LCG). The function \\(f(\\cdot)\\) used here is just a linear transformation modulo \\(m\\): \\(x_{n+1} = (ax_n + c) \\mod m\\).\nHere, we pick \\(m = 2^{32}\\), \\(a = 69069\\), \\(c = 1\\), which yields sensible performance.\n\nusing DataFrames, AlgebraOfGraphics, CairoMakie\n\na, c, m = 69069, 1, 2^32\nnext(x) = (a * x + c) % m\n\nN = 10^6\nvec = Array{Float64,1}(undef, N)\n\nx = 2024  # Seed\nfor i in 1:N\n    global x = next(x)\n    vec[i] = x / m  # Scale x to [0, 1]\nend\ndf = DataFrame(x=1:N, y=vec)\n\nfig = Figure()\np1 = data(first(df, 5000)) * mapping(:x, :y) * visual(Scatter, markersize=3)\np2 = data(df) * mapping(:y) * visual(Hist, bins=50, normalization=:pdf)\ndraw!(fig[1, 1], p1, axis=(xlabel=\"n\", ylabel=L\"\\mathbf{x_n}\"))\ndraw!(fig[1, 2], p2, axis=(xlabel=\"x\", ylabel=\"Density\"))\nfig\n\n\n\n\n\n\n2.2 More about Julia’s pseudorandom number generator\nIn addition to rand(), we can also use randn() to generate normally distributed random numbers.\nAfter invoking using Random, the following functions are available:\n\nRandom.seed!()\nrandsubseq()\nrandstring()\nrandcycle()\nbitrand()\nrandperm() and shuffle() for permutations\n\nIn addition, in Julia, we can create an object representing a pseudorandom number generator implemented via a specified algorithm, for example, the Mersenne Twister pseudorandom number generator, which is considerably more complicated than the LCG described above. In Julia, we can create such an object of the Mersenne Twister pseudorandom number generator by calling rng = MersenneTwister(seed), and then pass the rng to rand() to let it use the given pseudorandom number generator to generate pseudorandom numbers."
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#monte-carlo-simulation",
    "href": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#monte-carlo-simulation",
    "title": "Probability and statistics with Julia",
    "section": "3 Monte Carlo simulation",
    "text": "3 Monte Carlo simulation\nThe core idea of Monte Carlo simulation lies in building a mathematical relationship between an unknown quantity to be estimated and the probability of a certain event, which can be estimated by statistical sampling. Then, we can get an estimate of this unknown quantity.\nWe can use this idea to estimate the value of \\(\\pi\\).\n\nusing DataFrames, AlgebraOfGraphics, CairoMakie\n\nline_df = DataFrame(x=[0, 0, 1, 1, 0],\n    y=[0, 1, 1, 0, 0])\n\nx = range(0, 1, length=1000)\nquarter_circle_df = DataFrame(x=x,\n    y=@. sqrt(1 - x^2))\n\nrect = data(line_df) * mapping(:x, :y) * visual(Lines)\nquarter_circle = data(quarter_circle_df) * mapping(:x, :y) * visual(Lines)\ndraw(rect + quarter_circle, axis=(limits=(0, nothing, 0, nothing),))\n\n\n\n\nAs can be seen from the above figure, we know:\n\nThe area of the unit square is 1;\nThe area of the first quadrant of the unit circle is \\(\\pi / 4\\);\nThen, if we randomly throw a ball within the unit square, the probability of the event that this ball falls into the area of the first quadrant of the unit circle is \\(\\pi / 4\\). Further, we know that the probability of this event can be estimated by its frequency if we repeat this experiment infinitely many times; therefore, we can estimate the value of \\(\\pi\\) by the following formula:\n\n\\[\n\\hat{\\pi} = 4 \\frac{\\text{The number of times falling in }x^2 + y^2 \\leq 1}{\\text{Total number of times}}\n\\]\n\nusing Random, LinearAlgebra, AlgebraOfGraphics, CairoMakie, DataFrames\n\nRandom.seed!(1234)\n\nN = 10^5\ndf = DataFrame([(x=rand(), y=rand()) for _ in 1:N])\ntransform!(df, [:x, :y] =&gt; ByRow((x, y) -&gt; ifelse(norm([x, y]) &lt;= 1, \"in\", \"out\")) =&gt; :flag)\npi_estimate = 4 * count(df.flag .== \"in\") / N\nprintln(\"π estimate: \", pi_estimate)\n\nfig = Figure()\np = data(df) * mapping(:x, :y, color=:flag) * visual(Scatter, markersize=1)\ndraw!(fig, p, axis=(limits=(0, nothing, 0, nothing),))\nfig\n\nπ estimate: 3.14688"
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#distributions-and-related-packages-for-probability-distributions",
    "href": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#distributions-and-related-packages-for-probability-distributions",
    "title": "Probability and statistics with Julia",
    "section": "4 Distributions and related packages for probability distributions",
    "text": "4 Distributions and related packages for probability distributions\n\n4.1 Introduction\nPackages:\n\nStatistics (built-in)\nStatsBase\nDistributions\n\n\n4.1.1 Weighted vectors\nThe StatsBase package provides the “weighted vector” object via Weights(), which allows for an array of values to be given probabilistic weights.\nAn alternative of Weights() is to use the Categorical distribution supplied by the Distributions package.\nTogether with Weights(), you can use the sample() function from StatsBase to generate observations.\n\nusing StatsBase, Random\n\nRandom.seed!(1234)\n\ngrades = 'A':'E'\nweights = Weights([0.1, 0.2, 0.1, 0.2, 0.4])\n\nN = 10^6\nd = sample(grades, weights, N)\n[count(i -&gt; i == g, d) for g in grades] / N\n\n5-element Vector{Float64}:\n 0.099651\n 0.200224\n 0.099522\n 0.20053\n 0.400073\n\n\n\n\n4.1.2 Distribution type objects\nThe Distributions package allows us to create distribution type objects based on what family they belong to. Then these distribution type objects can be used as arguments for other functions.\n\nusing Distributions, CairoMakie\n\ndist = TriangularDist(0, 2, 1)  # Triangular distribution\nx = 0:0.01:2\nu = 0:0.01:1\n\nfig = Figure(size=(800, 250))\nlines!(Axis(fig[1, 1], xlabel=\"x\", ylabel=\"f(x)\"), x, pdf.(dist, x))  # PDF\nlines!(Axis(fig[1, 2], xlabel=\"x\", ylabel=\"F(x)\"), x, cdf.(dist, x))  # CDF\nlines!(Axis(fig[1, 3], xlabel=\"u\", ylabel=L\"\\mathbf{F^{-1}(u)}\"), u, quantile.(dist, u))  # ICDF\nfig\n\n\n\n\n\nprintln(\"Parameters: \", params(dist))\nprintln(\"Central descriptors: \", mean(dist), \", \", median(dist))\nprintln(\"Dispersion descriptos: \", var(dist), \", \", std(dist))\nprintln(\"Higher-order moment shape descriptors: \", skewness(dist), \", \", kurtosis(dist))\nprintln(\"Range: \", minimum(dist), \", \", maximum(dist))\nprintln(\"Mode: \", mode(dist), \", \", modes(dist))  # Value(s) of x where PMF or PDF is maximized\n\nParameters: (0.0, 2.0, 1.0)\nCentral descriptors: 1.0, 1.0\nDispersion descriptos: 0.16666666666666666, 0.408248290463863\nHigher-order moment shape descriptors: 0.0, -0.6\nRange: 0.0, 2.0\nMode: 1.0, [1.0]"
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#univariate-distributions",
    "href": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#univariate-distributions",
    "title": "Probability and statistics with Julia",
    "section": "5 Univariate distributions",
    "text": "5 Univariate distributions\n\n5.1 Families of discrete distributions\n\n5.1.1 Discrete uniform distribution\n\nusing StatsBase, CairoMakie\n\nfaces, N = 1:6, 10^6\n\nmcEstimate = counts(rand(faces, N), faces) / N  # rand(faces, N) is identical to rand(DiscreteUniform(1, 6), N)\ntheory = [1 / 6 for _ in faces]\n\nfig, ax = stem(faces, mcEstimate, label=\"Estimate\",\n    color=:black, stemcolor=:black,\n    stemwidth=6, markersize=18,\n    axis=(xlabel=\"x\", ylabel=\"f(x)\"))\nstem!(ax, faces, theory, label=\"Theory\",\n    color=:red, stemcolor=:red)\nylims!(ax, nothing, 0.25)\naxislegend(ax)\nfig\n\n\n\n\n\n\n5.1.2 Binomial distribution\n\nusing StatsBase, Distributions, CairoMakie\n\nbinomialRV(n, p) = sum(rand(n) .&lt; p)\n\np, n, N = 0.25, 10, 10^6\n\nb_dist = Binomial(n, p)\nx = 0:n\nb_pmf = pdf.(b_dist, x)\nest_data = [binomialRV(n, p) for _ in 1:N]\nest_pmf = counts(est_data, 0:n) / N\n\nfig, ax = stem(x, est_pmf, label=\"Estimate\",\n    color=:black, stemcolor=:black,\n    stemwidth=6, markersize=18,\n    axis=(xlabel=\"x\", ylabel=\"f(x)\"))\nstem!(ax, x, b_pmf, label=\"Theory\",\n    color=:red, stemcolor=:red)\naxislegend(ax)\nfig\n\n\n\n\n\n\n5.1.3 Geometric distribution\nConsider an infinite sequence of independent trials, each with sucess probability \\(p\\), and let \\(X\\) be the first trial that is successful. Then the PMF is:\n\\[\nP(X=x) = p(1-p)^{x-1}\n\\]\nfor \\(x = 1, 2, ...\\).\nAn alternative version is to count the number of failures until success. Obviously, we have \\(\\tilde{X} = X - 1\\). Then the PMF is:\n\\[\nP(\\tilde{X} = x) = p(1-p)^x\n\\]\nfor \\(x = 0, 1, 2, ...\\).\nIn Distributions package, Geometric stands for the distribution of \\(\\tilde{X}\\).\n\nusing StatsBase, Distributions, CairoMakie\n\nfunction geometricRV(p)\n    x = 0\n    while true\n        if rand() &lt; p\n            return x\n        end\n        x += 1\n    end\nend\n\np = 0.25\nx = 0:25\nN = 10^6\n\ng_dist = Geometric(p)\ng_pmf = pdf.(g_dist, x)\nmcEstimate = counts([geometricRV(p) for _ in 1:N], x) / N\n\nfig, ax = stem(x, mcEstimate, label=\"Estimate\",\n    color=:black, stemcolor=:black,\n    stemwidth=6, markersize=18,\n    axis=(xlabel=\"x\", ylabel=\"f(x)\"))\nstem!(ax, x, g_pmf, label=\"Theory\",\n    color=:red, stemcolor=:red)\naxislegend(ax)\nfig\n\n\n\n\n\n\n5.1.4 Negative binomial distribution\n\\(X\\) stands for the number of trials until the \\(r\\)-th success. The PMF is:\n\\[\nP(X=x) = \\binom{x-1}{r-1} p^r (1-p)^{x-r}\n\\]\nfor \\(x = r, r+1, r+2, ...\\).\nSimilarly to the geometric distribution, we usually count the number of failures until the \\(r\\)-th success. The PMF is:\n\\[\nP(\\tilde{X} = x) = \\binom{x+r-1}{x} p^r (1-p)^x\n\\]\nfor \\(x = 0, 1, 2, ...\\).\n\nusing StatsBase, Distributions, CairoMakie\n\nfunction nbRV(r, p)\n    x = 0\n    success = 0\n    while true\n        if success == r\n            return x\n        end\n        if rand() &lt; p\n            success += 1\n        else\n            x += 1\n        end\n    end\nend\n\nr = 5\np = 0.25\nx = 0:60\nN = 10^6\n\nnb_dist = NegativeBinomial(r, p)\nnb_pmf = pdf.(nb_dist, x)\nmcEstimate = counts([nbRV(r, p) for _ in 1:N], x) / N\n\nfig, ax = stem(x, mcEstimate, label=\"Estimate\",\n    color=:black, stemcolor=:black,\n    stemwidth=6, markersize=18,\n    axis=(xlabel=\"x\", ylabel=\"f(x)\"))\nstem!(ax, x, nb_pmf, label=\"Theory\",\n    color=:red, stemcolor=:red)\naxislegend(ax)\nfig\n\n\n\n\n\n\n\n\n\n\nSummary\n\n\n\nSo far, we’ve seen that binomial distribution, Bernoulli distribution (0-1 distribution, two-point distribution), geometric distribution, and negative binomial distribution all involve Bernoulli trials which has exactly two possible outcomes, “success”, and “failure”, where the probability of success is the same every time the experiment is conducted.\nIn a word:\n\nBinomial distribution (\\(X \\sim B(n, p)\\)): \\(X\\) indicates the number of successes in \\(n\\) Bernoulli experiments.\nBernoulli distribution (\\(X \\sim B(1, p)\\)): \\(X\\) indicates the number of successes in \\(1\\) Bernoulli experiments.\nGeometric distribution (\\(X \\sim Ge(p)\\)): \\(X\\) indicates the number of total Bernoulli experiments until the first success.\nNegative binomial distribution (\\(X \\sim Nb(r, p)\\)): \\(X\\) indicates the number of total Bernoulli experiments until the \\(r\\)-th success.\n\nObviously, a binomial distribution or a negative binomial distribution can be divided into \\(n\\) Bernoulli distributions or \\(r\\) geometric distributions, respectively.\n\n\n\n\n5.1.5 Hypergeometric distribution\nHypergeometric distribution means sampling without replacement, which means the probability of success changes for each subsequent sample.\nThe PMF is:\n\\[\np(x) = \\frac{\\binom{M}{x} \\binom{N-M}{n-x}}{\\binom{N}{n}}\n\\]\nfor \\(x = max(0, n+M-N), ..., min(n, M)\\), where \\(N\\) (the population size), \\(M\\) (the number of successes), and \\(n\\) (the sample size) are all parameters.\nNote: \\(max(0, n+M-N)\\): if \\(n \\gt N-M\\) (i.e., \\(n\\) is greater than the number of failures), then at least \\(n - (N-M)\\) successes must occur.\n\nusing Distributions, CairoMakie\n\nN, M, n = 500, 100, 60\nx = max(0, n - (N - M)):min(n, M)\n\nh_dist = Hypergeometric(M, N - M, n)  # the 1st is the number of successes; the 2nd is the number of failures; the 3rd is the sample size\nh_pmf = pdf.(h_dist, x)\n\nstem(x, h_pmf,\n    color=:black, stemcolor=:black,\n    axis=(xlabel=\"x\", ylabel=\"f(x)\"))\n\n\n\n\n\n\n5.1.6 Poisson distribution\nThe Poisson process is a stochastic process (random process) which can be used to model occurrences of events over time or more generally in space.\nIn a Poisson process, during an infinitesimally small time interval, \\(\\Delta t\\), it is assumed that as \\(\\Delta t \\rightarrow 0\\):\n\nThere is an occurrence with probability \\(\\lambda \\Delta t\\) and no occurrence with probability \\(1 - \\lambda \\Delta t\\).\nThe chance of 2 or more occurences during an interval of length \\(\\Delta t\\) tends to \\(0\\).\n\nHere, \\(\\lambda \\gt 0\\) is the intensity of the Poisson process, and has the property that when multiplied by an interval of length \\(T\\), the mean occurrences during the interval is \\(\\lambda T\\).\nFor a Poisson process over the time interval \\([0, T]\\), the Poisson distribution can be used to describe the number of occurrences. The PMF is:\n\\[\nP(x\\text{ Poisson process occurrences during interval }[0, T]) = \\frac{(\\lambda T)^x}{x!} e^{-\\lambda T}\n\\]\nfor \\(x = 0, 1, 2, ...\\).\nWhen the interval is \\([0, 1]\\), then we have the PMF:\n\\[\np(x) = \\frac{\\lambda ^x}{x!} e^{-\\lambda}\n\\]\nfor \\(x = 0, 1, 2, ...\\), where \\(\\lambda\\) is the mean of occurences.\nIn addition, the times between occurrences in the Poisson process are exponentially distributed.\nThe Poisson process has many elegant analytic properties. One such property is to consider the random variable \\(N \\ge 0\\) such that\n\\[\n\\prod_{i=1}^{N} U_i \\ge e^{-\\lambda} \\gt \\prod_{i=1}^{N+1} U_i\n\\]\nwhere \\(U_1, U_2, ...\\) is a sequence of i.i.d uniform \\((0, 1)\\) random variables and \\(\\prod_{i=1}^{0} \\equiv 1\\).\nIt turns out that \\(N\\) is Poisson distributed with mean \\(\\lambda\\).\n\nusing StatsBase, Distributions, CairoMakie\n\nfunction pRV(lambda)\n    N, p = 0, 1\n    while p &gt;= MathConstants.e^(-lambda)\n        N += 1\n        p *= rand()\n    end\n    return N - 1\nend\n\nx = 0:20\nlambda = 5.5\nN = 10^6\n\np_dist = Poisson(lambda)\np_pmf = pdf.(p_dist, x)\n\nmcEstimate = counts([pRV(lambda) for _ in 1:N], x) / N\n\nfig, ax = stem(x, mcEstimate, label=\"Estimate\",\n    color=:black, stemcolor=:black,\n    stemwidth=6, markersize=18,\n    axis=(xlabel=\"x\", ylabel=\"f(x)\"))\nstem!(ax, x, p_pmf, label=\"Theory\",\n    color=:red, stemcolor=:red)\naxislegend(ax)\nfig\n\n\n\n\n\n\n\n5.2 Families of continuous distributions\n\n5.2.1 Continuous uniform distribution\n\nusing Distributions, CairoMakie\n\nx = 0:0.1:2π\nN = 10^6\n\nc_unif_dist = Uniform(0, 2π)\nc_unif_pmf = pdf.(c_unif_dist, x)\nest_data = rand(N) * 2π  # Equivalent to rand(c_unif_dist, N)\n\nfig, ax = stephist(est_data, normalization=:pdf, color=:black, label=\"Estimate\")\nlines!(ax, x, c_unif_pmf, color=:red, label=\"Theory\")\nylims!(ax, nothing, 0.3)\naxislegend(ax)\nfig\n\n\n\n\n\n\n5.2.2 Exponential distribution\nAs mentioned before, the exponential distribution is often used to model random durations between occurrences in the Poisson process.\nA non-negative random variable \\(X\\), expoentially distributed with a rate parameter \\(\\lambda\\), has PDF:\n\\[\nf(x) = \\lambda e^{-\\lambda x}\n\\]\nAs can be verified, the mean is \\(\\frac{1}{\\lambda}\\), the variance is \\(\\frac{1}{\\lambda ^2}\\), and the CCDF is \\(\\bar{F}(x) = e^{-\\lambda x}\\).\nIn addition, exponential random variables possess a lack of memory property:\n\\[\nP(X&gt;t+s|X&gt;t) = P(X&gt;s)\n\\]\nWhile geometric random variables also have such a property, this hints at the fact that exponential random variables are the continuous analogs of geometric random variables.\n\n\n\n\n\n\nSuppose that X is an exponential random variable, and \\(Y = \\lfloor X \\rfloor\\), where \\(\\lfloor \\cdot \\rfloor\\) represents the floor function. Then we’ll know that \\(Y\\) is a geometric random variable:\n\\[\np_Y (y) = P(\\lfloor X \\rfloor = y) = \\int_y^{y+1} \\lambda e^{-\\lambda x} \\mathrm{d}x = (e^{-\\lambda})^y (1-e^{-\\lambda})\n\\]\nfor \\(y = 0, 1, 2, ...\\).\nIf we set \\(p = 1 - e^{-\\lambda}\\), then \\(Y\\) is a geometric random variable (representing the number of failures until the first success) which starts at \\(0\\) and has the success parameter \\(p\\).\n\n\n\nNote: the parameter of Exponential is \\(\\frac{1}{\\lambda}\\), instead of \\(\\lambda\\).\nExponential distribution:\n\nusing Distributions, CairoMakie\n\nlambda = 1\nx = 0:0.01:10\n\nexp_dist = Exponential(1 / lambda)\nexp_pmf = pdf.(exp_dist, x)\n\nlines(x, exp_pmf, color=:black)\n\n\n\n\nThe PMF of the floor of an exponential random variable is a geometric distribution:\n\nusing StatsBase, Distributions, CairoMakie\n\nlambda = 1\nN = 10^6\nx = 0:6\n\nexp_dist = Exponential(1 / lambda)\nfloor_data = counts(convert.(Int, floor.(rand(exp_dist, N))), x) / N\n\ngeom_dist = Geometric(1 - MathConstants.e^-lambda)\n\nfig, ax = stem(x, floor_data, label=\"Floor of Exponential\",\n    color=:black, stemcolor=:black,\n    stemwidth=6, markersize=18,\n    axis=(xlabel=\"x\", ylabel=\"f(x)\"))\nstem!(ax, x, geom_dist, label=\"Geometric\",\n    color=:red, stemcolor=:red)\naxislegend(ax)\nfig\n\n\n\n\n\n\n5.2.3 Gamma distribution\nThe gamma distribution is commonly used to model asymmetric non-negative data.\nIt generalizes the exponential distribution and the chi-squared distribution.\nConsider such an example, where the lifetimes of light bulbs are exponentially distributed with mean \\(\\frac{1}{\\lambda}\\). Now imagine that we are lighting a room continuously with a single light bulb, and that we replace the bulb with a new one when it burns out. If we start at time \\(0\\), what is the distribution of time until \\(n\\) bulbs are replaced?\nOne way to describe this time is by the random variable \\(T\\), where\n\\[\nY = X_1 + X_2 + ... + X_n\n\\]\nand \\(X_i\\) are i.i.d. exponential random variables representing the lifetimes of light bulbs. It turns out that the distribution of \\(T\\) is a gamma distribution.\nAt a first glance, this is quite similar with the case, where the random variable of geometric distribution indicates the total number of Bernoulli trials until the first success, while the random variable of negative binomial distribution indicates the total number of Bernoulli trials until the \\(r\\)-th success, and we have \\(Y = X_1 + X_2 + ... + X_r\\), where \\(Y\\) is a random variable of negative binomial distribution, and \\(X_i\\) are i.i.d. geometric random variables.\nThe PDF of the gamma distribution is proportional to \\(x^{\\alpha - 1} e^{-\\lambda x}\\), where \\(\\alpha\\) is called the shape parameter, and \\(\\lambda\\) is called the rate parameter.\nIn order to normalize \\(x^{\\alpha - 1} e^{-\\lambda x}\\), we need to divide by \\(\\int_0^\\infty x^{\\alpha -1} e^{-\\lambda x} \\mathrm{d}x\\), which can be represented by \\(\\frac{\\Gamma (\\alpha)}{\\lambda ^\\alpha}\\), where \\(\\Gamma (\\cdot)\\) is called the gamma function.\nThen, the PDF of the gamma distribution is:\n\\[\nf(x) = \\frac{\\lambda ^\\alpha}{\\Gamma (\\alpha)} x^{\\alpha - 1} e^{-\\lambda x}\n\\]\ni.e., \\(X \\sim Ga(\\alpha, \\lambda)\\).\nIn the light bulbs case, we have \\(T \\sim Ga(n, \\lambda)\\), where \\(\\alpha = n\\).\nIt can also be evaluated that \\(E[X] = \\frac{\\alpha}{\\lambda}\\) and \\(Var(X) = \\frac{\\alpha}{\\lambda ^2}\\).\n\n\n\n\n\n\nSquared coefficient of variation\n\n\n\nSquared coefficient of variation is often used for non-negative random variables:\n\\[\nSCV = \\frac{Var(X)}{[E(X)]^2}\n\\]\nThe SCV is a normalized or unit-less version of the variance.\nThe lower it is, the less variability in the random variable.\nIt can be seen that for a gamma random variable, the SCV is \\(\\frac{1}{\\alpha}\\).\nFor the light bulbs case, the SCV is \\(\\frac{1}{n}\\), which indicates for large \\(n\\), i.e., more light bulbs, there is less variability.\n\n\n\nusing Distributions, CairoMakie\n\nlambda = 1 / 3\nN = 10^6\nbulbs = [1, 10, 50]  # α = 1 is exponential\nx = 0:0.1:20\ncolors = [:blue, :red, :green]\n\n# Theoretical gamma PDFs\n# For each case, we set the rate parameter at λn, so that the mean time until all light bulbs run out is n/(λn) = 1/λ, independent of n\n# For the rate parameter, like Exponential, Gamma also accepts 1/λ, not λ\nga_dists = [Gamma(n, 1 / (n * lambda)) for n in bulbs]\n\n# Generate exponentially distributed pseudorandom numbers by using the inverse probability transformation\nfunction approxBySumExp(dist::Gamma)\n    n = Int64(shape(dist))  # shape() is used to get the shape parameter α\n    [sum(-(1 / (n * lambda)) * log.(rand(n))) for _ in 1:N]  # Generate n exponentially distributed pseudorandom numbers, and then add them up to generate N gamma distributed pseudorandom numbers\nend\n\nest_data = approxBySumExp.(ga_dists)\n\nfig = Figure()\nax = Axis(fig[1, 1])\nfor i in 1:length(bulbs)\n    label = string(\"Shape = \", round(shape(ga_dists[i]), digits=2), \", Scale = \", round(Distributions.scale(ga_dists[i]), digits=2))  # The inverse of the rate parameter is called the scale parameter. Of coourse, you can also use the rate() function to get the rate parameter (λ)\n    stephist!(ax, est_data[i], normalization=:pdf, color=colors[i], label=label, bins=50)\nend\nfor i in 1:length(bulbs)\n    lines!(ax, x, pdf.(ga_dists[i], x), color=colors[i])\nend\nxlims!(ax, 0, 20)\nylims!(ax, 0, 1)\naxislegend(ax)\nfig\n\n\n\n\nNote: in the above code, we generate the exponentially distributed pseudorandom numbers by using the inverse probability transformation: \\(F(x) = P(X \\le x) = 1 - e^{-\\lambda x} \\Longrightarrow U = F(X) \\Longrightarrow U = 1 - e^{-\\lambda X} \\Longrightarrow X = -\\frac{1}{\\lambda} \\log(1-U) \\Longrightarrow X = -\\frac{1}{\\lambda} \\log U\\) (since we’ll use the rand function to generate uniformly distributed pseudorandom numbers in \\([0, 1]\\), it’s reasonable that replacing \\(1-U\\) with \\(U\\)).\n\n\n5.2.4 Beta distribution\nThe beta distribution is a commonly used distribution when seeking a parameterized shape over a finite support.\nThe PDF is:\n\\[\nf(x) = \\frac{x^{\\alpha - 1} (1-x)^{\\beta -1}}{B(\\alpha, \\beta)}\n\\]\nfor \\(x \\in [0, 1]\\). Both \\(\\alpha\\) and \\(\\beta\\) are shape parameters.\n\nusing Distributions, CairoMakie\n\nx = 0:0.01:1\n\nfig, ax = lines(x, pdf.(Beta(2, 2), x), label=\"α = β = 2\")\nlines!(ax, x, pdf.(Beta(1, 1), x), label=\"α = β = 1\")  # U(0, 1)\naxislegend(ax)\nfig\n\n\n\n\nNote: you can use mathematical special functions like beta or gamma function calling beta or gamma provided by the SpecialFunctions package. In addition, QuadGK provides the quadgk function to integrate one-dimensional function.\n\n\n5.2.5 Weibull distribution\nFor a random variable \\(T\\), representing the lifetime of an individual or a component, an interesting quantity is the instantaneous chance of failure at any time, given that the component has been operating without failure up to time \\(x\\).\nThe instantaneous chance of failure at time \\(x\\) can be expressed as\n\\[\nh(x) = \\lim_{\\Delta \\to 0} \\frac{1}{\\Delta} P(T \\in [x, x+\\Delta] | T \\gt x)\n\\]\nAlternatively, by using the conditional probability (\\(P(T \\in [x, x+\\Delta] | T \\gt x) = \\frac{P(T \\in [x, x+\\Delta])}{P(T \\gt x)} = \\frac{P(T \\in [x, x+\\Delta])}{1 - P(X \\le x)}\\)) and noticing that the PDF \\(f(x)\\) satisfies \\(f(x)\\Delta \\approx P(x \\le T \\lt x + \\Delta)\\) for small \\(\\Delta\\), we can express \\(h(x)\\) as\n\\[\nh(x) = \\lim_{\\Delta \\to 0} \\frac{f(x)\\Delta}{\\Delta (1-F(x))} = \\frac{f(x)}{1-F(x)}\n\\]\nHere the function \\(h(\\cdot)\\) is called the hazard rate function, which is often used in reliability analysis and survival analysis. It’s a common method of viewing the distribution for lifetime random variables \\(T\\).\nIn fact, we can reconstruct the CDF of \\(T\\) as\n\\[\nF(x) = 1 - \\exp(-\\int_0^x h(t)\\mathrm{d}t)\n\\]\nThe Weibull distribution is defined through the hazard rate function of the form \\(h(x) = \\lambda x^{\\alpha - 1}\\). Where \\(\\lambda\\) is positive, and \\(\\alpha\\) takes on any real value.\nThe parameter \\(\\alpha\\) gives the Weibull distribution different modes of behavior:\n\n\\(\\alpha = 1\\): the hazard rate is constant, in which case the Weibull distribution is actually an exponential distribution with rate \\(\\lambda\\).\n\\(\\alpha &gt; 1\\): the hazard rate increases over time. This depicts a situation of “aging components”, i.e., the longer a components has lived, the higher the instantaneous chance of failure. This is sometimes called Increasing Failure Rate (IFR).\n\\(\\alpha &lt; 1\\): this is an opposite case against \\(\\alpha &gt; 1\\). This is sometimes called Decreasing Failure Rate (DFR).\n\nFor Weibull distribution, we have\n\\[\nF(x) = 1 - \\exp(-\\int_0^x h(t)\\mathrm{d}t)\n\\]\nand\n\\[\nh(x) = \\lambda x^{\\alpha - 1}\n\\]\nThen the CDF and PDF are\n\\[\nF(x) = 1 - e^{-\\frac{\\lambda}{\\alpha} x^\\alpha}\n\\]\nand\n\\[\nf(x) = \\lambda x^{\\alpha - 1} e^{-\\frac{\\lambda}{\\alpha} x^\\alpha}\n\\]\nNote that in Julia, the distribution is parameterized via\n\\[\nf(x) = \\frac{\\alpha}{\\theta} (\\frac{x}{\\theta})^{\\alpha - 1} e^{-(\\frac{x}{\\theta})^\\alpha} = \\alpha \\theta ^{-\\alpha} x^{\\alpha - 1} e^{-\\theta ^{-\\alpha} x^\\alpha}\n\\]\nwhere the bijection from \\(\\lambda\\) to \\(\\theta\\) is\n\\[\n\\lambda = \\alpha \\theta ^{-\\alpha}\n\\]\nand\n\\[\n\\theta = (\\frac{\\alpha}{\\lambda})^{\\frac{1}{\\alpha}}\n\\]\nIn this case, \\(\\theta\\) is called the scale parameter, and \\(\\alpha\\) is the shape parameter.\n\nusing Distributions, CairoMakie\n\nalphas = [0.5, 1, 1.5]\ngiven_lambda = 2\nx = 0.01:0.01:10\ncolors = [:blue, :red, :green]\n\nactual_lambda(dist::Weibull) = shape(dist) * Distributions.scale(dist)^(-shape(dist))\ntheta(lambda, alpha) = (alpha / lambda)^(1 / alpha)\n\nwb_dists = [Weibull(alpha, theta(given_lambda, alpha)) for alpha in alphas]\n\nhazardA(dist, x) = pdf(dist, x) / ccdf(dist, x)\nhazardB(dist, x) = actual_lambda(dist) * x^(shape(dist) - 1)\n\n# We usually use the hazard rate function to view the Weibull distribution\nhazardsA = [hazardA.(dist, x) for dist in wb_dists]\nhazardsB = [hazardB.(dist, x) for dist in wb_dists]\n\nprintln(\"Maximum difference between two implementations of hazard: \",\n    maximum(maximum.(hazardsA - hazardsB)))\n\nfig = Figure()\nax = Axis(fig[1, 1],\n    xlabel=\"x\",\n    ylabel=\"Instantaneous failure rate\")\nfor i in 1:length(hazardsA)\n    label = string(\"λ = \", round(actual_lambda(wb_dists[i]), digits=2), \", α = \", round(shape(wb_dists[i]), digits=2))\n    lines!(ax, x, hazardsA[i], color=colors[i], label=label)\nend\nxlims!(ax, 0, 10)\nylims!(ax, 0, 10)\naxislegend(ax)\nfig\n\nMaximum difference between two implementations of hazard: 1.7763568394002505e-15\n\n\n\n\n\n\n\n5.2.6 Normal distribution\nThe normal distribution (also known as Gaussian distribution) is defined by two parameters, \\(\\mu\\) and \\(\\sigma ^2\\), which are the mean and variance respectively.\nThe PDF is\n\\[\nf(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma ^2}}\n\\]\nThe normal distribution usually comes with the standard form with \\(\\mu = 0\\) and \\(\\sigma ^2 = 1\\). The PDF is\n\\[\nf(u) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{u^2}{2}}\n\\]\nThe CDF of the standard normal distribution (the CDF of the normal distribution is not available as a simple expression) is\n\\[\n\\Phi (u) = \\int_{-\\infty}^u \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{t^2}{2}} \\mathrm{d}t = \\frac{1}{2} (1 + \\mathrm{erf}(\\frac{x}{\\sqrt{2}})\n\\]\nwhere \\(\\mathrm{erf}(\\cdot)\\) is a mathematical special function, called error function, and defined as\n\\[\n\\mathrm{erf}(x) = \\frac{2}{\\sqrt{\\pi}} \\int_0^x e^{-t^2} \\mathrm{d}t\n\\]\nFor any general normal random variable with mean \\(\\mu\\) and variance \\(\\sigma ^2\\), the CDF is available via \\(\\Phi(\\frac{x-\\mu}{\\sigma})\\).\n\nusing Distributions, Calculus, SpecialFunctions, CairoMakie\n\nx = -5:0.01:5\n\n# erf function from the SpecialFunctions package\nphiA(x) = 0.5 * (1 + erf(x / sqrt(2)))  # Calculate Φ(u) using the error function\nphiB(x) = cdf(Normal(), x)  # Calculate Φ(u)\n\nprintln(\"Maximum difference between two CDF implementations: \",\n    maximum(phiA.(x) - phiB.(x)))\n\nnormalDensity(x) = pdf(Normal(), x)\n\n# Calculate the numerical derivatives from the Calculus package\nd0 = normalDensity.(x)\nd1 = derivative.(normalDensity, x)  # We'll know that x = 0 is the unique extremum\nd2 = second_derivative.(normalDensity, x)  # We'll know x=±1 are two inflection points\n\nfig, ax = lines(x, d0, color=:red, label=\"f(x)\")\nlines!(x, d1, color=:blue, label=\"f'(x)\")\nlines!(x, d2, color=:green, label=\"f''(x)\")\naxislegend(ax)\nfig\n\nMaximum difference between two CDF implementations: 1.1102230246251565e-16\n\n\n\n\n\n\n\n5.2.7 Rayleigh distribution\nConsider an exponentially distributed random variable \\(X\\), with rate parameter \\(\\lambda = \\frac{\\sigma ^{-2}}{2}\\), where \\(\\sigma &gt; 0\\).\nLet \\(R = \\sqrt{X}\\), and then we have\n\\[\nF_R(y) = P(R \\le y) = P(\\sqrt{X} \\le y) = P(X \\le y^2) = F_X(y^2) = 1 - exp(-\\frac{y^2}{2\\sigma ^2})\n\\]\nand by differentiating, we get\n\\[\nf_R(y) = \\frac{y}{\\sigma ^2} exp(-\\frac{y^2}{2\\sigma ^2})\n\\]\nwhich is called the PDF of Rayleigh distribution.\nThe mean of a Rayleigh random variable is \\(\\sigma \\sqrt{\\frac{\\pi}{2}}\\).\nAs mentioned before, we have \\(U \\sim U(0, 1) \\xrightarrow{X = -\\frac{1}{\\lambda}\\log U} X \\sim Exp(\\lambda) \\xrightarrow{R=\\sqrt{X}, \\lambda = \\frac{\\sigma ^{-2}}{2}} R \\sim Rl(\\sigma)\\)\nIn addition, if \\(N_1\\) and \\(N_2\\) are two i.i.d. normally distributed random variables, each with \\(\\mu = 0\\) and std. \\(\\sigma\\), then \\(\\tilde{R} = \\sqrt{N_1^2 + N_2^2}\\) is also Rayleigh distributed just as \\(R\\) above.\nTherefore, we have three ways to generate Rayleigh distributed random variables:\n\nusing Distributions, CairoMakie\n\nN = 10^6\nsigma = 1.5\n\n# U(0, 1) ⟶ Exp(λ) ⟶ Rl(σ)\nrlA = sqrt.(-(2 * sigma^2) * log.(rand(N)))\n\n# From two i.i.d. normally distributed random variables\nnormal_dist = Normal(0, sigma)\nrlB = sqrt.(rand(normal_dist, N) .^ 2 + rand(normal_dist, N) .^ 2)\n\nrlC = rand(Rayleigh(sigma), N)\n\nmean.([rlA, rlB, rlC, sigma * sqrt(π / 2)])\n\n4-element Vector{Float64}:\n 1.880909546203193\n 1.8788405402037578\n 1.877567319733627\n 1.8799712059732503\n\n\nA common way to generate normal random variables, called the Box-Muller Transform, is to use the relationship \\(R = \\sqrt{N_1^2 + N_2^2}\\).\nThe relationship between the pair \\((N_1, N_2)\\) and their polar coordinate counterpart \\((\\theta, R)\\) is\n\\[\n\\begin{cases}\n   N_1 = R\\cos(\\theta) \\\\\n   N_2 = R\\sin(\\theta)\n\\end{cases}\n\\]\nwhere \\(\\theta\\) is a uniformly distributed random variable on \\([0, 2\\pi]\\), and \\(R\\) is a Rayleigh distributed random variable with parameter \\(\\sigma\\).\nGiven this, we can first generate \\(\\theta\\) and \\(R\\), and then transform them via the above formula into \\(N_1\\) and \\(N_2\\). Often, \\(N_2\\) is not needed. Hence, in practice, given two independent uniform \\((0, 1)\\) random variables \\(U_1\\) and \\(U_2\\), we set \\(Z = \\sqrt{-2\\sigma ^2 \\log U_1} \\cdot \\cos(2\\pi U_2)\\). Here \\(Z\\) is a normally distributed random variable with \\(\\mu = 0\\) and std. \\(\\sigma\\).\nGenerate \\(N(0, 1)\\):\n\nusing Distributions, CairoMakie\n\nZ(sigma) = sqrt(-2 * sigma * log(rand())) * cos(2 * pi * rand())\n\nfig, ax = hist([Z(1) for _ in 1:10^6], bins=50,\n    normalization=:pdf, label=\"MC estimate\")\nlines!(-4:0.01:4, pdf.(Normal(), -4:0.01:4),\n    label=\"PDF\", color=:red, linewidth=3)\naxislegend(ax)\nfig\n\n\n\n\n\n\n5.2.8 Cauchy distribution\nThe PDF is\n\\[\nf(x) = \\frac{1}{\\pi \\gamma (1 + (\\frac{x - x_0}{\\gamma})^2)}\n\\]\nwhere \\(x_0\\) is the location parameter at which the peak is observed, and \\(\\gamma\\) is the scale parameter.\nNote: the mean and variance are undefined for Cauchy distribution.\n\n\n5.2.9 Summary\n\n\n\n\n\n\n\nA brief summay of univariate distributions"
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#multivariate-distributions",
    "href": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#multivariate-distributions",
    "title": "Probability and statistics with Julia",
    "section": "6 Multivariate distributions",
    "text": "6 Multivariate distributions\nConsider \\(\\mathbf{X} = (X_1, ..., X_n)\\) as a random vector with multiple random variables, defined in the same probability space.\n\n6.1 Covarianve and correlation coefficient\nCovariance: \\(Cov(X, Y) = E[(X-\\mu_X)(Y-\\mu_Y)] = E[XY] - \\mu_X \\mu_Y\\).\nCorrelation coefficient: \\(\\rho_{XY} = \\frac{Cov(X, Y)}{\\sigma_X \\sigma_Y}\\), where \\(-1 \\le \\rho_{XY} \\le 1\\).\nThe correlation coefficient is a normalized covariance standing for the linear correlation relationship between \\(X\\) and \\(Y\\).\n\n\n6.2 Expectation vector and covariance matrix\nConsider a random vector \\(X = [X_1, ..., X_n]^\\top\\):\nThe expectation vector is defined as\n\\[\n\\mu_{\\mathbf{X}} = [E(X_1), ..., E(X_n)]^\\top\n\\]\nThe covariance matrix is defined as\n\\[\n\\Sigma_\\mathbf{X} = Cov(\\mathbf{X}) = E[(\\mathbf{X} - \\mu_\\mathbf{X})(\\mathbf{X} - \\mu_\\mathbf{X})^\\top]\n\\]\nAs can be verified, the \\(i,j\\)-th element of \\(\\Sigma_\\mathbf{X}\\) is \\(Cov(\\mathbf{X}_i, \\mathbf{X}_j)\\), and hence the diagonal elements are the variances.\n\n\n6.3 Affine transformation\nFor any collection of random variables,\n\\[\nE[X_1+ ... + X_n] = E[X_1] + ... + E[X_n]\n\\]\nFor uncorrelated random variables,\n\\[\nVar(X_1 + ... + X_n) = \\sum_{i} Var(X_i)\n\\]\nMore generally, if we allow the random variables to be correlated, then\n\\[\nVar(X_1 + ... + X_n) = \\sum_{i} Var(X_i) + 2\\sum_{i &lt; j} Cov(X_i, X_j)\n\\]\nObviously, the right-hand side is the sum of the elements of the matrix \\(Cov(\\mathbf{X})\\).\nThe above is a special case of the affine transformation, where we take a random vector \\(\\mathbf{X} = [X_1, ..., X_n]^\\top\\) with covariance matrix \\(\\Sigma_\\mathbf{X}\\), and an \\(m \\times n\\) matrix \\(\\mathbf{A}\\) and \\(m\\) vector \\(\\mathbf{b}\\). We then set\n\\[\n\\mathbf{Y} = \\mathbf{A}\\mathbf{X} + \\mathbf{b}\n\\]\nThen, the new random vector \\(\\mathbf{Y}\\) has expectation and covariance\n\\[\nE[\\mathbf{Y}] = \\mathbf{A}E[\\mathbf{X}] + \\mathbf{b}\\ \\ \\ \\ \\text{and}\\ \\ \\ \\ Cov(\\mathbf{Y}) = \\mathbf{A}\\Sigma_\\mathbf{X}\\mathbf{A}^\\top\n\\]\nThe above case can be retrieved by setting \\(\\mathbf{A} = [1, ..., 1]\\), and \\(\\mathbf{b} = \\mathbf{0}\\).\n\n\n6.4 The Cholesky decomposition and generating random vectors\nNow we want to create an \\(n\\)-dimensional random vector \\(\\mathbf{Y}\\) with some specified expectation vector \\(\\mu_\\mathbf{Y}\\) and covariance matrix \\(\\Sigma_\\mathbf{Y}\\), which are known.\nFirst, we can generate a random vector \\(\\mathbf{X}\\) with \\(\\mu_\\mathbf{X} = \\mathbf{0}\\) and identity-covariance matrix \\(\\Sigma_\\mathbf{X} = \\mathbf{I}\\) (e.g., a sequence of \\(n\\) i.i.d. N(0, 1) random variables).\nThen, by applying the affine transformation \\(\\mathbf{Y} = \\mathbf{A}\\mathbf{X} + \\mathbf{b}\\), we have \\(\\mu_\\mathbf{Y} = \\mathbf{b}\\) and a matrix \\(\\mathbf{A}\\) which satisfies \\(\\Sigma_\\mathbf{Y} = \\mathbf{A}\\mathbf{A}^\\top\\). The Cholesky decomposition will help us get \\(\\mathbf{A}\\) from \\(\\Sigma_\\mathbf{Y} = \\mathbf{A}\\mathbf{A}^\\top\\).\n\nusing Distributions, LinearAlgebra, Random, CairoMakie\n\nRandom.seed!(1)\n\nN = 10^5\n\nmuY = [15; 20]\nSigY = [6 4; 4 9]\n\nA = cholesky(SigY).L  # The Cholesky decomposition; get the lower triangular form\n\nrngGens = [() -&gt; rand(Normal()),\n    () -&gt; rand(Uniform(-sqrt(3), sqrt(3))),\n    () -&gt; rand(Exponential()) - 1]  # Expectation 0; variance 1\n\nlabels = [\"Normal\", \"Uniform\", \"Exponential\"]\ncolors = [:blue, :red, :green]\n\nrv(rng) = A * [rng(), rng()] + muY\n\nds = [[rv(rng) for _ in 1:N] for rng in rngGens]\n\nprintln(\"E1\\tE2\\tVar1\\tVar2\\tCov\")\nfor d in ds\n    println(round(mean(first.(d)), digits=2), \"\\t\", round(mean(last.(d)), digits=2), \"\\t\",\n        round(var(first.(d)), digits=2), \"\\t\", round(var(last.(d)), digits=2), \"\\t\",\n        round(cov(first.(d), last.(d)), digits=2))\nend\n\nfig = Figure()\nax = Axis(fig[1, 1],\n    xlabel=L\"X_1\",\n    ylabel=L\"X_2\")\nfor i in 1:length(ds)\n    scatter!(ax, first.(ds[i]), last.(ds[i]), color=colors[i], label=labels[i], markersize=2)\nend\naxislegend(ax, position=:rb)\nfig\n\nE1  E2  Var1    Var2    Cov\n15.01   20.01   5.97    9.04    3.99\n15.01   20.0    6.0 8.99    3.98\n15.0    20.0    5.99    8.89    4.0\n\n\n\n\n\n\n\n6.5 Bivariate normal distribution\n\\[\n\\mu_\\mathbf{XY} = \\left[\\begin{matrix} \\mu_\\mathbf{X} \\\\ \\mu_\\mathbf{Y} \\end{matrix}\\right]\n\\]\n\\[\n\\Sigma_\\mathbf{XY} = \\left[\\begin{matrix} \\sigma_\\mathbf{X}^2 & \\sigma_\\mathbf{X}\\sigma_\\mathbf{Y}\\rho \\\\ \\sigma_\\mathbf{X}\\sigma_\\mathbf{Y}\\rho & \\sigma_\\mathbf{Y}^2\\end{matrix} \\right]\n\\]\n\nusing Distributions, CairoMakie\n\nmeanVect = [27.1554, 26.1638]\ncovMat = [16.1254 13.047; 13.047 12.3673]\n\nbiNorm = MvNormal(meanVect, covMat)  # Multivariate normal distribution\n\nN = 10^3\npoints = rand(biNorm, N)\n\nsupport = 15:0.5:40\nz = [pdf(biNorm, [x, y]) for x in support, y in support]\n\nfig = Figure(size=(900, 400))\nax2 = Axis(fig[1, 1],\n    xlabel=\"x\",\n    ylabel=\"y\")\nscatter!(ax2, points[1, :], points[2, :], markersize=4, color=:black)\ncontour!(support, support, z, levels=[0.001, 0.005, 0.02], color=:red, linewidth=2)\nax3 = Axis3(fig[1, 2],\n    xlabel=\"x\",\n    ylabel=\"y\",\n    zlabel=\"z\")\nsurface!(support, support, z)\ncolsize!(fig.layout, 1, Auto(0.65))\nfig"
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#processing-and-summarizing-data",
    "href": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#processing-and-summarizing-data",
    "title": "Probability and statistics with Julia",
    "section": "7 Processing and summarizing data",
    "text": "7 Processing and summarizing data\n\n7.1 Processing data\nData cleaning.\n\n\n7.2 Summarizing data\nDescriptive statistics.\n\n7.2.1 Single sample\nGiven a set of observations \\(x_1, x_2, ..., x_n\\).\n\nSample mean: measure of centrality.\n\n\nArithmetic mean:\n\n\\[\n\\bar{x} = \\frac{\\displaystyle\\sum_{i=1}^{n} x_i}{n}\n\\]\n\nGeometric mean:\n\n\\[\n\\bar{x}_g = \\sqrt[n]{\\displaystyle\\prod_{i=1}^n x_i}\n\\]\nUseful for averaging growth factors.\ne.g., if we start with an original base level say \\(L\\) with growths of \\(x_1\\), \\(x_2\\), and \\(x_3\\) in three consecutive periods, then after three periods, we have\n\\[\n\\text{Value after three periods} = L\\cdot x_1\\cdot x_2\\cdot x_3 = L\\cdot \\bar{x}_g^3\n\\]\nHere, the average growth factor is \\(\\bar{x}_g\\).\n\nHarmonic mean:\n\n\\[\n\\bar{x}_h = \\frac{n}{\\displaystyle\\sum_{i=1}^n \\frac{1}{x_i}}\n\\]\nUseful for averaging rates or speeds.\nAssume that you are on a brisk hike, walking \\(5\\) km up a mountain and then \\(5\\) km back down.\nSay your speed going up is \\(x_1 = 5 \\text{ km/h}\\), and your speed going down is \\(x_2 = 10 \\text{ km/h}\\).\nYou travel up for \\(1\\) h, and down for \\(0.5\\) h and hence your total travel time is \\(1.5\\) h.\nWhat is your average speed for the whole journey?\nThe avearge speed shoud be \\(\\frac{10 \\text{ km}}{1.5 \\text{ h}} = 6.6\\bar{6} \\text{ km/h}\\).\nThis is not the arithmetic mean which is \\(\\frac{x_1 + x_2}{2} = \\frac{5 \\text{ km/h}+ 10 \\text{ km/h}}{2} = 7.5 \\text{ km/h}\\) but rather equals the harmonic mean.\n\nVariance: a measure of dispersion.\n\n\nSample variance: the dispersion degree of sample observations away from the sample mean.\n\n\\[\ns^2 = \\frac{\\displaystyle\\sum_{i=1}^n (x_i - \\bar{x})^2}{n-1} = \\frac{\\displaystyle\\sum_{i=1}^n x_i^2 - n\\bar{x}^2}{n-1}\n\\]\nNote that the denominator is \\(n-1\\) instead of \\(n\\), which is the population variance (\\(s^2\\) defined in the above way is an unbiased estimator of the population variance).\n\nSample standard deviation: \\(s = \\sqrt{s^2}\\).\nStandard error: \\(\\frac{s}{\\sqrt{n}}\\) (the dispersion degree of sample mean away from the population mean).\n\nAnother breed of descriptive statistics is based on order statistics. This term is used to describe the sorted sample, denoted by\n\\(x_{(1)} \\le x_{(2)} \\le ... \\le x_{(n)}\\)\nBased on the order statistics, we can define a variety of statistics.\n\nminimum: \\(x_{(1)}\\).\nmaximum: \\(x_{(n)}\\).\nmedian: which in case of \\(n\\) being odd is \\(x_{(\\frac{n+1}{2})}\\); in case of \\(n\\) being even is the arithmetic mean of \\(x_{(\\frac{n}{2})}\\) and \\(x_{(\\frac{n}{2} + 1)}\\). A measure of centrality. It is not influenced by very high or very low measurements.\n\\(\\alpha\\)-quantile: which is \\(x_{(\\widetilde{\\alpha n})}\\), where \\(\\widetilde{\\alpha n}\\) denotes a rounding of \\(\\alpha n\\) to the nearest element of \\(\\{1, ..., n\\}\\).\n\n\\(\\alpha = 0.25\\) and \\(\\alpha = 0.75\\) is called the first quantile and the third quantile, the difference of which is called the inter-quantile range (IQR), which is a measure of dispersion.\n\nrange: \\(x_{(n)} - x_{(1)}\\), which is also a measure of dispersion.\n\nA measure of centrality: mean (arithmetic mean, geometric mean, harmonic mean), median (i.e., \\(0.5\\)-quantile).\nA measure of dispersion: variance (sample variance, sample standard deviation, standard error), IQR, range.\nIn Julia, packages Statistics together with StatsBase is usually used to perform descriptive statistics:\n\nusing Statistics, StatsBase, Distributions\n\nd = rand(Exponential(1 / 2), 10^6)\n\nprintln(\"Sample arithmetic mean, sample geometric mean, sample harmonic mean: \", (mean(d), geomean(d), harmmean(d)))\nprintln(\"Sample variance, sample standard deviation, sample standard error: \", (var(d), std(d), sem(d)))\nprintln(\"Minimum, maximum, range: \", (minimum(d), maximum(d), maximum(d) - minimum(d)))\nprintln(\"95th percentile, 0.95 quantile, IQR: \", (percentile(d, 95), quantile(d, 0.95), iqr(d)), \"\\n\")\n\nsummarystats(d)\n\nSample arithmetic mean, sample geometric mean, sample harmonic mean: (0.4989885578097969, 0.2802727834891644, 0.0040630310498548415)\nSample variance, sample standard deviation, sample standard error: (0.24873470917951312, 0.4987331041544296, 0.0004987331041544296)\nMinimum, maximum, range: (4.750186936682846e-9, 6.627393536148787, 6.6273935313986)\n95th percentile, 0.95 quantile, IQR: (1.4925592077411902, 1.4925592077411889, 0.5482163698428605)\n\n\n\nSummary Stats:\nLength:         1000000\nMissing Count:  0\nMean:           0.498989\nStd. Deviation: 0.498733\nMinimum:        0.000000\n1st Quartile:   0.143779\nMedian:         0.346183\n3rd Quartile:   0.691995\nMaximum:        6.627394\n\n\n\n\n7.2.2 Observations in pairs\nWhen data is configured in the form of pairs, \\((x_1, y_1), ..., (x_n, y_n)\\), we often consider the (1) sample covariance\n\\[\n\\widehat{cov}_{x,y} = \\frac{\\displaystyle\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{n-1}\n\\]\nor its normalized form - (2) correlation coefficient (Pearson correlation coefficient)\n\\[\n\\hat{\\rho}_{x,y} = \\frac{\\widehat{cov}_{x,y}}{s_x s_y}\n\\]\nWe often represent the variances and covariances in the (3) sample covariance matrix\n\\[\n\\hat{\\Sigma} = \\left[ \\begin{matrix} \\widehat{cov}_{x,x} & \\widehat{cov}_{x,y} \\\\ \\widehat{cov}_{x,y} & \\widehat{cov}_{y,y} \\end{matrix} \\right] = \\left[ \\begin{matrix} s_x^2 & \\hat{\\rho}_{x,y} s_x s_y \\\\ \\hat{\\rho}_{x,y} s_x s_y & s_y^2 \\end{matrix} \\right]\n\\]\n\nusing CSV, DataFrames, Statistics\n\nd = CSV.read(\"./data/temperatures.csv\", DataFrame)\n\nx = d.Brisbane\ny = d.GoldCoast\n\ncovXY = cov(x, y)\nsigX = std(x)\nsigY = std(y)\nrhoXY = covXY / (sigX * sigY)\n\nprintln(\"covXY: \", covXY, \"\\n\",\n    \"sigX: \", sigX, \"\\n\",\n    \"sigY: \", sigY, \"\\n\",\n    \"rhoXY: \", rhoXY)\n\nmeanVect = [mean(x), mean(y)]\ncovMat = [sigX^2 covXY\n    covXY sigY^2]\n\nprintln(\"meanVect: \", meanVect)\nprintln(\"covMat: \", covMat)\n\ncovXY: 13.046961200891614\nsigX: 4.015643106449177\nsigY: 3.5167106180015955\nrhoXY: 0.923884392762155\nmeanVect: [27.155405405405407, 26.163835263835264]\ncovMat: [16.1253895583728 13.046961200891614; 13.046961200891614 12.367253570765163]\n\n\n\n\n7.2.3 Observations in vectors\nThe data is represented by an \\(n\\times p\\) matrix, \\(\\mathbf{X}\\), where the rows are observations and the columns are features.\n\\[\n\\mathbf{X} = [\\mathbf{X_1}, ..., \\mathbf{X_p}]\n\\]\n\\(\\mathbf{X_j}\\) represents the \\(j\\)-th feature.\nBasically, we can summarize the data matrix \\(\\mathbf{X}\\) by these statistics:\n\nSample mean vector\n\n\\[\n\\bar{\\mathbf{x}} = [\\bar{x}_1, ..., \\bar{x}_p]^\\top\n\\]\n\nSample standard deviation vector\n\n\\[\n\\mathbf{s} = [s_1, ..., s_p]^\\top\n\\]\nWith these two statistics, we often standardize or normalize the data by creating a new \\(n\\times p\\) matrix \\(\\mathbf{Z}\\) with entries\n\\[\nz_{ij} = \\frac{x_{ij} - \\bar{x}_j}{s_j}, i = 1, ..., n,\\ \\ j = 1, ..., p\n\\]\nalso called z-scores.\nThe normalized data has the attribute that each column has a \\(0\\) sample mean and a unit standard deviation. Hence the first- and second-order information of the \\(j\\)-th feature is lost when moving from \\(\\mathbf{X}\\) to \\(\\mathbf{Z}\\).\nIt can be created via\n\\[\n\\mathbf{Z} = (\\mathbf{X} - \\mathbf{1}\\mathbf{\\bar{x}}^\\top)diag(\\mathbf{s})^{-1}\n\\]\nwhere \\(diag(\\cdot)\\) creates a diagonal matrix from a vector by using the Diagonal function, and then get the inverse matrix by using the grammar D^-1, both of which are from the LinearAlgebra package.\nIn Julia this can be calculated using the zscore function.\n\nSample covariance matrix\n\n\\[\n\\begin{align}\n\\hat{\\Sigma} & = \\frac{1}{n-1} (\\mathbf{X} - \\mathbf{1}\\mathbf{\\bar{x}}^\\top)^\\top (\\mathbf{X} - \\mathbf{1}\\mathbf{\\bar{x}}^\\top) \\\\\n             & = \\frac{1}{n-1} \\mathbf{X}^\\top (\\mathbf{I} - n^{-1} \\mathbf{1} \\mathbf{1}^\\top) \\mathbf{X}\n\\end{align}\n\\]\n\nSample correlation matrix\n\nThe following only picks two columns called \\(x\\) and \\(y\\) to perform deduction:\n\\[\n\\begin{align}\n\\hat{\\rho}_{x,y} & = \\frac{\\widehat{cov}_{x,y}}{s_x s_y} \\\\\n                 & = \\frac{\\displaystyle\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{(n-1) s_x s_y} \\\\\n                 & = \\frac{1}{n-1} \\displaystyle\\sum_{i=1}^n \\frac{x_i - \\bar{x}}{s_x} \\cdot \\frac{y_i - \\bar{y}}{s_y} \\\\\n                 & = \\frac{1}{n-1} \\displaystyle\\sum_{i=1}^n z_{ix} z_{iy} \\\\\n                 & = \\frac{1}{n-1} \\mathbf{Z}^\\top \\mathbf{Z}\n\\end{align}\n\\]\nIn julia this can be performed via the cor function.\n\nusing Statistics, StatsBase, LinearAlgebra, DataFrames, CSV\n\ndf = CSV.read(\"./data/3featureData.csv\", DataFrame, header=false)\nprintln(df, \"\\n\")\n\nX = Matrix(df)\nprintln(X, \"\\n\")\n\nn, p = size(X)\n\n# Sample mean vector\nxbarA = X' * ones(n) / n\nxbarB = [mean(X[:, j]) for j in 1:p]\nxbarC = sum(X, dims=1) / n\nprintln(\"Sample mean vector: \", \"\\n\", xbarA, \"\\n\", xbarB, \"\\n\", xbarC, \"\\n\")\n\n# Sample standard deviation vector\nsA = [std(X[:, j]) for j in 1:p]\nsB = std(X, dims=1)\nprintln(\"Sample standard deviation vector: \", \"\\n\", sA, \"\\n\", sB, \"\\n\")\n\nxbar = xbarB\ns = sA\n\n# Z-scores matrix\nZA = [((X[i, j] - mean(X[:, j])) / std(X[:, j])) for i in 1:n, j in 1:p]\nZB = (X - ones(n) * xbar') * Diagonal(s)^-1\nZC = hcat([zscore(X[:, j]) for j in 1:p]...)\nprintln(\"Z-scores matrix: \", \"\\n\", ZA, \"\\n\", ZB, \"\\n\", ZC, \"\\n\")\n\n# Sample covariance matrix\ncovA = (X - ones(n) * xbar')' * (X - ones(n) * xbar') / (n - 1)\ncovB = X' * (I - ones(n, n) / n) * X / (n - 1)\ncovC = [cov(X[:, i], X[:, j]) for i in 1:p, j in 1:p]\ncovD = [cor(X[:, i], X[:, j]) * std(X[:, i]) * std(X[:, j]) for i in 1:p, j in 1:p]\ncovE = cov(X)\nprintln(\"Sample covariance matrix: \", \"\\n\", covA, \"\\n\", covB, \"\\n\", covC, \"\\n\", covD, \"\\n\", covE, \"\\n\")\n\nZMat = ZC\n\n# Sample correlation coefficient matrix\ncorA = cov(X) ./ [std(X[:, i]) * std(X[:, j]) for i in 1:p, j in 1:p]\ncorB = cov(X) ./ (std(X, dims=1)' * std(X, dims=1))\ncorC = [cor(X[:, i], X[:, j]) for i in 1:p, j in 1:p]\ncorD = ZMat' * ZMat / (n - 1)\ncorE = cov(ZMat)\ncorF = cor(X)\nprintln(\"Sample correlation coefficient matrix: \", \"\\n\", corA, \"\\n\", corB, \"\\n\", corC, \"\\n\", corD, \"\\n\", corE, \"\\n\", corF, \"\\n\")\n\n7×3 DataFrame\n Row │ Column1  Column2  Column3 \n     │ Float64  Float64  Float64 \n─────┼───────────────────────────\n   1 │     0.9      2.1      1.2\n   2 │     1.1      1.9      2.5\n   3 │     1.7      1.9      3.4\n   4 │     0.8      2.3      2.3\n   5 │     1.3      1.6      9.4\n   6 │     0.7      2.7      1.3\n   7 │     0.9      2.1      4.4\n\n[0.9 2.1 1.2; 1.1 1.9 2.5; 1.7 1.9 3.4; 0.8 2.3 2.3; 1.3 1.6 9.4; 0.7 2.7 1.3; 0.9 2.1 4.4]\n\nSample mean vector: \n[1.0571428571428572, 2.085714285714286, 3.5]\n[1.0571428571428572, 2.085714285714286, 3.5]\n[1.0571428571428572 2.085714285714286 3.5]\n\nSample standard deviation vector: \n[0.34572215654165056, 0.34846602621858486, 2.834313555930842]\n[0.34572215654165056 0.34846602621858486 2.834313555930842]\n\nZ-scores matrix: \n[-0.45453510621013815 0.04099600308453923 -0.8114839641461745; 0.12396411987549243 -0.5329480400990126 -0.35281911484616285; 1.859461798132383 -0.5329480400990126 -0.03528191148461632; -0.7437847192529532 0.6149400462680898 -0.4233829378153955; 0.7024633459611227 -1.3938641048743392 2.081632777592361; -1.0330343322957687 1.7628281326351936 -0.7762020526615583; -0.45453510621013815 0.04099600308453923 0.31753720336154667]\n[-0.45453510621013815 0.04099600308453923 -0.8114839641461745; 0.12396411987549243 -0.5329480400990126 -0.35281911484616285; 1.859461798132383 -0.5329480400990126 -0.03528191148461632; -0.7437847192529532 0.6149400462680898 -0.4233829378153955; 0.7024633459611227 -1.393864104874339 2.081632777592361; -1.0330343322957687 1.7628281326351936 -0.7762020526615583; -0.45453510621013815 0.04099600308453923 0.31753720336154667]\n[-0.45453510621013815 0.04099600308453923 -0.8114839641461745; 0.12396411987549243 -0.5329480400990126 -0.35281911484616285; 1.859461798132383 -0.5329480400990126 -0.03528191148461632; -0.7437847192529532 0.6149400462680898 -0.4233829378153955; 0.7024633459611227 -1.393864104874339 2.081632777592361; -1.0330343322957687 1.7628281326351936 -0.7762020526615583; -0.45453510621013815 0.04099600308453923 0.31753720336154667]\n\nSample covariance matrix: \n[0.11952380952380953 -0.0873809523809524 0.44; -0.0873809523809524 0.12142857142857146 -0.715; 0.44 -0.715 8.033333333333335]\n[0.11952380952380959 -0.08738095238095228 0.44000000000000034; -0.08738095238095202 0.12142857142857223 -0.7149999999999989; 0.44000000000000034 -0.714999999999999 8.033333333333337]\n[0.11952380952380953 -0.0873809523809524 0.44; -0.0873809523809524 0.12142857142857146 -0.715; 0.44 -0.715 8.033333333333335]\n[0.11952380952380953 -0.0873809523809524 0.44; -0.08738095238095242 0.12142857142857147 -0.7150000000000001; 0.44000000000000006 -0.7150000000000001 8.033333333333335]\n[0.11952380952380953 -0.0873809523809524 0.44; -0.0873809523809524 0.12142857142857146 -0.715; 0.44 -0.715 8.033333333333335]\n\nSample correlation coefficient matrix: \n[1.0 -0.7253191060768939 0.44903228675078916; -0.7253191060768939 0.9999999999999999 -0.7239318847019132; 0.44903228675078916 -0.7239318847019132 1.0]\n[1.0 -0.7253191060768939 0.44903228675078916; -0.7253191060768939 0.9999999999999999 -0.7239318847019132; 0.44903228675078916 -0.7239318847019132 1.0]\n[1.0 -0.725319106076894 0.4490322867507892; -0.725319106076894 1.0 -0.7239318847019133; 0.4490322867507892 -0.7239318847019133 1.0]\n[1.0 -0.7253191060768939 0.4490322867507892; -0.7253191060768939 0.9999999999999999 -0.7239318847019133; 0.4490322867507892 -0.7239318847019133 0.9999999999999999]\n[1.0 -0.7253191060768939 0.4490322867507892; -0.7253191060768939 0.9999999999999998 -0.7239318847019132; 0.4490322867507892 -0.7239318847019132 0.9999999999999998]\n[1.0 -0.725319106076894 0.4490322867507892; -0.725319106076894 1.0 -0.7239318847019133; 0.4490322867507892 -0.7239318847019133 1.0]\n\n\n\n\n\n\n7.3 Plots for single samples and time series\nHere, we focus on a single collection of observations, \\(x_1, ..., x_n\\).\nIf the observations are obtained by randomly sampling a population, then the order of the observations is inconsequential.\nIf the observations represent measurement over time then we call the data time-series, and in this case, plotting the observations one after another is the standard way for considering temporal patterns in the data.\n\n7.3.1 Histograms\nConsidering frequencies of occurrences.\nFirst denote the support of the observations via \\([l, m]\\), where \\(l\\) is the minimal observation and \\(m\\) is the maximal observation.\nThen the interval \\([l, m]\\) is partitioned into a finite set of bins \\(B_1, ..., B_L\\), and the frequency in each bin is recorded via\n\\[\nf_j = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}{\\{x_i \\in B_j}\\}, \\ \\ \\ \\ \\text{for}\\ j = 1, ..., L\n\\]\nHere \\(\\mathbf{1}\\{\\cdot\\}\\) is \\(1\\) for \\(x_i \\in \\B_j\\), or \\(0\\) if not.\nWe have that \\(\\sum f_j = 1\\), and hence \\(f_i, ..., f_L\\) is a PMF.\nA histogram is then just a visual representation of PMF. One way to plot the frequencies is via a stem plot. However, such a plot would not represent the widths of the bins. Instead we plot \\(h(x)\\) defined as\n\\[\nh(x) = \\sum_{j=1}^L \\frac{f_j}{|B_j|} \\mathbf{1}{\\{x_i \\in B_j}\\}\n\\]\nwhere \\(|B_j|\\) is the width of bin \\(j\\). Hence \\(h(x)\\) is actually a PDF.\nIn a word, calculate frequencies of occurrences in each bin \\(\\implies\\) PMF; further normalized by bin widths \\(\\implies\\) PDF.\n\nusing Distributions, CairoMakie\n\nn = 2000\nd = rand(Normal(), n)\n\n# PMF\nfig, ax = hist(d, bins=20, normalization=:probability, color=:purple, label=\"PMF\")\n# PDF\nstephist!(ax, d, bins=20, normalization=:pdf, color=:red, label=\"PDF\")\naxislegend(ax)\nfig\n\n\n\n\n\n\n7.3.2 Density plots and kernel density estimation\nA more modern and visually applealing alternative to histograms is the smoothed histogram, also known as a density plot, often generated via a kernel density estimate.\n\nMixture model\n\nGenerating observations from a mixture model means that we sample from populations made up of heterogeneous sub-populations.\nEach sub-population has its own probability distribution and these are “mixed” in the process of sampling.\nAt first, a latent (un-observed) random variable determines which sub-population is used, and then a sample is taken from that sub-population.\nThat is if the \\(M\\) sub-populations have densities \\(g_1(x), ..., g_M(x)\\) with weights \\(p_1, ..., p_M\\), and \\(\\sum p_i = 1\\), then the density of the mixture is\n\\[\nf(x) = \\sum_{i=1}^M p_i g_i(x)\n\\]\n\nKernel density estimate\n\nGiven a set of observations, \\(x_1, ..., x_n\\), the KDE is the function\n\\[\n\\hat{f}(x) = \\frac{1}{n} \\sum_{i=1}^n \\frac{1}{h} K(\\frac{x-x_i}{h})\n\\]\nwhere \\(K(\\cdot)\\) is some specified kernel function and \\(h &gt; 0\\) is the bandwidth parameter.\nThe kernel function is a function that satisfies the properties of a PDF. A typical example is the Gaussian kernel\n\\[\nK(x) = \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{x^2}{2}}\n\\]\nWith such a kernel, the estimate \\(\\hat{f}(x)\\) is a PDF because it is a weighted superposition of scaled kernel fucntions centered about each of the observations.\nA very small bandwidth implies that the density\n\\[\n\\frac{1}{h} K(\\frac{x-x_i}{h})\n\\]\nis very concentrated around \\(x_i\\).\nFor any value of \\(h\\), it can be proved under general conditions that if the data is distributed according to some density \\(f(\\cdot)\\), then \\(\\hat{f}(\\cdot)\\) converges to \\(f(\\cdot)\\) when the sample size grows.\n\nusing Distributions, CairoMakie\n\nmu1, sigma1 = 10, 5\nmu2, sigma2 = 40, 12\n\ndist1, dist2 = Normal(mu1, sigma1), Normal(mu2, sigma2)\nmixRV(p) = (rand() &lt;= p) ? rand(dist1) : rand(dist2)\n\nn = 2000\nd = [mixRV(0.3) for _ in 1:n]\n\n# PMF\nfig, ax = hist(d, bins=20, normalization=:probability, color=:skyblue, label=\"PMF\")\n# PDF\nstephist!(ax, d, bins=20, normalization=:pdf, color=:red, label=\"PDF\")\n# Smoothed PDF\ndensity!(ax, d, color=(:white, 0), label=\"Smoothed PDF\", strokecolor=:green, strokewidth=2)\naxislegend(ax)\nfig\n\n\n\n\nIn a word, the KDE is a useful way to estimate the PDF of the unknown underlying distribution given some sample data.\n\n\n7.3.3 Empirical cumulative distribution function\nThe Empirical Cumulative Distribution Function (ECDF) can be viewed as an estimate of the underlying CDF.\nIn contrast to histograms and KDEs, ECDFs provide an unique representation of the data independent of tuning parameters.\nThe ECDF is a stepped function which, given \\(n\\) data points, increases by \\(\\frac{1}{n}\\) at each point.\nMathematically, given the sample, \\(x_1, ..., x_n\\), the ECDF is given by\n\\[\n\\hat{F}(t) = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1} \\{x_i \\le t\\}\\ \\ \\ \\ \\text{where }\\mathbf{1}\\text{ is the indicator function}\n\\]\nIn the case of i.i.d. data from an underlying distribution with CDF \\(F(\\cdot)\\), the Glivenko-Cantelli theorem ensures that the ECDF \\(\\hat{F}(\\cdot)\\) approaches \\(F(\\cdot)\\) as the sample size grows.\n\nusing Distributions, StatsBase, CairoMakie\n\nmu1, sigma1 = 10, 5\nmu2, sigma2 = 40, 12\n\ndist1, dist2 = Normal(mu1, sigma1), Normal(mu2, sigma2)\n\np = 0.3\n\nmixRV(p) = (rand() &lt;= p) ? rand(dist1) : rand(dist2)\nmixCDF(x) = p * cdf(dist1, x) + (1 - p) * cdf(dist2, x)\n\nn = [30, 100]\n\ndata1 = [mixRV(p) for _ in 1:n[1]]\ndata2 = [mixRV(p) for _ in 1:n[2]]\n\nempiricalCDF1 = ecdf(data1)\nempiricalCDF2 = ecdf(data2)\n\nx = -10:0.1:80\n\nfig, ax = lines(x, empiricalCDF1, label=\"ECDF with n = $(n[1])\")\nlines!(x, empiricalCDF2, label=\"ECDF with n = $(n[2])\")\nlines!(x, mixCDF.(x), label=\"Underlying CDF\")\naxislegend(ax, position=:lt)\nfig\n\n\n\n\n\n\n7.3.4 Normal probability plot\nSee Section 7.4.1 for details.\n\n\n7.3.5 Visualizing time series\nIn cases where the time-series data appears to be stationary (a stationary sequence is one in which the distributional law of observations doesn’t depend on the exact time. This means that there isn’t an apparent trend nor a cyclic component.), then a histogram is immediately insightful; otherwise, plotting data points one after the other along the time axis is necessary.\n\nusing DataFrames, CSV, Dates, CairoMakie\n\nd = CSV.read(\"./data/temperatures.csv\", DataFrame)\nbrisbane = d.Brisbane\ngoldcoast = d.GoldCoast\n\ndiff = brisbane - goldcoast\ndates = string.([Date(Year(d.Year[i]),\n    Month(d.Month[i]),\n    Day(d.Day[i]))\n                 for i in 1:nrow(d)])\n\nfortnight_range = 250:263\ndate_fortnight = dates[fortnight_range]\nbris_fortnight = brisbane[fortnight_range]\ngold_fortnight = goldcoast[fortnight_range]\n\nfig = Figure(size=(1100, 900))\n\nax1_slice_indexes = [1, 389, 777]\nax1 = Axis(fig[1, 1],\n    xlabel=\"Time\",\n    ylabel=\"Temperature\",\n    xticks=(ax1_slice_indexes, dates[ax1_slice_indexes]))\nseries!(ax1, stack(zip(brisbane, goldcoast)))\naxislegend(ax1, position=:rb)\n\nax2_slice_indexes = [1, 7, 14]\nax2 = Axis(fig[2, 1],\n    xlabel=\"Time\",\n    ylabel=\"Temperature\",\n    xticks=(ax2_slice_indexes, date_fortnight[ax2_slice_indexes]))\nseries!(ax2, stack(zip(bris_fortnight, gold_fortnight)))\nscatter!(1:length(date_fortnight), bris_fortnight)\nscatter!(1:length(date_fortnight), gold_fortnight)\naxislegend(ax2, position=:lb)\n\nax3_slice_indexes = [1, 389, 777]\nax3 = Axis(fig[3, 1],\n    xlabel=\"Time\",\n    ylabel=\"Temperature Difference\",\n    xticks=(ax3_slice_indexes, dates[ax3_slice_indexes]))\nseries!(ax3, reshape(diff, 1, length(diff)))\n\nax4 = Axis(fig[4, 1],\n    xlabel=\"Temperature Difference\",\n    ylabel=\"Frequency\")\nhist!(ax4, diff, bins=50)\n\nfig\n\n\n\n\n\n\n7.3.6 Radial plot\nRadial plot is useful for presenting time-series or cyclic data.\nA variation of radial plot is the radar plot, which is often used to visualize the levels of different categorical variables on the one plot.\n\nusing DataFrames, CSV, Dates, CairoMakie\n\nd = CSV.read(\"./data/temperatures.csv\", DataFrame)\nsubset!(d, :Year =&gt; x -&gt; x .== 2015)\nbrisbane = d.Brisbane\ngoldcoast = d.GoldCoast\n\ndates = [Date(Year(d.Year[i]),\n    Month(d.Month[i]),\n    Day(d.Day[i]))\n         for i in 1:nrow(d)]\n\nx = 0:2pi/(length(brisbane)-1):2pi |&gt; collect\nax_slice_indexes = [findfirst(Dates.month.(dates) .== m) for m in 1:12]\n\nfig = Figure(size=(600, 600))\nax = PolarAxis(fig[1, 1],\n    thetaticks=(x[ax_slice_indexes], Dates.monthabbr.(1:12)))\nseries!(ax, x, [brisbane goldcoast]')\n\nfig\n\n\n\n\n\n\n\n7.4 Plots for comparing two or more samples\n\n7.4.1 Quantile-Quantile (Q-Q) plot\nThe Q-Q plot checks if the distributional shape of two samples is the same or not.\nFor this plot, we require that the sample sizes are the same.\nThen the ranked quantiles of the first sample are plotted against the ranked quantiles of the second sample.\nIn the case where the samples have a similar distributional shape, the resulting plot appears like a collection of increasing points along a straight line.\n具体原理解释如下：\n给定一列数据 \\(x_1, ..., x_n\\)，假定其服从正态分布。现取一个正态分布作为模板，将其 PDF 下的面积等分成 \\(n\\) 份，即每一块区域代表的概率都是相等的，都是 \\(\\frac{1}{n}\\)。如果现在要从这个正态分布中抽取一个随机数，在理想情况下，这个数出现在任何一个小区域内的概率都是相等的。也就是说，在该正态分布被分成 \\(n\\) 等份后，如果我们要从其中抽出 \\(n\\) 个随机数，在理想情况下，应该是刚好每个小区间都被抽出了一个数，并且我们预期这些数应该是每个小区间的中位数（二分位数）。\n在下图中，\\(n = 10\\)：\n\nusing Distributions, CairoMakie\n\nd = Normal()\n\nn = 10\nx = -4:0.01:4\ny = pdf.(d, x)\nq = quantile.(d, collect(1/n:1/n:(n-1)/n))\n\nfig, ax = lines(x, y, color=:black)\nvlines!(ax, q, color=:red)\nfig\n\n\n\n\n对于 \\(n = 10\\) 来说，累积概率分位数分隔点分别为 \\(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9\\)（\\(\\frac{1}{n}, \\frac{2}{n}, ..., \\frac{n-1}{n}\\)），对应的每个小区间的累积概率二分位数应为 \\(0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95\\)（\\(\\frac{i-0.5}{n}\\ \\ \\ \\ \\text{for}\\ i = 1,2, .., n\\)），再利用公式 \\(\\Phi^{-1}\\left(\\frac{i-0.5}{n}\\right)\\ \\ \\ \\ \\text{for}\\ i = 1,2, .., n\\) 得到每个小区间相应的二分位数值。\n在理想情况下，排完序的实际观测值 \\(x_1, ..., x_n\\) 应该和上述 \\(n\\) 个二分位数值一致，即以实际值作为纵轴，理论值作为横轴，画出的这些点应该位于斜线 \\(y = x\\) 上。\n值得注意的是，取理论分位数值这一步有很多方法，除了等分概率分布取二分位数之外，也有直接将概率分布等分为 \\(n+1\\) 份，直接取对应的 \\(n\\) 个分位数即可。\n\nusing Random, Distributions, CairoMakie, Statistics\n\nRandom.seed!(1234)\n\nn = 2000\nmu, sigma = 10, 1\nrank = collect(1:2000)\n\nd = Normal(mu, sigma)\n\nempirical_data = rand(d, n) |&gt; sort\ntheoretical_data = quantile.(Normal(), @. (rank - 0.5) / n)\n\n# x = σU + μ\nfig, ax = scatter(theoretical_data, empirical_data, color=:steelblue)\nablines!(ax, mu, sigma, color=:red)\nqqnorm!(Axis(fig[2, 1]), empirical_data, qqline=:fitrobust, color=:red, markercolor=:steelblue)\nfig\n\n\n\n\nIf you want roughly to see if the two given data sets \\(x_1, ..., x_n\\), and \\(y_1, ..., y_n\\) have exactly the same distributional shape, you can just do the following:\n\nusing Distributions, CairoMakie, Random\n\nRandom.seed!(1)\n\n# Plot the ranked quantiles of x against the ranked quantiles of y\nx = randn(2000) |&gt; sort\ny = randn(2000) |&gt; sort\n\nfig, ax = scatter(x, y, color=:steelblue)\nablines!(0, 1, color=:red)\nqqplot!(Axis(fig[2, 1]), x, y, qqline=:identity, color=:red, markercolor=:steelblue)\nfig\n\n\n\n\n\n\n7.4.2 Box plot\nThe box plot, also known as a box and whisker plot, which displays the first and the third quantiles along with the median. The location of the whiskers is typically given by\n\\[\n\\text{minimum} = Q1 - 1.5 IQR\\ \\ \\text{,}\\ \\ \\text{maximum} = Q3 + 1.5 IQR\n\\]\nwhere IQR is the inter-quantile range. Observations that lie outside this range are called outliers.\n\nusing CairoMakie\n\ncategories = repeat(1:3, outer=300)\nv = randn(900)\n\n# notch is used to test the significance of the difference between two medians under the 0.95 confidence interval\nboxplot(categories, v, show_notch=true, color=:cyan)\n\n\n\n\n\nusing CairoMakie\n\ncategories = repeat(1:3, inner=800)\ndodge = repeat(repeat(1:2, outer=3), inner=400)\nv = randn(2400)\n\nboxplot(categories, v, dodge=dodge, show_notch=true, color=map(d -&gt; d == 1 ? :cyan : :magenta, dodge))\n\n\n\n\n\n\n7.4.3 Violin plot\nIt is similar to the box plot, however, the shape of each sample is represented by a mirrored kernel density estimate of the data.\n\nusing CairoMakie\n\ncategories = repeat(1:3, outer=300)\nv = randn(900)\n\nviolin(categories, v, color=:cyan, datalimits=extrema)\n\n\n\n\n\nusing CairoMakie\n\ncategories = repeat(1:3, inner=800)\ndodge = repeat(repeat(1:2, outer=3), inner=400)\nv = randn(2400)\n\nviolin(categories, v, dodge=dodge, color=map(d -&gt; d == 1 ? :cyan : :magenta, dodge), datalimits=extrema)\n\n\n\n\n\nusing CairoMakie\n\ncategories = repeat(1:3, inner=800)\nside = repeat(repeat([:left, :right], outer=3), inner=400)\nv = randn(2400)\n\nviolin(categories, v, side=side, color=map(d -&gt; d == :left ? :cyan : :magenta, side), datalimits=extrema)\n\n\n\n\n\n\n\n7.5 Plots for multivariate and high-dimensional data\nFor vectors of observations, \\((x_{11}, ..., x_{1p}), ..., (x_{n1}, ..., x_{np})\\), where \\(n\\) is the number of observations and \\(p\\) is the number of variables, or features. In case where \\(p\\) is large the data is called high dimensional.\n\n7.5.1 Scatter plot matrix\nIt consists of taking each possible pair of variables and plotting a scatter plot for that pair.\nObviously, with \\(p\\) variables, we need at least \\(\\frac{p^2-p}{2}\\) scatters.\n\nusing RDatasets, AlgebraOfGraphics, DataFrames, CairoMakie\n\ndf = dataset(\"datasets\", \"iris\")\n\nfeature_names = [\"Sepal Length\", \"Sepal Width\", \"Petal Length\", \"Petal Width\", \"Species\"]\n\nrename!(df, feature_names)\n\nfig = Figure(size=(1200, 1200))\nfor i in 1:4\n    for j in 1:4\n        scatter = data(df) * mapping(feature_names[i], feature_names[j], color=feature_names[5]) * visual(Scatter)\n        ax_scatter = Axis(fig[i, j],\n            xlabel=feature_names[i],\n            ylabel=feature_names[j])\n        grid = draw!(ax_scatter, scatter)\n        if i == 1 && j == 1\n            legend!(fig[i, j], grid; tellheight=false, tellwidth=false, halign=:left, valign=:top)\n        end\n    end\nend\nfig\n\n\n\n\n\n\n7.5.2 Heat map with marginals\nIn cases of pairs of observations \\((x_1, y_1), ..., (x_n, y_n)\\), the bivariate data can be constructed into a bivariate histogram (shown in the form of heat map in the 2D plane) in a manner similar to the univariate histogram. In addition, we can also add two marginal histograms beside the heat map, which are two separate histograms, one for \\(x_1, ..., x_n\\), and the other for \\(y_1, ..., y_n\\).\n\nusing Distributions, DataFrames, AlgebraOfGraphics, CairoMakie\n\nN = 10^6\nmeanVect = [27, 26]\ncovMat = [16 13; 13 12]\nbiNorm = MvNormal(meanVect, covMat)\nsimData = DataFrame(rand(biNorm, N)', [:x, :y])\n\nfig = Figure(size=(600, 600))\ngl = fig[1, 1] = GridLayout()\n\nax_x = Axis(gl[1, 1])\nhist!(ax_x, simData[!, :x], bins=50, normalization=:pdf)\n\nax_y = Axis(gl[2, 2])\nhist!(ax_y, simData[!, :y], bins=50, normalization=:pdf, direction=:x)\n\nfor ax in [ax_x, ax_y]\n    hidedecorations!(ax)\n    hidespines!(ax)\nend\n\nax_hm = Axis(gl[2, 1],\n    xlabel=\"x\",\n    ylabel=\"y\")\nhm = data(simData) * mapping(:x, :y) * AlgebraOfGraphics.density(npoints=50)\ngrid = draw!(ax_hm, hm)\ncolorbar!(gl[3, 1], grid; tellheight=true, tellwidth=true, vertical=false, flipaxis=false)\n\ncolgap!(gl, 0)\nrowgap!(gl, 0)\ncolsize!(gl, 2, Auto(0.25))\nrowsize!(gl, 1, Auto(0.25))\n\nfig\n\n\n\n\n\n\n\n7.6 Andrews plot\nThe idea of Andrews plot is to represent a data vector \\((x_{i1}, ..., x_{ip})\\) via a real-valued function. For any individual vector, such a transformation cannot be generally useful; however, when comparing groups of vectors, it may yield a way to visualize structural differences in the data.\nThe specific transformation rule that we present here creates a plot known as Andrews plot.\nHere, for the \\(i\\)-th data vector \\((x_{i1}, ..., x_{ip})\\), we create the function \\(f_i(\\cdot)\\) defined on \\([-\\pi, \\pi]\\) via,\n\\[\nf_i(t) = \\frac{x_{i1}}{\\sqrt{2}} + x_{i2}\\sin(t) + x_{i3}\\cos(t) + x_{i4}\\sin(2t) + x_{i5}\\cos(2t) + x_{i6}\\sin(3t) + x_{i7}\\cos(3t) + \\cdots\n\\]\nwith the last term involving a \\(\\sin()\\) if \\(p\\) is even and a \\(\\cos()\\) is \\(p\\) is odd. For \\(i = 1, ..., n\\), the functions \\(f_1(\\cdot), ..., f_n(\\cdot)\\) are plotted.\nIn cases where each \\(i\\) has an associated label from a small finite set, different colors or line patterns can be used.\n\nusing RDatasets, AlgebraOfGraphics, DataFrames, StatsBase, CairoMakie\n\nfunction gen_uni_str(n::Int; exclude_strs::Vector{String}=String[], iter_n::Int=1000)\n    alphabet = [collect('a':'z'); collect('A':'Z')]\n    num_underscore = [collect('0':'9'); \"_\"]\n\n    for i in 1:iter_n\n        uni_str = join([rand(alphabet, 1); rand([alphabet; num_underscore], n - 1)])\n        if uni_str .∉ Ref(exclude_strs)\n            return uni_str\n        end\n    end\n    error(\"cannot generate an unique string against the given arguments\")\nend\n\nfunction andrewsplot(df::DataFrame, features::Vector{String}; npoints::Int=100, scale::Bool=true)\n    if nrow(df) &lt; 1 || length(features) &lt; 1\n        error(\"both the data frame and features must have at least 1 element\")\n    end\n\n    if npoints &lt; 1\n        error(\"the npoints must be an integer greater than 0\")\n    end\n\n    tmp_df = transform(df, eachindex =&gt; \"row_number\")\n    transform!(tmp_df, :row_number =&gt; (x -&gt; string.(x)) =&gt; :row_number)\n    n_vars = length(features)\n\n    if scale\n        # scale each column to mean 0 and std 1\n        # to ensure that all features contribute equally to the shape of the curve\n        scaled_df = DataFrame(hcat([zscore(tmp_df[!, j]) for j in features]...), features)\n    else\n        scaled_df = tmp_df[!, features]\n    end\n\n    if iseven(n_vars)\n        placeholder_column_name = gen_uni_str(12; exclude_strs=features)\n        scaled_df[!, placeholder_column_name] = zeros(nrow(scaled_df))\n        n_vars = n_vars + 1\n    end\n\n    fvs = Vector{Float64}(undef, nrow(scaled_df) * npoints)\n    fvs_index_pairs = [[(i - 1) * npoints + 1, min(i * npoints, length(fvs))] for i in 1:Int(ceil(length(fvs) / npoints))]\n    ob_index_pairs = [[(i - 1) * 2 + 1, min(i * 2, n_vars - 1)] for i in 1:Int(ceil((n_vars - 1) / 2))]\n    f_range = collect(range(-π, π; length=npoints))\n    for i in 1:nrow(scaled_df)\n        ob = Vector(scaled_df[i, :])\n        f_it0 = popfirst!(ob) / √2\n        for j in eachindex(f_range)\n            t = f_range[j]\n            f_it = f_it0\n            for multiplier in 1:length(ob_index_pairs)\n                x1, x2 = ob[ob_index_pairs[multiplier]]\n                f_it = f_it + x1 * sin(multiplier * t) + x2 * cos(multiplier * t)\n            end\n            fvs[fvs_index_pairs[i][1]+j-1] = f_it\n        end\n    end\n\n    fvs_df = DataFrame(andrew_plot_x=repeat(f_range; outer=nrow(scaled_df)),\n        andrew_plot_y=fvs,\n        row_number=repeat(1:nrow(scaled_df); inner=npoints))\n    transform!(fvs_df, :row_number =&gt; (x -&gt; string.(x)) =&gt; :row_number)\n    return innerjoin(tmp_df, fvs_df; on=:row_number, renamecols=\"_raw\" =&gt; \"_new\")\nend\n\niris = dataset(\"datasets\", \"iris\")\nfeatures = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]\ndf = andrewsplot(iris, features; scale=false)\np = data(df) * mapping(:andrew_plot_x_new, :andrew_plot_y_new; group=:row_number, color=:Species_raw) * visual(Lines)\ndraw(p; figure=(size=(800, 500),))\n\n\n\n\n\n\n7.7 Plots for the board room\n\n7.7.1 Pie chart\nUsed to convey relative proportions.\n\nusing CairoMakie\n\nd = [36, 12, 68, 5, 42, 27]\ncolors = [:yellow, :orange, :red, :blue, :purple, :green]\n\npie(d,\n    color=colors,\n    radius=4,  # the radius of the pie plot\n    inner_radius=2,  # the inner radius between 0 and radius to create a donut chart\n    strokecolor=:white,\n    strokewidth=5,\n    axis=(autolimitaspect=1,),\n)\n\n\n\n\nNote: introduction to two Axis() parameters:\n\naspect=nothing: defined as the axis aspect ratio of the width over height.\n\nThis will change the size of the axis.\nIf you set it to DataAspect(), the axis aspect ratio width/heigth will matches that of the data limits.\nFor example, if the x limits range from 0 to 300 and the y limits from 100 to 250, then DataAspect() will result in an aspect ratio of (300 - 0) / (250 - 100) = 2. This can be useful when plotting images, because the image will be displayed unsquished.\nAxisAspect(ratio) reduces the effective axis size within the available layout space so that the axis aspect ratio width/height matches ratio.\n\nautolimitaspect=nothing: the ratio of the limits to the axis size equals that number.\n\nFor example, if the axis size is \\(100\\times 200\\), then with autolimitaspect=1, the autolimits will also have a ratio of 1 to 2.\n\nusing CairoMakie\n\npie([π / 2, 2π / 3, π / 4],\n    normalize=false,\n    offset=π / 2,\n    color=[:orange, :purple, :green],\n    axis=(autolimitaspect=1,),\n)\n\n\n\n\n\n\n7.7.2 Bar plot\nUsed to convey relative proportions.\n\nusing CSV, DataFrames, AlgebraOfGraphics, CairoMakie, CategoricalArrays\n\ndf = CSV.read(\"./data/companyData.csv\", DataFrame)\ndf[!, \"Year\"] = categorical(df[!, \"Year\"])\ndf[!, \"Type\"] = categorical(df[!, \"Type\"]; levels=[\"C\", \"B\", \"A\"])\n\np = data(df) * mapping(:Year, :MarketCap; color=:Type, stack=:Type) * visual(BarPlot)\ndraw(p)\n\n\n\n\n\nusing CSV, DataFrames, AlgebraOfGraphics, CairoMakie\n\ndf = CSV.read(\"./data/companyData.csv\", DataFrame)\n\np = data(df) * mapping(:Year, :MarketCap; color=:Type, dodge=:Type) * visual(BarPlot)\ndraw(p)\n\n\n\n\n\n\n7.7.3 Stack plot\nShow how constituent amounts of a metric change over time.\n\nusing CSV, DataFrames, AlgebraOfGraphics, CairoMakie, CategoricalArrays\n\nfunction areaplot(df::DataFrame, x::AbstractString, y::AbstractString, group::AbstractString)\n    if nrow(df) == 0\n        error(\"the data frame is empty\")\n    end\n\n    tmp_df = groupby(df[:, [x, y, group]], group)\n    final_df = DataFrame([[], [], [], []], [x, y, group, \"row_number\"])\n    for i in 1:length(tmp_df)\n        sort!(tmp_df[i], x; rev=false)\n        transform!(tmp_df[i], eachindex =&gt; :row_number)\n        if i == 1\n            sub_tmp_df = copy(tmp_df[i])\n            sub_tmp_df[!, y] = repeat([0], nrow(sub_tmp_df))\n        else\n            sub_tmp_df = copy(tmp_df[i-1])\n            sub_tmp_df[!, group] = tmp_df[i][:, group]\n            tmp_df[i][!, y] = tmp_df[i][!, y] .+ sub_tmp_df[!, y]\n        end\n        final_df = vcat(final_df, sort(sub_tmp_df, x; rev=false), sort(tmp_df[i], x; rev=true))\n    end\n    transform!(final_df, Cols(:row_number, y) =&gt; ByRow(((x, y) -&gt; (x, y))) =&gt; :Point)\n\n    return final_df\nend\n\ndf = CSV.read(\"./data/companyData.csv\", DataFrame)\ndf[!, \"Year\"] = categorical(df[!, \"Year\"])\ndf[!, \"Type\"] = categorical(df[!, \"Type\"])\nx, y, group = \"Year\", \"MarketCap\", \"Type\"\nfinal_df = areaplot(df, x, y, group)\n\np = data(final_df) * mapping(:Point; color=:Type) * visual(Poly)\ndraw(p)\n\n\n\n\n\n\n\n7.8 Working with files and remote servers"
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#statistical-inference-concepts",
    "href": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#statistical-inference-concepts",
    "title": "Probability and statistics with Julia",
    "section": "8 Statistical inference concepts",
    "text": "8 Statistical inference concepts\nThe statistical inference concepts involve using mathematical techniques to make conclusions about unkown population parameters based on collected data.\nThe analyses and methods of statistical inference can be categorized into:\n\nFrequentist (classical): based on the assumption that population parameters of some underlying distribution, or probability law, exist and are fixed, but are yet unknown. The process of statistical inference then deals with making conclusions about these parameters based on sampled data.\nBayesian: only assumes that there is a prior distribution of the parameters. The key process deals with analyzing a posterior distribtution of the parameters.\nMachine learning.\n\nIn general, a statistical inference process involves data, model, and analysis. The data is assumed to be comprised of random samples from the model. The goal of the analysis is to make informed statements about population parameters of the model based on the data.\nSuch statements typically take one of the following forms:\n\nPoint estimation: determination of a single value (or vector of values) representing a best estimate of the parameter/parameters.\nConfidence intervals: determination of a range of values where the parameter lies. Under the model and the statistical process used, it is guaranteed that the parameter lies within this range with a pre-specified probability.\nHypothesis tests: the process of determining if the parameter lies in a given region, in the complement of that region, or fails to take on a specific value.\n\n\n8.1 A random sample\nWhen carrying out frequentist statistical inference, we assume that there is some underlying distribution \\(F(x; \\theta)\\) from which we are sampling, where \\(\\theta\\) is the scalar or vector-valued unknown parameter we wish to know.\nWe assume that each observation is statistically independent and identically distributed as the rest. That is, from a probablistic perspective, the observations are taken as independent and identically distributed (i.i.d) random variables. In mathematical statistics, this is called a random sample. We denote the random variables of the observations by \\(X_1, ..., X_n\\), and their respective values by \\(x_1, ..., x_n\\).\nTypically, we compute statistics from the random sample, such as the sample mean and sample variance. We can consider each observation as a random variable, so these statistics are random variables too.\n\\[\n\\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\\ \\ \\ \\ \\text{and}\\ \\ \\ \\ S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X-\\overline{X})^2\n\\]\nFor \\(S^2\\), we use \\(n-1\\), which makes \\(S^2\\) an unbiased estimator of the population variance.\nHere, we consider the sample statistics, such as the sample mean and sample variance, as random variables. This means that these statistics also subject to some underlying distributions. To know what distribution each statistics subject to is the first step to do statistical inference.\n\n\n8.2 Sampling from a normal population\nWe often assume that the distribution we sample from is a normal distribution (i.e. \\(F(x; (\\mu, \\sigma^2))\\)).\nUnder the normality assumption, the distribution of the random variables \\(\\overline{X}\\) and \\(S^2\\) as well as transformations of them are well known:\n\\[\n\\begin{align}\n\\overline{X} &\\backsim N(\\mu, \\frac{\\sigma^2}{n}) \\\\\n\\frac{(n-1)S^2}{\\sigma^2} &\\backsim \\chi^2_{n-1} \\\\\nT := \\frac{\\overline{X}-\\mu}{S/\\sqrt{n}} &\\backsim t_{n-1}\n\\end{align}\n\\]\nThe notations \\(\\chi^2_{n-1}\\) and \\(t_{n-1}\\) denote a chi-squared distribution and a student T-distribution, respectively.\n\n\n8.3 Independence of the sample mean and sample variance\nIn many cases, the sample mean and sample variance calculated from the same sample group are not independent, but in the special case where the samples \\(X_1, ..., X_n\\) are from a normal distribution, independence between \\(\\overline{X}\\) and \\(S^2\\) holds. In fact, this property characetrizes the normal distribution - that is, this property only holds for the normal distribution.\n\nusing Distributions, CairoMakie, Random, DataFrames\n\nRandom.seed!(1234)\n\nfunction mean_var(dist, n)\n    sample = rand(dist, n)\n    (mean(sample), var(sample))\nend\n\nuni_dist = Uniform(-sqrt(3), sqrt(3))\nn, N = 3, 10^5\n\n# the sample mean and sample variance are calculated from the same sample group\n# so the two are not independent\ndata_uni = DataFrame([mean_var(uni_dist, n) for _ in 1:N], [:mean, :var])\n# the sample mean and sample variance are calculated from two different sample groups\n# so the two are independent\ndata_uni_ind = DataFrame([(mean(rand(uni_dist, n)), var(rand(uni_dist, n))) for _ in 1:N], [:mean, :var])\n\nfig, ax = scatter(data_uni.mean, data_uni.var; color=:blue, label=\"Same group\", markersize=2)\nscatter!(ax, data_uni_ind.mean, data_uni_ind.var; color=:orange, label=\"Separate group\", markersize=2)\nax.xlabel = L\"\\overline{X}\"\nax.ylabel = L\"S^2\"\nax.title = \"Uniform Distribution\"\naxislegend(ax)\nfig\n\n\n\n\n\n# in the case where we sample from the normal distribution\n# the sample mean and sample variance are always independent\n# independent of the way we calculate them i.e., from the same sample group or from two different sample groups\ndata_norm = DataFrame([mean_var(Normal(), n) for _ in 1:N], [:mean, :var])\ndata_norm_ind = DataFrame([(mean(rand(Normal(), n)), var(rand(Normal(), n))) for _ in 1:N], [:mean, :var])\n\nfig, ax = scatter(data_norm.mean, data_norm.var; color=:blue, label=\"Same group\", markersize=2)\nscatter!(ax, data_norm_ind.mean, data_norm_ind.var; color=:orange, label=\"Separate group\", markersize=2)\nax.xlabel = L\"\\overline{X}\"\nax.ylabel = L\"S^2\"\nax.title = \"Normal Distribution\"\naxislegend(ax)\nfig\n\n\n\n\n\n\n8.4 T-Distribution\nThe random variable T-statistic is given by\n\\[\nT = \\frac{\\overline{X}-\\mu}{S/\\sqrt{n}} \\backsim t_{n-1}\n\\]\nDenoting the mean and variance of the normally distributed observations by \\(\\mu\\) and \\(\\sigma^2\\), respectively, we can represent the T-statistic as\n\\[\nT = \\frac{\\frac{\\overline{X}-\\mu}{\\sigma/\\sqrt{n}}}{\\sqrt{\\frac{(n-1)S^2}{\\sigma^2}\\frac{1}{n-1}}} = \\frac{Z}{\\sqrt{\\frac{\\chi^2_{n-1}}{n-1}}}\n\\]\nHere, the numerator \\(Z\\) is a standard normal random variable, and in the denominator the random variable \\(\\chi^2_{n-1} = (n-1)S^2/\\sigma^2\\) is chi-distributed wit \\(n-1\\) degrees of freedom. Furthermore, the numerator and denominator random variables are independent because they are based on the sample mean and sample variance, respectively.\nHence, \\(T \\backsim t(n-1)\\), which means a “T-Distribution with \\(n-1\\) degrees of freedom”.\nHere, we check the above fact that T-statistic is derived from two independent random variables (the numerator is a standard normal random variable, while the denominator is a random variable chi-distributed with \\(n-1\\) degrees of freedom):\n\nusing Random, StatsBase, Distributions, CairoMakie\n\nRandom.seed!(0)\n\nfunction tStat(degree)\n    z = rand(Normal())\n    c = rand(Chisq(degree))\n    z / sqrt(c / degree)\nend\n\nn, N = 10, 10^6\n\nsimulationTStats = [tStat(n - 1) for _ in 1:N]\n\nxGrid = -5:0.01:5\n\nfig, ax = stephist(simulationTStats; bins=400, color=:blue, label=\"Simulated\", normalization=:pdf)\nlines!(ax, xGrid, pdf.(TDist(n - 1), xGrid); color=:red, label=\"Analytical\")\nax.limits = (first(xGrid), last(xGrid), nothing, nothing)\nfig\n\n\n\n\nA T-Distribution with \\(k\\) degrees of freedom can be shown to have a density function,\n\\[\nf(x) = \\frac{\\Gamma(\\frac{k+1}{2})}{\\sqrt{k\\pi} \\Gamma(\\frac{k}{2})} \\left(1+\\frac{x^2}{k}\\right)^{-\\frac{k+1}{2}}\n\\]\nNote that \\(E(\\chi^2_{n-1}) = n-1\\) and \\(Var(\\chi^2_{n-1}) = 2(n-1)\\), so \\(E\\left(\\frac{\\chi^2_{n-1}}{n-1}\\right) = 1\\), and \\(Var(\\frac{\\chi^2_{n-1}}{n-1}) = \\frac{2}{n-1}\\).\nTherefore, we have \\(\\frac{\\chi^2_{n-1}}{n-1} \\rightarrow 1\\) as \\(n \\rightarrow \\infty\\), with the same holding for \\(\\sqrt{\\frac{\\chi^2_{n-1}}{n-1}}\\).\nHence, for large \\(n\\), the distribution of \\(T\\) will converge to the distribution of \\(Z\\).\n\nusing Distributions, Random, CairoMakie, DataFrames\n\nRandom.seed!(1234)\n\nn, N, alpha = 3, 10^7, 0.1\n\nmyT(n) = rand(Normal()) / sqrt(rand(Chisq(n - 1)) / (n - 1))\nmcQuantile = quantile([myT(n) for _ in 1:N], alpha)\nanalyticQuantile = quantile(TDist(n - 1), alpha)\n\nprintln(\"Quantile from Monte Carlo: \", mcQuantile)\nprintln(\"Analytic quantile: \", analyticQuantile)\n\nxGrid = -5:0.1:5\n\nfig = Figure()\nax = fig[1, 1] = Axis(fig)\n\nlines!(ax, xGrid, pdf.(Normal(), xGrid), label=\"Normal\", color=:red)\nscatter!(ax, xGrid, pdf.(TDist(1), xGrid), label=\"DOF = 1\", color=:blue)\nscatter!(ax, xGrid, pdf.(TDist(5), xGrid), label=\"DOF = 5\", color=:purple)\nscatter!(ax, xGrid, pdf.(TDist(10), xGrid), label=\"DOF = 10\", color=:orange)\nscatter!(ax, xGrid, pdf.(TDist(100), xGrid), label=\"DOF = 100\", color=:green)\n\naxislegend(ax)\n\nfig\n\nQuantile from Monte Carlo: -1.8845517968939285\nAnalytic quantile: -1.8856180831641263\n\n\n\n\n\n\n\n8.5 Two samples and the F-Distribution\nMany statistical procedures involve the ratio of sample variances, or similar quantities, for two or more samples.\nFor example, if \\(X_1, ..., X_{n_1}\\) is one sample, and \\(Y_1, ..., Y_{n_2}\\) is another sample, and both samples are distributed normally with the same parameters, then the ratio of the two sample variances\n\\[\nF = \\frac{S_X^2}{S_Y^2}\n\\]\nIt turns out such a statistic distributed as the F-Distribution, with density given by\n\\[\nf(x) = K(a, b) \\frac{x^{\\frac{a}{2}-1}}{(ax+b)^{\\frac{a+b}{2}}}\\ \\ \\ \\ \\text{with}\\ \\ \\ \\ K(a, b) = \\frac{\\Gamma(\\frac{a+b}{2}) a^{\\frac{a}{2}} b^{\\frac{b}{2}}}{\\Gamma(\\frac{a}{2}) \\Gamma(\\frac{b}{2})}\n\\]\nHere, the parameters \\(a\\) and \\(b\\) are the numerator degrees of freedom and denominator degrees of freedom, respectively.\n\nusing Distributions, CairoMakie\n\nn1, n2 = 10, 15\nN = 10^6\nmu, sigma = 10, 4\nnorm_dist = Normal(mu, sigma)\n\nfvs = Array{Float64}(undef, N)\n\nfor i in 1:N\n    d1 = rand(norm_dist, n1)\n    d2 = rand(norm_dist, n2)\n    fvs[i] = var(d1) / var(d2)\nend\n\nf_range = 0:0.1:5\nfig, ax = stephist(fvs, bins=400, color=:blue, label=\"Simulated\", normalization=:pdf)\nlines!(ax, f_range, pdf.(FDist(n1 - 1, n2 - 1), f_range), color=:red, label=\"Analytic\")\nxlims!(ax, low=0, high=5)\naxislegend(ax)\nfig\n\n\n\n\n\n\n8.6 The central limit theorem\nThe Central Limit Theorem (CLT) indicates that summations of a large number of independent random quantities, each with finite variance, yield a sum that is approximately normally distributed.\nThis is why the normal distribution is ubiquitous in nature.\nConsider an i.i.d sequence \\(X_1, X_2, ...\\), where all \\(X_i\\) are distributed according to some distribution \\(F(x_i; \\theta)\\) with mean \\(\\mu\\) and finite variance \\(\\sigma^2\\).\nThen consider the random variable\n\\[\nY_n := \\sum_{i=1}^n X_i\n\\]\nIt is clear that \\(E(Y_n) = n\\mu\\) and \\(Var(Y_n) = n\\sigma^2\\).\nHence, we may consider a random variable\n\\[\n\\widetilde{Y}_n := \\frac{Y_n - n\\mu}{\\sqrt{n}\\sigma}\n\\]\nObserve that \\(\\widetilde{Y}_n\\) is zero mean and unit variance. The CLT states that as \\(n \\rightarrow \\infty\\), the ditribution of \\(\\widetilde{Y}_n\\) converges to a standard normal distribution. That is, for every \\(x \\in R\\),\n\\[\n\\lim_{n \\rightarrow \\infty} P(\\widetilde{Y}_n \\le x) = \\int_{-\\infty}^x \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{u^2}{2}} du\n\\]\nAlternatively, this may be viewed as indicating that for non-small \\(n\\)\n\\[\nY_n\\ \\ \\widetilde{\\text{approx}}\\ \\ N(n\\mu, n\\sigma^2)\n\\]\nIn addition, we have\n\\[\n\\overline{Y}_n = \\frac{Y_n}{n}\\ \\ \\widetilde{\\text{approx}}\\ \\ N(\\mu, \\frac{\\sigma^2}{n})\n\\]\nThis means that sample means from i.i.d samples with finite variances are asymptotically distributed according to a normal distribution as the sample size grows.\n\nusing Distributions, Random, CairoMakie\n\nRandom.seed!(1234)\n\n# note that n = 30 isn't enough to get a perfect fit to a normal distribution in the case of exponential distribution\nn, N = 30, 10^6\n\ndist1 = Uniform(1 - sqrt(3), 1 + sqrt(3))\ndist2 = Exponential(1)\ndist3 = Normal(1, 1)\n\ndata1 = [mean(rand(dist1, n)) for _ in 1:N]\ndata2 = [mean(rand(dist2, n)) for _ in 1:N]\ndata3 = [mean(rand(dist3, n)) for _ in 1:N]\n\nfig, ax = stephist(data1, bins=100, color=:blue, label=\"Average of Uniforms\", normalization=:pdf)\nstephist!(ax, data2, bins=100, color=:orange, label=\"Average of Exponentials\", normalization=:pdf)\nstephist!(ax, data3, bins=100, color=:green, label=\"Average of Normals\", normalization=:pdf)\nlines!(ax, 0:0.01:2, pdf.(Normal(1, 1 / sqrt(n)), 0:0.01:2), color=:red, label=\"Analytic Normal Distribution\")\naxislegend(ax)\nfig\n\n\n\n\n\n\n8.7 Point estimation\nGiven a random sample, \\(X_1, ..., X_n\\), a common task of statistical inference is to estimate a parameter \\(\\theta\\), or a function of it, say \\(h(\\theta)\\).\nThe process of designing an estimator, analyzing its performance, and carrying out the estimation is called point estimation.\nAlthough we can never know the underlying parameter \\(\\theta\\), or \\(h(\\theta)\\) exactly, we can arrive at an estimate for it via an estimator \\(\\hat{\\theta} = f(X_1, ..., X_n)\\). Here, the design of the estimator is embodied by \\(f(\\cdot)\\), a function that specifies how to construct the estimate from the sample.\nWhen performing point estimation, the first question we must answer is how close is \\(\\hat{\\theta}\\) to the actual unknown quantity \\(\\theta\\) or \\(h(\\theta)\\)?\n\n8.7.1 Describing the performance and behavior of estimators\nWhen analyzing the performance of an estimator \\(\\hat{\\theta}\\), it is important to understand that it is a random variable.\nOne common measure of its performance is the Mean Squared Error (MSE),\n\\[\n\\begin{align}\nMSE_\\theta(\\hat{\\theta}) &:= E[(\\hat{\\theta}-\\theta)^2] \\\\\n&= E(\\hat{\\theta}^2-2\\hat{\\theta}\\theta+\\theta^2) \\\\\n&= E(\\hat{\\theta}^2) - 2\\theta E(\\hat{\\theta}) + \\theta^2 \\\\\n&= E(\\hat{\\theta}^2) - [E(\\hat{\\theta})]^2 + [E(\\hat{\\theta})]^2 - 2\\theta E(\\hat{\\theta}) + \\theta^2 \\\\\n&= Var(\\hat{\\theta}) + (E(\\hat{\\theta}) - \\theta)^2 \\\\\n&:= variance + bias^2\n\\end{align}\n\\]\nHere, the MSE can be decomposed into the variance of the estimator and its bias squared.\n\nThe variance of the estimator represents the dispersion degree of the estimator itself. Low variance is clearly a desirable performance measure. This indicates the stability of the estimator.\nThe bias squared represents whether the estimator \\(\\hat{\\theta}\\) is an unbiased estimator of the parameter \\(\\theta\\) or \\(h(\\theta)\\). This indicates how close is the \\(E(\\hat{\\theta})\\) to \\(\\theta\\) or \\(h(\\theta)\\).\n\nThis can be illustrated by the folllowing plot:\n\nusing Distributions, CairoMakie, Random\n\nRandom.seed!(1234)\n\nest_pts = rand(Normal(3, 1), 10)\n\nfig = Figure()\nax = Axis(fig[1, 1])\n\nscatter!(repeat([0], 10), est_pts; color=:black, markersize=10, label=L\"\\hat{\\theta}\")\nscatter!(0, mean(est_pts); label=L\"E(\\hat{\\theta})\", color=:cyan, markersize=20)\nscatter!(0, 10; color=:red, markersize=20, label=L\"\\theta\")\n\nbracket!(0, mean(est_pts), 0, 10; text=L\"(E(\\hat{\\theta})-\\theta)^2\", offset=20, style=:square, orientation=:up)\nbracket!(0, minimum(est_pts), 0, maximum(est_pts); text=L\"Var(\\hat{\\theta})\", offset=20, style=:square, orientation=:down)\n\naxislegend(ax)\nfig\n\n\n\n\nCertainly, we are really interested in whether an estimator is unbiased, and then how low the variance of the estimator is.\nWhether an estimator is unbiased means that \\(E(\\hat{\\theta}) = \\theta\\).\nHere, we give some examples:\nConsider \\(X_1, ..., X_n\\) distributed according to any distribution with a finite mean \\(\\mu\\).\n\nThe sample mean \\(\\overline{X}\\) is an unbiased estimator of the population mean \\(\\mu\\):\n\n\\[\n\\begin{align}\nE(\\overline{X}) &= E\\left[\\frac{1}{n} \\sum_{i=1}^n X_i\\right] \\\\\n&= \\frac{1}{n} \\sum_{i=1}^n E(X_i) \\\\\n&= \\frac{1}{n} n\\mu \\\\\n&= \\mu\n\\end{align}\n\\]\n\\[\n\\begin{align}\nVar(\\overline{X}) &= Var\\left(\\frac{1}{n} \\sum_{i=1}^n X_i\\right) \\\\\n&= \\frac{1}{n^2} \\sum_{i=1}^n Var(X_i) \\\\\n&= \\frac{1}{n^2} n\\sigma^2 \\\\\n&= \\frac{\\sigma^2}{n}\n\\end{align}\n\\]\nSo the sample mean \\(\\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\\) is an unbiased estimator of the population mean \\(\\mu\\) with the variance \\(\\frac{\\sigma^2}{n}\\).\n\nIn the case where the population mean \\(\\mu\\) is known, but the population variance \\(\\sigma^2\\) is unknown, then \\(\\hat{\\sigma^2} := \\frac{1}{n} \\sum_{i=1}^n (X_i-\\mu)^2\\) is an unbiased estimator of the population variance \\(\\sigma^2\\), but \\(\\hat{\\sigma} := \\sqrt{\\hat{\\sigma^2}}\\) is not an unbiased estimator of \\(\\sigma\\) (in fact, \\(\\hat{\\sigma}\\) is asymptotically unbiased. That is, the bias tends to \\(0\\) as the sample size grows):\n\n\\[\n\\begin{align}\nE(\\hat{\\sigma^2}) &= E\\left(\\frac{1}{n} \\sum_{i=1}^n (X_i-\\mu)^2\\right) \\\\\n&= \\frac{1}{n} \\sum_{i=1}^n E\\left((X_i-\\mu)^2\\right) \\\\\n&= \\frac{1}{n} n\\sigma^2 \\\\\n&= \\sigma^2\n\\end{align}\n\\]\nSo in the case where the population mean \\(\\mu\\) is known, \\(\\hat{\\sigma^2}\\) is an unbiased estimator of \\(\\sigma^2\\), but \\(\\hat{\\sigma}\\) is not an unbiased estimator of \\(\\sigma\\).\n\nusing Random, Statistics\n\nRandom.seed!(1234)\n\n# consider an uniform distribution over [0, 1]\ntrueVar, trueStd = 1 / 12, sqrt(1 / 12)\n\nfunction estVar(n)\n    sample = rand(n)\n    sum((sample .- 0.5) .^ 2) / n\nend\n\nN = 10^7\nfor n in 10:20:90\n    biasVar = mean([estVar(n) for _ in 1:N]) - trueVar\n    biasStd = mean([sqrt(estVar(n)) for _ in 1:N]) - trueStd\n    println(\"n = \", n, \" Var bias: \", round(biasVar; digits=6),\n        \"\\t Std bias: \", round(biasStd; digits=5))\nend\n\nn = 10 Var bias: -4.0e-6     Std bias: -0.00304\nn = 30 Var bias: -3.0e-6     Std bias: -0.00098\nn = 50 Var bias: 3.0e-6  Std bias: -0.00058\nn = 70 Var bias: 4.0e-6  Std bias: -0.00042\nn = 90 Var bias: -1.0e-6     Std bias: -0.00032\n\n\n\nIn the case where the population mean \\(\\mu\\) is not known, the sample variance \\(S^2 := \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\overline{X})^2\\) is an unbiased estimator of \\(\\sigma^2\\):\n\n\\[\n\\begin{align}\n\\sum_{i=1}^{n}(x_i-\\bar{x})^2 &= \\sum_{i=1}^{n}(x_i^2-2x_i\\bar{x}+\\bar{x}^2) \\\\\n&= \\sum_{i=1}^{n}x_i^2 - 2n\\bar{x}\\frac{1}{n}\\sum_{i=1}^{n}x_i + n\\bar{x}^2 \\\\\n&= \\sum_{i=1}^{n}x_i^2 - n\\bar{x}^2\n\\end{align}\n\\]\n\\[\nE(X^2) = Var(X) + [E(X)]^2 = \\sigma^2 + \\mu^2\n\\]\n\\[\n\\begin{align}\nE(S^2) &= E\\left(\\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\overline{X})^2\\right) \\\\\n&= \\frac{1}{n-1}E\\left(\\sum_{i=1}^{n}X_i^2 - n\\overline{X}^2\\right) \\\\\n&= \\frac{1}{n-1}\\left(\\sum_{i=1}^{n}E(X_i^2) - nE(\\overline{X}^2)\\right) \\\\\n&= \\frac{1}{n-1}\\left(n(\\sigma^2+\\mu^2) - n(\\frac{\\sigma^2}{n}+\\mu^2)\\right) \\\\\n&= \\frac{1}{n-1} (n-1)\\sigma^2 \\\\\n&= \\sigma^2\n\\end{align}\n\\]\nIn summary, we can evaluate the performance and behavior of an estimator from different aspects, such as unbias (\\(E(\\hat{\\theta}) = \\theta\\)), effectiveness (\\(Var(\\hat{\\theta})\\) is as small as possible), consistency (an estimator is consistent if it converges to the true value as the number of observations grows to infinity), etc.\n\n\n8.7.2 Designing estimators\n\n8.7.2.1 Method of moments\nThe key idea is that the \\(k\\)’s moment estimator calculated from the random sample should be equal to the \\(k\\)’s moment of the underlying distribution from which we sample (i.e. \\(\\hat{m}_k = m_k\\)). Then we can obtain parameter estimates for a distribution.\n\\[\n\\hat{m}_k = \\frac{1}{n} \\sum_{i=1}^{n}X_i^k\n\\]\n\\[\nm_k = E(X^k) = \\begin{cases}\n\\sum_{i=1}^{\\infty} x_i p(x_i) &\\text{for discrete case} \\\\\n\\int_{-\\infty}^{\\infty} x p(x) dx &\\text{for continuous case}\n\\end{cases}\n\\]\nIn cases where there are multiple unkown parameters, say \\(K\\), we use the first \\(K\\) moment estimates to formulate a system of \\(K\\) equations and \\(K\\) unkowns. This system of equations can be written as \\(E[X^k; \\theta_1, ..., \\theta_K] = \\hat{m}_k\\ \\ \\ \\ \\text{for}\\ \\ \\ \\ k=1,...,K\\).\n\nusing Random, Distributions, NLsolve\n\nRandom.seed!(1234)\n\n# Triangular distribution\na, b, c = 3, 5, 4\ndist = TriangularDist(a, b, c)\nn = 2000\nsamples = rand(dist, n)\n\nm_k(k, data) = 1 / n * sum(data .^ k)\nmHats = [m_k(i, samples) for i in 1:3]\n\nfunction equations(F, x)\n    F[1] = 1 / 3 * (x[1] + x[2] + x[3]) - mHats[1]\n    F[2] = 1 / 6 * (x[1]^2 + x[2]^2 + x[3]^2 +\n                    x[1] * x[2] + x[1] * x[3] + x[2] * x[3]) - mHats[2]\n    F[3] = 1 / 10 * (x[1]^3 + x[2]^3 + x[3]^3 +\n                     x[1]^2 * x[2] + x[1]^2 * x[3] + x[2]^2 * x[1] +\n                     x[2]^2 * x[3] + x[3]^2 * x[1] + x[3]^2 * x[2] +\n                     x[1] * x[2] * x[3]) - mHats[3]\nend\n\nnlOutput = nlsolve(equations, [0.1, 0.1, 0.1])\nsol = sort(nlOutput.zero)\naHat, bHat, cHat = sol[1], sol[3], sol[2]\nprintln(\"Found estimates for (a, b, c) = \", (aHat, bHat, cHat), \"\\n\")\nprintln(nlOutput)\n\nFound estimates for (a, b, c) = (3.0233820362818355, 5.003274273506214, 4.0251075704074575)\n\nResults of Nonlinear Solver Algorithm\n * Algorithm: Trust-region with dogleg and autoscaling\n * Starting Point: [0.1, 0.1, 0.1]\n * Zero: [3.0233820362818355, 5.003274273506214, 4.0251075704074575]\n * Inf-norm of residuals: 0.000000\n * Iterations: 13\n * Convergence: true\n   * |x - x'| &lt; 0.0e+00: false\n   * |f(x)| &lt; 1.0e-08: true\n * Function Calls (f): 14\n * Jacobian Calls (df/dx): 13\n\n\n\n\n8.7.2.2 Maximum likelihood estimation (MLE)\nThe key is to consider the likelihhod of the parameter \\(\\theta\\) having a specific value given observations \\(x_1, ..., x_n\\). This is done via the likelihood function,\n\\[\nL(\\theta; x_1, ..., x_n) = f_{X_1, ..., X_n}(x_1, ..., x_n; \\theta)\n\\]\nIf \\(X_1, ..., X_n\\) are i.i.d., where the joint PDF of \\(X_1, ..., X_n\\) is represented as the product of the individual PDF, then we have\n\\[\nL(\\theta; x_1, ..., x_n) = f_{X_1, ..., X_n}(x_1, ..., x_n; \\theta) = \\prod_{i=1}^n f(x_i; \\theta)\n\\]\nNow given the likelihood function, the maximum likelihood estimator is a value \\(\\theta\\) that maximizes \\(L(\\theta; x_1, ..., x_n)\\). So an MLE is the maximizer of the likelihood.\n\nusing Random, Distributions, CairoMakie\n\nRandom.seed!(1234)\n\nrealAlpha, realLambda = 2, 3\ngammaDist = Gamma(realAlpha, 1 / realLambda)\n\nn = 10^2\nsamples = rand(gammaDist, n)\n\nalphaGrid = collect(1:0.02:3)\nlambdaGrid = collect(1:0.02:5)\n\nlikelihood = [prod(pdf.(Gamma(a, 1 / l), samples)) for a in alphaGrid, l in lambdaGrid]\n\nsurface(alphaGrid, lambdaGrid, likelihood, axis=(type=Axis3,))\n\n\n\n\nObserve that any maximizer \\(\\hat{\\theta}\\) of \\(L(\\theta; x_1, ..., x_n)\\) will also maximize its logarithm. Practically, both from an analytic and numerical perspective, considering this \\(log-likelihood function\\) is often more attractive:\n\\[\nl(\\theta; x_1, ..., x_n) := \\log L(\\theta; x_1, ..., x_n) = \\sum_{i=1}^{n}\\log \\left(f(x_i; \\theta)\\right)\n\\]\nNote: the second equality holds only for i.i.d. \\(X_1, ..., X_n\\).\nHence, given a sample from a gamma distribution, the log-likelihood function is\nFirst, the PDF of the gamma distribution is\n\\[\nf(x) = \\frac{\\lambda^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1}e^{-\\lambda x}\n\\]\nwith parameters \\(\\lambda &gt; 0\\) and \\(\\alpha &gt; 0\\).\n\\[\nl(\\theta; x_1, ..., x_n) = n\\alpha\\log(\\lambda) - n\\log(\\Gamma(\\alpha)) + (\\alpha - 1)\\sum_{i=1}^{n}\\log(x_i) - \\lambda\\sum_{i=1}^{n}x_i\n\\]\nDivide by \\(n\\) to obtain the following function that needs to be maximized:\n\\[\n\\tilde{l}(\\theta; \\bar{x}, \\bar{x}_l) = \\alpha\\log(\\lambda) - \\log(\\Gamma(\\alpha)) + (\\alpha - 1)\\bar{x}_l - \\lambda \\bar{x}\n\\]\nwhere \\(\\bar{x}\\) is the sample mean, and \\(\\bar{x}_l := \\frac{1}{n}\\sum_{i=1}^{n}\\log(x_i)\\).\nFurther simplification is possible by removing the stand-alone \\(-\\bar{x}_l\\) term, as it does not affect the optimal value. Heance, our optimization problem is then,\n\\[\n\\max_{\\lambda &gt; 0, \\alpha &gt; 0} \\alpha (\\log(\\lambda + \\bar{x}_l)) - \\log(\\Gamma(\\alpha)) - \\lambda \\bar{x}\n\\]\nAs is typical in such cases, the function actually depends on the sample only through the two sufficient statistics \\(\\bar{x}\\) and \\(\\bar{x}_l\\).\nThen, taking \\(\\alpha\\) as fixed, we may consider the derivative with respect to \\(\\lambda\\), and equate this to \\(0\\):\n\\[\n\\frac{\\alpha}{\\lambda} - \\bar{x} = 0\n\\]\nHence, for any optimal \\(\\alpha^\\star\\), we have \\(\\lambda = \\frac{\\alpha}{\\bar{x}}\\). This allows us to substitute \\(\\lambda^\\star\\) for \\(\\lambda\\) to obtain\n\\[\n\\max_{\\alpha &gt; 0} \\alpha (\\log(\\alpha) - \\log(\\bar{x}) + \\bar{x}_l) - \\log(\\Gamma(\\alpha)) - \\alpha\n\\]\nNow by taking the derivative with respective to \\(\\alpha\\), and equating this to \\(0\\), we obtain\n\\[\n\\log(\\alpha) + 1 - \\log(\\bar{x}) + \\bar{x}_l - \\psi(\\alpha) - 1 = 0\n\\]\nwhere \\(\\psi(z) := \\frac{d}{dz}\\log(\\Gamma(z))\\) is the well-known digamma function.\nHence, we find that \\(\\alpha^\\star\\) must satisfy\n\\[\n\\log(\\alpha) - \\psi(\\alpha) - \\log(\\bar{x}) + \\bar{x}_l = 0\n\\]\nwith \\(\\lambda^\\star = \\frac{\\alpha^\\star}{\\bar{x}}\\). Our optimal MLE solution is given by \\((\\alpha^\\star, \\lambda^\\star)\\). In order to find this value, we must solve it numerically.\n\nusing SpecialFunctions, Distributions, Roots, CairoMakie, Random\n\nRandom.seed!(1234)\n\neq(alpha, xb, xbl) = log(alpha) - digamma(alpha) - log(xb) + xbl\n\nrealAlpha, realLambda = 2, 3\ngammaDist = Gamma(realAlpha, 1 / realLambda)\n\nfunction mle(sample)\n    alpha = find_zero((a) -&gt; eq(a, mean(sample), mean(log.(sample))), 1)\n    lambda = alpha / mean(sample)\n    return [alpha, lambda]\nend\n\nN = 10^4\n\nmles10 = [mle(rand(gammaDist, 10)) for _ in 1:N]\nmles100 = [mle(rand(gammaDist, 100)) for _ in 1:N]\nmles1000 = [mle(rand(gammaDist, 1000)) for _ in 1:N]\n\nfig = Figure()\nax = Axis(fig[1, 1],\n    xlabel=L\"\\alpha\",\n    ylabel=L\"\\lambda\",\n    limits=(0, 6, 0, 8))\n\nscatter!(ax, first.(mles10), last.(mles10),\n    color=:blue, markersize=2, label=\"n = 10\")\nscatter!(ax, first.(mles100), last.(mles100),\n    color=:red, markersize=2, label=\"n = 100\")\nscatter!(ax, first.(mles1000), last.(mles1000),\n    color=:green, markersize=2, label=\"n = 1000\")\n\nmarker_elem1 = MarkerElement(color=:blue, marker=:circle, markersize=20, points=Point2f[(0.5, 0.5)])\nmarker_elem2 = MarkerElement(color=:red, marker=:circle, markersize=20, points=Point2f[(0.5, 0.5)])\nmarker_elem3 = MarkerElement(color=:green, marker=:circle, markersize=20, points=Point2f[(0.5, 0.5)])\nLegend(fig[1, 1],\n    [marker_elem1, marker_elem2, marker_elem3],\n    [\"n = 10\", \"n = 100\", \"n = 1000\"],\n    tellwidth=false, tellheight=false,\n    halign=:left, valign=:top)\nfig\n\n\n\n\n\n\n8.7.2.3 Comparing the method of moments and MLE\nNow we use the Mean Squared Error (MSE)\n\\[MSE_\\theta(\\hat{\\theta}) = E[(\\hat{\\theta}-\\theta)^2] = Var(\\hat{\\theta}) + (E[\\hat{\\theta}] - \\theta)^2 = \\text{variance} + \\text{bias}^2\\]\nto compare the performance and behavior of moments and MLE.\nConsider a random sample \\(x_1, ..., x_n\\) from an uniform distribution on the interval \\((a, b)\\).\nThe MLE for the parameter \\(\\theta = (a, b)\\) can be shown to be\n\\[\n\\begin{align}\n\\hat{a} &= \\min\\{x_1, ..., x_n\\} \\\\\n\\hat{b} &= \\max\\{x_1, ..., x_n\\}\n\\end{align}\n\\]\nFor the method of moments, since \\(X \\backsim U(a, b)\\), it follows that\n\\[\n\\begin{align}\nE[X] &= \\frac{a+b}{2} \\\\\nVar(X) &= \\frac{(b-a)^2}{12}\n\\end{align}\n\\]\nHence, by solving for \\(a\\) and \\(b\\), and replacing \\(E[X]\\) and \\(Var(X)\\) with \\(\\bar{x}\\) and \\(s^2\\) respectively, we obtain\n\\[\n\\begin{align}\n\\hat{a} &= \\bar{x}-\\sqrt{3}s \\\\\n\\hat{b} &= \\bar{x}+\\sqrt{3}s\n\\end{align}\n\\]\n\nusing Distributions, CairoMakie\n\nN = 10^5\nnMin, nStep, nMax = 10, 10, 200\nsampleSizes = nMin:nStep:nMax\ntrueB = 5\ntrueDist = Uniform(-2, trueB)\n\nMLEest(data) = maximum(data)\nMMest(data) = mean(data) + sqrt(3) * std(data)\n\nres = Dict{Symbol,Array{Float64}}(\n    (sym -&gt; sym =&gt; Array{Float64}(undef, length(sampleSizes))).(\n        [:MSEMLE, :MSEMM, :VarMLE, :VarMM, :BiasMLE, :BiasMM]))\n\nfor (i, n) in enumerate(sampleSizes)\n    mleEst, mmEst = Array{Float64}(undef, N), Array{Float64}(undef, N)\n    for j in 1:N\n        samples = rand(trueDist, n)\n        mleEst[j] = MLEest(samples)\n        mmEst[j] = MMest(samples)\n    end\n    meanMLE, meanMM = mean(mleEst), mean(mmEst)\n    varMLE, varMM = var(mleEst), var(mmEst)\n\n    res[:MSEMLE][i] = varMLE + (meanMLE - trueB)^2\n    res[:MSEMM][i] = varMM + (meanMM - trueB)^2\n    res[:VarMLE][i] = varMLE\n    res[:VarMM][i] = varMM\n    res[:BiasMLE][i] = meanMLE - trueB\n    res[:BiasMM][i] = meanMM - trueB\nend\n\nfig = Figure(size=(600, 1200))\nax_mse = Axis(fig[1, 1],\n    xlabel=\"Sample size\",\n    ylabel=\"MSE\")\nscatter!(ax_mse, sampleSizes, res[:MSEMLE]; color=:blue, label=\"MSE (MLE)\")\nscatter!(ax_mse, sampleSizes, res[:MSEMM]; color=:red, label=\"MSE (MM)\")\naxislegend(ax_mse)\n\nax_var = Axis(fig[2, 1],\n    xlabel=\"Sample size\",\n    ylabel=\"Variance\")\nscatter!(ax_var, sampleSizes, res[:VarMLE]; color=:blue, label=\"Variance (MLE)\")\nscatter!(ax_var, sampleSizes, res[:VarMM]; color=:red, label=\"Variance (MM)\")\naxislegend(ax_var)\n\nax_bias = Axis(fig[3, 1],\n    xlabel=\"Sample size\",\n    ylabel=\"Bias\")\nscatter!(ax_bias, sampleSizes, res[:BiasMLE]; color=:blue, label=\"Bias (MLE)\")\nscatter!(ax_bias, sampleSizes, res[:BiasMM]; color=:red, label=\"Bias (MM)\")\naxislegend(ax_bias; position=:rb)\nfig\n\n\n\n\nIn fact, there is more supporting theory for the usefulness of maximum likelihood estimation as \\(n \\rightarrow \\infty\\).\n\n\n\n\n8.8 Confidence interval\nGiven a single sample \\(X_1, ..., X_n\\), how does one obtain an indication about the accuracy of the estimate?\nConsider the case where we are trying to estimate the parameter \\(\\theta\\). A confidence interval is then an interval \\([L, U]\\) obtained from our sample data, such that \\(P(L\\le \\theta \\le U) = 1-\\alpha\\), where \\(1-\\alpha\\) is called the confidence level.\nConsider a case of a single observation \\(X\\) (\\(n=1\\)) taken from a symmetric triangular distribution, with a spread of 2 and an unknown center (mean) \\(\\mu\\).\nIn this case, we would set\n\\[\n\\begin{align}\nL &= X + q_{\\frac{\\alpha}{2}} \\\\\nU &= X + q_{1-\\frac{\\alpha}{2}}\n\\end{align}\n\\]\nwhere \\(q_u\\) is the \\(u\\)’th quantile of a triangular distribution centered at \\(0\\), and having a spread of \\(2\\).\nSetting \\(L\\) and \\(U\\) in this manner ensures that \\(P(L\\le \\theta \\le U) = 1-\\alpha\\) holds.\nIn this case, we know that \\(q_{\\frac{\\alpha}{2}} = -(1 - \\sqrt{\\alpha})\\) and \\(q_{1-\\frac{\\alpha}{2}} = 1 - \\sqrt{\\alpha}\\).\n\n\n\n\n\n\nImportant\n\n\n\nTo understand the confidence interval \\(P(L\\le \\theta \\le U) = 1-\\alpha\\), a key point is that there is \\(1-\\alpha\\) chance that the actual parameter \\(\\theta\\) is covered by the interval \\([L, U]\\). This means that if the sampling experiment is repeated say \\(N\\) times, then on average, \\(N\\times(1-\\alpha)\\) of the time the actual parameter \\(\\theta\\) is covered by the interval.\n\n\n\nusing Distributions, CairoMakie, Random\n\nRandom.seed!(1234)\n\nalpha = 0.05\nL(obs) = obs - (1 - sqrt(alpha))\nU(obs) = obs + (1 - sqrt(alpha))\n\nmu = 5.57\ntriDist = TriangularDist(mu - 1, mu + 1, mu)\n\nN = 100\nbounds = zeros(N, 2)\nhits = Vector{Symbol}(undef, N)\nfor i in 1:N\n    obs = rand(triDist)\n    LL, UU = L(obs), U(obs)\n    bounds[i, :] = [LL UU]\n    if LL &lt;= mu && mu &lt;= UU\n        hits[i] = :blue\n    else\n        hits[i] = :red\n    end\nend\n\nfig, ax = rangebars(1:N, bounds[:, 1], bounds[:, 2], color=hits)\nhlines!(ax, mu; color=:green, label=\"Parameter value\")\naxislegend(ax)\nfig\n\n\n\n\n\n\n8.9 Hypothesis tests\nThe approach involves partitioning the parameter space \\(\\Theta\\) into \\(\\Theta_0\\) and \\(\\Theta_1\\), and then, based on the sample, concluding whether one of the two hypotheses, \\(H_0 : \\theta \\in \\Theta_0\\) or \\(H_1 : \\theta \\in \\Theta_1\\) holds.\nThe hypothesis \\(H_0\\) is called the null hypothesis and \\(H_1\\) the alternative hypothesis. The former is the default hypothesis, and in carrying out hypothesis testing our general aim is to reject this hypothesis.\nSince our decision is based on a random sample, there is always a chance of making a mistakenly false conclusion. There are two types of errors that can be made in carrying out a hypothesis testing.\n\n\n\n\n\n\n\nType I and type II erorrs with their probabilities \\(\\alpha\\) and \\(\\beta\\) respectively\n\n\nNote that \\(1-\\beta\\) is known as the power of the hypothesis test.\n\n\n\n\n\n\nHow to understand: fail to reject \\(H_0\\) and reject \\(H_0\\)\n\n\n\nNote that in carrying out a hypothesis test, \\(\\alpha\\) is typically specified, while power is not direcly controlled, but rather is influenced by the sample size and other factors.\nAn important point in terminology is that we don’t use the phrase “accept” for the null hypothesis, rather we “fail to reject it” (if we stick with \\(H_0\\)) or “reject it” (if we choose \\(H_1\\)). This is because when we fail to reject \\(H_0\\), we typically don’t know the actual value of \\(\\beta\\), hence we aren’t able to put a level of certainty on \\(H_0\\) being the case. In other words, when we fail to reject \\(H_0\\), this doesn’t mean that \\(H_0\\) is true. We just haven’t enough evidence to reject it based on the sample data. This means that we are still likely to make type II error with the probability \\(\\beta\\) (i.e. in reality, \\(H_0\\) is false, but we fail to reject it) though we fail to reject \\(H_0\\). Because we usualy don’t know the actual value of \\(\\beta\\), we cannot give such an assertion that \\(H_0\\) is true with a specified confidence level. This is why we just say that we fail to reject \\(H_0\\) based on the sample data, instead of \\(H_0\\) is true.\nHowever, if we do reject \\(H_0\\), then by the design of hypothesis tests we can say that our error probability is bounded by \\(\\alpha\\).\n\n\n\n8.9.1 How to design and perform a hypothesis testing\n\nFormulate the scientific question as a hypothesis by partitioning the parameter space \\(\\Theta\\) into \\(\\Theta_0\\) and \\(\\Theta_1\\), and then formimg the two hypotheses \\(H_0 : \\theta \\in \\Theta_0\\) and \\(H_1 : \\theta \\in \\Theta_1\\).\nDefine the test statistic, denoted \\(X^*\\), as a function of the sample data.\n\nSince the test statistic follows some distribution under \\(H_0\\), the next step is to consider how likely it is to observe the specific value (\\(X^*\\)) calculated from the sample data under \\(H_0\\).\nTo this end, in setting up a hypothesis test, we typically choose a significance level \\(\\alpha\\) (e.g. \\(0.05\\) or \\(0.01\\)), which quantifies our level of tolerance for enduring a type I error. For example, setting \\(\\alpha = 0.01\\) implies we wish to design a test where the probability of type I error is at most \\(0.01\\) if \\(H_0\\) holds. Clearly, a low \\(\\alpha\\) is desirable, however, there are tradeoffs involved since seeking a very low \\(\\alpha\\) will imply a high \\(\\beta\\) (low power).\n\nPick a significance level \\(\\alpha\\).\n\nConsider that we have a series of sample observations distributed as continuous uniform between \\(0\\) and some unknown upper bound \\(m\\).\nSay we set\n\\[\nH_0: m=1,\\ \\ \\ \\ H_1: m&lt;1\n\\]\nwith observations \\(X_1, ..., X_n\\), one possible test statistic is the sample range:\n\\[\nX^* = max(X_1, ..., X_n) - min(X_1, ..., X_n)\n\\]\nAs is always the case, the test statistic is a random variable. Under \\(H_0\\), we expect the distribution of \\(X^*\\) to have support \\([0, 1]\\) with the most likely value being close to \\(1\\). This is because low values of \\(X^*\\) are less plausible under \\(H_0\\). The explicit form of the distribution of \\(X^*\\) can be analytically obtained however for simplicity we use a Monte Carlo simulation to estimate it and present the density.\nFor this case, it is sensible to reject \\(H_0\\) if \\(X^*\\) is small enough.\n\nPerforming hypothesis testing.\n\nAt present, there are two alternatives for performing hypothesis tests:\n\nUsing rejection region:\n\nDenoting quantiles of this distribution by \\(q_0(u)\\), then we set the rejection region as \\(R = [0, q_0(\\alpha)]\\). Using Monte Carlo, we compute the rejection region where the critical value is the upper boundary \\(q_0(\\alpha)\\) of the rejection region in this case. Note that computing the rejection region does not require any sample data as it is based on model assumptions and not the sample.\nThe decision rule for this hypothesis test is simple: compare the observed value of the test statistic, \\(x^*\\), to the critical value \\(q_0(\\alpha)\\) and reject \\(H_0\\) if \\(x^*\\le q_0(\\alpha)\\), otherwise do not reject.\n\nUsing p-value:\n\nWe collect the data and compute the observed value of the test statistic \\(x^*\\). The p-value is then the maximal \\(\\alpha\\) under which the test would be rejected with the observed test statistic. In other words, we find \\(p\\) which solves \\(x^* = q_0(p)\\). This is computed via \\(F_0(x^*)\\), where \\(F(\\cdot)\\) is the CDF of \\(X^*\\).\nUsing the p-vaue approach, reporting a low p-value implies that we are very confident in rejecting \\(H_0\\), while a high p-value implies we are not. The p-value approach can be used to decide whether \\(H_0\\) should be rejected or not with a specified \\(\\alpha\\). For this case, simply comparing \\(p\\) and \\(\\alpha\\), and reject \\(H_0\\) if \\(p\\le \\alpha\\).\n\n\n\n\n\n\n\nUsing rejection region or p-value to perform hypothesis testing\n\n\n\nusing Distributions, CairoMakie, Random, Statistics\n\nRandom.seed!(1)\n\nn, N, alpha = 10, 10^7, 0.05\nmActual = 0.7\ndist0, dist1 = Uniform(0, 1), Uniform(0, mActual)\n\nts(sample) = maximum(sample) - minimum(sample)\n\nempiricalDistUnderH0 = [ts(rand(dist0, n)) for _ in 1:N]\nrejectionValue = quantile(empiricalDistUnderH0, alpha)\n\nsamples = rand(dist1, n)\ntestStat = ts(samples)\npValue = sum(empiricalDistUnderH0 .&lt;= testStat) / N\n\nif testStat &gt; rejectionValue\n    println(\"Do not reject: \", round(testStat; digits=4), \" &gt; \", round(rejectionValue; digits=4))\nelse\n    println(\"Reject: \", round(testStat; digits=4), \" &lt;= \", round(rejectionValue; digits=4))\nend\nprintln(\"p-value = \", round(pValue; digits=4))\n\nfig, ax = stephist(empiricalDistUnderH0; bins=100, color=:blue, normalization=:pdf)\nvlines!(ax, testStat; color=:red, label=\"Observed test statistic\")\nvlines!(ax, rejectionValue; color=:black, label=\"Critical value boundary\")\naxislegend(ax; position=:lt)\nax.title = L\"\\text{The distribution of the test statistic }X^*\\text{ under }H_0\"\nfig\n\nReject: 0.5725 &lt;= 0.6059\np-value = 0.032\n\n\n\n\n\n\n\n8.9.2 Understand type I and type II errors\nWhen the alternative parameter spaces \\(\\Theta_0\\) and \\(\\Theta_1\\) are only comprised of a single point each, the hypothesis test is called a simple hypothesis test.\nConsider a container that conatins two identical types of pipes, except that one type weighs \\(15\\) grams on average and the other \\(18\\) grams on avearge. The standard deviation of the weights of both pipe types is \\(2\\) grams.\nImagine that we sample a single pipe, and wish to determine its type. Denote the weight of this pipe by the random variable \\(X\\). For this example, we devise the following statistical hypothesis test: \\(\\Theta_0 = {15}\\) and \\(\\Theta_1 = {18}\\). Now, given a threshold \\(\\tau\\), we reject \\(H_0\\) if \\(X &gt; \\tau\\), otherwise we retain \\(H_0\\).\nIn this case, we can explicitly analyze the probabilities of both the type I and type II errors, \\(\\alpha\\) and \\(\\beta\\) respectively.\n\nusing Distributions, StatsBase, CairoMakie\n\nmu0, mu1, sd, tau = 15, 18, 2, 17.5\ndist0, dist1 = Normal(mu0, sd), Normal(mu1, sd)\ngrid = 5:0.1:25\nh0grid, h1grid = tau:0.1:25, 5:0.1:tau\n\n# CCDF: complementary CDF\nprintln(\"Probability of Type I error: \", ccdf(dist0, tau))\nprintln(\"Probability of Type II error: \", cdf(dist1, tau))\n\nfig, ax = lines(grid, pdf.(dist0, grid); color=:red, label=\"Bolt type 15g\")\nband!(ax, h0grid, repeat([0], length(h0grid)), pdf.(dist0, h0grid); color=(:red, 0.2))\nlines!(ax, grid, pdf.(dist1, grid); color=:green, label=\"Bolt type 18g\")\nband!(ax, h1grid, repeat([0], length(h1grid)), pdf.(dist1, h1grid); color=(:green, 0.2))\nlinesegments!(ax, [tau, 25], [0, 0]; color=:black, label=\"Rejection region\", linewidth=5)\ntext!([15, 18, 15.5, 18.5], [0.21, 0.21, 0.02, 0.02]; text=[L\"H_0\", L\"H_1\", L\"\\beta\", L\"\\alpha\"], align=repeat([(:center, :center)], 4), fontsize=28)\naxislegend(ax)\nfig\n\nProbability of Type I error: 0.10564977366685525\nProbability of Type II error: 0.4012936743170763\n\n\n\n\n\n\n\n8.9.3 The Receiver Operating Curve (ROC)\nIn the previous example, \\(\\tau = 17.5\\) was arbitrarily chosen.\nClearly, if \\(\\tau\\) was increased, the probability of making a type I error, \\(\\alpha\\), would decrease, while the probability of making a type II error, \\(\\beta\\), would increase. Conversely, if we decreased \\(\\tau\\) the reverse would occur.\nHere we use the Receiver Operating Curve (ROC) to help to visualize the tradeoff between type I and type II errors. It allows us to visualize the error tradeoffs for all possible \\(\\tau\\) values simutaneously for a particular alternative hypothesis \\(H_1\\).\nBelow we plot the analytic coordinates of \\((\\alpha(\\tau), 1-\\beta(\\tau))\\). This is the ROC. It is a parametric plot of the probability of a type I error and power.\n\nusing Distributions, StatsBase, CairoMakie\n\nmu0, mu1a, mu1b, mu1c, sd = 15, 16, 18, 20, 2\ntauGrid = 5:0.1:25\n\ndist0 = Normal(mu0, sd)\ndist1a, dist1b, dist1c = Normal(mu1a, sd), Normal(mu1b, sd), Normal(mu1c, sd)\n\nfalsePositive = ccdf.(dist0, tauGrid)\ntruePositiveA, truePositiveB, truePositiveC = ccdf.(dist1a, tauGrid), ccdf.(dist1b, tauGrid), ccdf.(dist1c, tauGrid)\n\nfig, ax = ablines(0, 1; color=:black, linestyle=:dash, label=L\"H_0 = H_1 = 15\")\nlines!(ax, falsePositive, truePositiveA; color=:blue, label=L\"H_{1a}: \\mu_1 = 16\")\nlines!(ax, falsePositive, truePositiveB; color=:red, label=L\"H_{1b}: \\mu_1 = 18\")\nlines!(ax, falsePositive, truePositiveC; color=:green, label=L\"H_{1c}: \\mu_1 = 20\")\nax.xlabel = L\"\\alpha\"\nax.ylabel = L\"\\text{Power }(1-\\beta)\"\naxislegend(ax; position=:rb)\nfig\n\n\n\n\n\n\n8.9.4 A randomized hypothesis test\nWe now investigate the concept of a randomization test, which is a type of non-parametric test, i.e. a statistical test which does not require that we know what type of distribution the data comes from.\nA virtue of non-parametric tests is that they do not impose a specific model.\nConsider the following example, where a farmer wants to test whether a new fertilizer is effective at increasing the yield of her tomato plants. As an experiment, she took \\(20\\) plants, kept \\(10\\) as controls, and treated the remaining \\(10\\) with fertilizer, After \\(2\\) months, she harvested the plants and recorded the yield of each plant in kg as shown in the following table:\n\n\n\n\n\n\n\nYield in kg for \\(10\\) plants with, and \\(10\\) plants without fertilizer (control)\n\n\nIt can be observed that the group of plants treated with fertilizer have an average yield \\(0.494\\) kg greater than that of the control group. One could argue that this difference is due to the effects of the fertilizer. We now investigate if this is a reasonable assumption. Let us assume for a moment that the fertilizer had no effect on plant yield (\\(H_0\\)) and that the result was simply due to random chance. In such a scenario, we actually have \\(20\\) observations from the same group, and regardless of how we arrange our observations, we would expect to observe similar results.\nHence, we can investigate the likelihood of this outcome occurring by random chance, by considering all possible combinations of \\(10\\) samples from our group of \\(20\\) observations, and counting how many of these combinations result in a difference in sample means greater than or equal to \\(0.494\\) kg. The proportion of times this occurs is analogous to the likelihood that the difference we observe in our sample means was purely due to random chance. It is in a sense the p-value.\nBefore proceeding, we calculate the number of ways one can sample \\(r = 10\\) unique items from \\(n = 20\\) total, which is given by\n\\[\n\\binom{20}{10} = 184,756\n\\]\nHence, the number of possible combinations in our example is computationally manageable. Note that in a different situation where \\(n\\) and \\(r\\) would be bigger, e.g. \\(n = 40\\) and \\(r = 20\\), the number of combinations would be too big for an exhaustive search (about \\(137\\) billion). In such a case, a viable alternative is to randomly sample combinations for estimating the p-value.\n\nusing Combinatorics, Statistics, DataFrames, CSV\n\ndf = CSV.read(\"./data/fertilizer.csv\", DataFrame)\ncontrol = df.Control\nfertilizer = df.FertilizerX\n\nsubGroups = collect(combinations([control; fertilizer], 10))\nmeanFert = mean(fertilizer)\npVal = sum([mean(i) &gt;= meanFert for i in subGroups]) / length(subGroups)\nprintln(\"p-value = \", pVal)\n\np-value = 0.023972157873086666\n\n\n\n\n\n8.10 Bayesian statistics\nIn the Bayesian paradigm, the scalar or vector of parameter \\(\\theta\\) is not assumed to exist as some fixed unknown quantity but instead is assumed to follow a distribution.\nThat is, the parameter itself, is a random variable, and the act of Bayesian inference is the process of obtaining more information about the distribution of \\(\\theta\\).\nThis allows us to incorparate prior beliefs about the parameter before experience from new observations is taken into consideration.\nThe key objects at play are the prior distribution of the parameter and the posterior distribution of the parameter.\nThe former is postulated beforehand, or exists as a consequence of previous inference, while the latter captures the distribution of the parameter after observations are taken into consideration.\nThe relationship between the prior and the posterior is\n\\[\n\\text{posterior} = \\frac{\\text{likelihood}\\times\\text{prior}}{evidence}\\ \\ \\ \\ \\text{or}\\ \\ \\ \\ f(\\theta|x) = \\frac{f(x|\\theta)\\times f(\\theta)}{\\int f(x|\\theta)f(\\theta)d\\theta}\n\\]\nThis is nothing but Bayes’s rule \\(P(B_i|A) = \\frac{P(A|B_i)P(B_i)}{\\sum_{j=1}^{n}P(A|B_j)P(B_j)}, A\\in \\cup_{i=1}^n B_i\\) applied to densities.\nHere the prior distribution (density) is \\(f(\\theta)\\), and the posterior distribution (density) is \\(f(\\theta|x)\\).\nObserve that the denominator, known as evidence or marginal likelihood, is constant with respect to the parameter \\(\\theta\\). This allows the equation to be written as\n\\[\nf(\\theta|x) \\propto f(x|\\theta)\\times f(\\theta)\n\\]\nHence, the posterior distribution can be easily obtained up to the normalizing constant (the evidence) by multiplying the prior with the likelihood.\nIn general, carrying out Beyesian inference involves the following steps:\n\nAssume some distributional model for the data based on the parameter \\(\\theta\\) which is a random variable.\nUse previous inference experience, elicit an expert, or make an educated guess to determine a prior distribution \\(f(\\theta)\\). The prior distribution might be parameterized by its own parameters, called hyper-parameters.\nCollect data \\(x\\) and create an expression or a computational mechanism for the likelihood \\(f(x|\\theta)\\) based on the distributional model chosen.\nUse the Bayes’s rule applied to densities to obtain the posterior distribution of the parameters \\(f(\\theta|x)\\).\n\nIn most cases, the evidence (the denominator) is not easily computable. Hence the posterior distribution is only available up to a normalizing constant. In some special cases, the form of the posterior distribution is the same as the prior distribution. In such cases, conjugacy holds, the prior is called a conjugate prior, and the hyper-parameters are updated from prior to posterior.\n\nThe posterior distribution can then be used to make conclusions about the model.\n\nFor example, if a single specific parameter value is needed to make the model concrete, a Bayes estimate based on the posterior distribution, for example, the posterior mean, may be computed:\n\\[\n\\hat{\\theta} = \\int \\theta f(\\theta|x) d\\theta\n\\]\nFurther analyses such as obtaining credible intervals, similar to condidence intervals, may also be carried out.\n\nThe model with \\(\\hat{\\theta}\\) can then be used for making conclusions. Alternatively, a whole class of models based on the posterior distribution \\(f(\\hat{\\theta}|x)\\) can be used. This often goes hand in hand with simulation as one is able to generate Monte Carlo samples from the posterior distribtion.\n\n\n8.10.1 A Poisson example\nConsider an example where an insurance company models the number of weekly fires in a city using a Poisson distribution with parameter \\(\\lambda\\). Here, \\(\\lambda\\) is also the expected number of fires per week.\nAssume that the following data is collected over a period of \\(16\\) weeks:\n\\[\nx = (x_1, ..., x_{16}) = (2, 1, 0, 0, 1, 0, 2, 2, 5, 2, 4, 0, 3, 2, 5, 0)\n\\]\nEach data point indicates the number of fires per week.\nIn this case, the MLE is \\(\\hat{\\lambda} = 1.8125\\) simply obtained by the sample mean. Hence, in a frequentist approach, after \\(16\\) weeks, the distribution of the number of fires per week is modeled by a Poisson distribution with \\(\\lambda = 1.8125\\). One can then obtain estimates for say, the probability of having more than \\(5\\) fires in a given week as follows:\n\\[\nP(\\text{fires per week} &gt; 5) = 1 - \\sum_{k=0}^{5} e^{-\\lambda \\frac{\\lambda^k}{k!}} \\approx 0.0107\n\\]\nHowever, the drawback of such an approach in estimating \\(\\lambda\\) is that it didn’t make use of previous information.\nSay that for example, further knowledge comes to light that the number of fires per week ranges between \\(0\\) and \\(10\\), and that the typical number is \\(3\\) fires per week. In this case, one can assign a prior distribution to \\(\\lambda\\) that captures this belief.\nIn this example, we can assume that we decide to use a triangular distribution which captures prior beliefs about the parameter \\(\\lambda\\) well because it has a defined range and a defined mode.\nWith the prior assigned and the data collected, we can use the machinery of Bayesian inference.\nIn this case, the prior distibution of the parameter \\(\\lambda\\) is the triangular distribution with the PDF:\n\\[\nf(\\lambda) = \\begin{cases}\n\\frac{1}{15}\\lambda, & \\lambda \\in [0,3] \\\\\n\\frac{1}{35}(10-\\lambda), & \\lambda \\in (3, 10]\n\\end{cases}\n\\]\nWith the \\(16\\) observations, \\(x_1, ..., x_{16}\\), the likelihood is\n\\[\nf(x|\\lambda) = \\prod_{k=1}^{16} e^{-\\lambda \\frac{\\lambda^k}{k!}}\n\\]\nHence, the posterior distribution \\(f(\\lambda|x) \\propto f(x|\\lambda)f(\\lambda)\\), then dividing by the evidence,\n\\[\n\\int_0^{10} f(x|\\lambda)f(\\lambda)d\\lambda\n\\]\n\nusing Distributions, CairoMakie\n\nalpha, beta = 8, 2\nprior(lam) = pdf(Gamma(alpha, 1 / beta), lam)\nd = [2, 1, 0, 0, 1, 0, 2, 2, 5, 2, 4, 0, 3, 2, 5, 0]\n\nlike(lam) = *([pdf(Poisson(lam), x) for x in d]...)\nposteriorUpToK(lam) = like(lam) * prior(lam)\n\ndelta = 10^-4\nlamRange = 0:delta:10\nK = sum([posteriorUpToK(lam) * delta for lam in lamRange])\nposterior(lam) = posteriorUpToK(lam) / K\n\nbayesEsitmate = sum([lam * posterior(lam) * delta for lam in lamRange])\n\nprintln(\"Computational Bayes Estimate: \", bayesEsitmate)\n\nfig, ax = lines(lamRange, prior.(lamRange); color=:blue, label=\"Prior distribution\")\nlines!(ax, lamRange, posterior.(lamRange); color=:red, label=\"Posterior distribution\")\nax.limits = (0, 10, 0, 1.2)\nax.xlabel = L\"\\lambda\"\nax.ylabel = \"Density\"\naxislegend(ax)\nfig\n\nComputational Bayes Estimate: 2.055555555555556\n\n\n\n\n\n\n\n8.10.2 Congugate prior example\nThe gamma distribution is said to be a conjugate prior to the Poisson distribution, which means that both the prior distribution and the posterior distribution are gamma distributions when the data is distributional as a Poisson distribution. In this case, the hyper-parameters typically have a simple update law from prior to posterior.\nIn the case of a gamma-Poisson conjugate pair, assume the hyper-parameters of the prior to have \\(\\alpha\\) (shape parameter) and \\(\\beta\\) (rate parameter). We have\n\\[\n\\begin{align}\n\\text{posterior} &\\propto \\text{likelihood}\\times \\text{prior} \\\\\n&\\propto \\left(\\prod_{k=1}^n e^{-\\lambda \\frac{\\lambda^k}{k!}}\\right) \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} \\lambda^{\\alpha-1} e^{-\\beta\\lambda} \\\\\n&= \\lambda^{\\alpha+(\\sum_{k=1}^{n} x_k)-1}e^{-\\lambda(\\beta+n)} \\\\\n&\\propto \\text{gamma density with shape parameter } \\alpha + \\sum x_i \\text{ and rate parameter } \\beta+n\n\\end{align}\n\\]\nThe hyper-parameter \\(\\alpha\\) is updated to \\(\\alpha + \\sum x_i\\) and the hyper-parameter \\(\\beta\\) is updated to \\(\\beta + n\\).\n\nusing Distributions, CairoMakie\n\nalpha, beta = 8, 2\nprior(lam) = pdf(Gamma(alpha, 1 / beta), lam)\nd = [2, 1, 0, 0, 1, 0, 2, 2, 5, 2, 4, 0, 3, 2, 5, 0]\n\nlike(lam) = *([pdf(Poisson(lam), x) for x in d]...)\nposteriorUpToK(lam) = like(lam) * prior(lam)\n\ndelta = 10^-4\nlamRange = 0:delta:10\nK = sum([posteriorUpToK(lam) * delta for lam in lamRange])\nposterior(lam) = posteriorUpToK(lam) / K\n\nbayesEsitmate = sum([lam * posterior(lam) * delta for lam in lamRange])\n\nnewAlpha, newBeta = alpha + sum(d), beta + length(d)\nclosedFormBayesEstimate = mean(Gamma(newAlpha, 1 / newBeta))\n\nprintln(\"Computational Bayes Estimate: \", bayesEsitmate)\nprintln(\"Closed form Bayes Estimate: \", closedFormBayesEstimate)\n\nfig, ax = lines(lamRange, prior.(lamRange); color=:blue, label=\"Prior distribution\")\nlines!(ax, lamRange, posterior.(lamRange); color=:red, label=\"Posterior distribution\")\nax.limits = (0, 10, 0, 1.2)\nax.xlabel = L\"\\lambda\"\nax.ylabel = \"Density\"\naxislegend(ax)\nfig\n\nComputational Bayes Estimate: 2.055555555555556\nClosed form Bayes Estimate: 2.0555555555555554\n\n\n\n\n\n\n\n8.10.3 Markov Chain Monte Carlo example\nIn cases where the dimension of the parameter space is high, carrying out straighforward integration is not possible.\nHowever, there are other ways of carrying out Bayesian inference.\nOne such popular way is by using algorithms that fall under the category known as Markov Chain Monte Carlo (MCMC).\nThe Metropolis-Hastings algorithm is one such popular MCMC algorithm.\nIt produces a series of samples \\(\\theta(1), \\theta(2), \\theta(3), ...\\), where it is guaranteed that for large \\(t\\), \\(\\theta(t)\\) is distributed according to the posterior distribution.\nTechnically, the random sequence \\(\\{\\theta(t)\\}_{t=1}^\\infty\\) is a Markov chain and it is guaranteed that the stationary distribution of this Markov chain is the specified posterior distribution. That is, the posterior distribution is an input parameter to the algorithm.\nThe major bebefits of Metropolis-Hastings and similar MCMC algorithms is that they only use the ratios of the posterior on different parameter values. For example, for parameter \\(\\theta_1\\) and \\(\\theta_2\\), the algorithm only uses the posterior distribution via the ratio\n\\[\nL(\\theta_1, \\theta_2) = \\frac{f(\\theta_1|x)}{f(\\theta_2|x)}\n\\]\nThis means that the normalizing constant (evidence) is not needed as it is implicitly canceled out. Thus, using \\(\\text{psoterior} \\propto \\text{likelihood}\\times \\text{prior}\\) suffices.\nFurther to the posterior distribution, an additional input parameter to Metropolis-Hastings is the so-called proposal density, denoted by \\(q(\\cdot|\\cdot)\\). This is a family of distributions where given a certain value of \\(\\theta_1\\) taken as a parameter, the new value, say \\(\\theta_2\\) is distributed with PDF\n\\[\nq(\\theta_2|\\theta_1)\n\\]\nThe idea of Metropolis-Hastings is to walk around the parameter space by randomly generating new values using \\(q(\\cdot|\\cdot)\\).\nAt each step, some new values are accepted while others are not, all in a manner which ensures the desired limiting behavior. The algorithm specification is to accept with probability\n\\[\nH = \\min\\left\\{1,\\ L(\\theta^*, \\theta(t)) \\frac{q(\\theta(t)|\\theta^*)}{q(\\theta^*|\\theta(t))}\\right\\}\n\\]\nwhere \\(\\theta^*\\) is the new proposed value, generated via \\(q(\\cdot|\\theta(t))\\), and \\(\\theta(t)\\) is the current value.\nWith each such iteration, the new value is accepted with probability \\(H\\) and rejected otherwise. With certian technical requirements on the posterior and proposal densities, the theory of Markov chains then guarantees that the stationary distribution of the sequence \\(\\{\\theta(t)\\}\\) is the posterior distribution.\nDifferent variants of the Metropolis-Hastings algorithm employ different types of proposal densities. There are also generalizations and extensions that we don’t discuss here, such as Gibbs Sampling and Hamiltonian Monte Carlo.\nAs an example, we use the folded normal distribution as a proposal density. This distribution is achieved by taking a normal random variable \\(X\\) with mean \\(\\mu\\) and variance \\(\\sigma^2\\) and considering \\(Y=|X|\\). In this case, the PDF of \\(Y\\) is\n\\[\nf(y) = \\frac{1}{\\sigma 2\\pi} \\left(e^{-\\frac{(y-\\mu)^2}{2\\sigma^2}} + e^{-\\frac{(y+\\mu)^2}{2\\sigma^2}}\\right)\n\\]\nIt supports to generate the non-negative parameters in question.\n\nusing Distributions, CairoMakie\n\nalpha, beta = 8, 2\n# prior with Gamma distribution which has two hyper-parameters α and β\nprior(lam) = pdf(Gamma(alpha, 1 / beta), lam)\nd = [2, 1, 0, 0, 1, 0, 2, 2, 5, 2, 4, 0, 3, 2, 5, 0]\n\n# data with Poisson distribution which has a parameter λ\nlike(lam) = *([pdf(Poisson(lam), x) for x in d]...)\n# posterior ∝ likelihood * prior\nposteriorUpToK(lam) = like(lam) * prior(lam)\n\nsig = 0.5\n# use the folded normal distribution as the proposal density\n# with each parameter θ1, it produces a new parameter θ2\nfoldedNormalPDF(x, mu) = (1 / sqrt(2 * pi * sig^2)) * (exp(-(x - mu)^2 / 2sig^2) + exp(-(x + mu)^2 / 2sig^2))\nfoldedNormalRV(mu) = abs(rand(Normal(mu, sig)))\n\nfunction sampler(piProb, qProp, rvProp)\n    lam = 1\n    warmN, N = 10^5, 10^6\n    samples = zeros(N - warmN)\n\n    for t in 1:N\n        while true\n            lamTry = rvProp(lam)\n            Lo = piProb(lamTry) / piProb(lam)\n            H = min(1, Lo * qProp(lam, lamTry) / qProp(lamTry, lam))\n            if rand() &lt; H\n                lam = lamTry\n                if t &gt; warmN\n                    samples[t-warmN] = lam\n                end\n                break\n            end\n        end\n    end\n    return samples\nend\n\nmcmcSamples = sampler(posteriorUpToK, foldedNormalPDF, foldedNormalRV)\nprintln(\"MCMC Bayes Estimate: \", mean(mcmcSamples))\n\nfig, ax = stephist(mcmcSamples; bins=100, color=:black, normalization=:pdf, label=\"Histogram of MCMC samples\")\n\nlamRange = 0:0.01:10\nlines!(ax, prior.(lamRange); color=:blue, label=\"Prior distribution\")\n\nclosedFormPosterior(lam) = pdf(Gamma(alpha + sum(d), 1 / (beta + length(d))), lam)\nlines!(ax, lamRange, closedFormPosterior.(lamRange); color=:red, label=\"Posterior distribution\")\n\nax.limits = (0, 10, 0, 1.2)\nax.xlabel = L\"\\lambda\"\nax.ylabel = \"Density\"\naxislegend(ax)\nfig\n\nMCMC Bayes Estimate: 2.066064798662241"
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#confidence-intervals",
    "href": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#confidence-intervals",
    "title": "Probability and statistics with Julia",
    "section": "9 Confidence intervals",
    "text": "9 Confidence intervals\nIn the setting of symmetric sampling distributions, a typical formula for the confidence interval \\([L, U]\\) is of the form\n\\[\n\\hat{\\theta} \\pm K_\\alpha s_\\text{err}\n\\]\nHere, \\(\\hat{\\theta}\\) is typically the point estimate for the parameter in question, \\(s_\\text{err}\\) is some measure or estimate of the variability (e.g. standard error) of the parameter, and \\(K_\\alpha\\) is a constant which depends on the model at hand and on \\(\\alpha\\). Typically by decreasing \\(\\alpha \\rightarrow 0\\), we have that \\(K_\\alpha\\) increases, implying a wider confidence interval. In addition, the specific form of \\(K_\\alpha\\) often depends on conditions such as\n\nSample size: is the sample size small or large.\nVariance: is the variance \\(\\sigma^2\\) known or unknown.\nDistribution: is the population assumed normally distributed or not.\n\n\n9.1 Single sample confidence intervals for the mean\nAssume that we want to estimate the population mean \\(\\mu\\) using a random sample, \\(X_1, ..., X_n\\).\nAs mentioned before, an unbiased point estimate for the mean is the sample mean \\(\\overline{X}\\), so a typical formula for the confidence interval of the mean is\n\\[\n\\overline{X} \\pm K_\\alpha \\frac{S}{\\sqrt{n}}\n\\]\n\n9.1.1 Population variance known\nIf we assume that the population variance \\(\\sigma^2\\) is known and the data is normally distributed, then the sample mean \\(\\overline{X}\\) is normally distributed with mean \\(\\mu\\) and variance \\(\\frac{\\sigma^2}{n}\\). This yields\n\\[\nP\\left( \\mu - z_{1-\\frac{\\alpha}{2}} \\frac{\\sigma}{\\sqrt{n}} \\le \\overline{X} \\le \\mu + z_{1-\\frac{\\alpha}{2}} \\frac{\\sigma}{\\sqrt{n}} \\right) = 1-\\alpha\n\\]\nwhere \\(z_{1-\\frac{\\alpha}{2}}\\) is the \\(1-\\frac{\\alpha}{2}\\) quantile of the standard normal distribution.\nBy rearranging the inequalities inside the probability statement above, we obtain the following confidence interval formula\n\\[\n\\bar{x} \\pm z_{1-\\frac{\\alpha}{2}} \\frac{\\sigma}{\\sqrt{n}}\n\\]\nIn practice, \\(\\sigma^2\\) is rarely known; hence, it is tempting to replace \\(\\sigma\\) by \\(s\\) (sample standard deviation) in the formula above. Such a replacement is generally fine for large samples.\nIn addition, the validity of the normality assumption should also be considered. In cases where the data is not normally distributed, the probability statement above only approximately holds. However, as \\(n \\rightarrow \\infty\\), it quickly becomes precise due to the central limit theorem.\n\nusing Distributions, HypothesisTests\n\nd = [\n    53.35674558144255,\n    53.45887516134873,\n    52.282838627926125,\n    52.98746570643515,\n    51.993167774733486,\n    53.373333606198,\n    55.75410538860477,\n    50.279496381439365,\n    53.6359586914001,\n    53.517705831707495,\n    53.70044994508253,\n    54.15592592604583,\n    53.55054914606446,\n    52.37319589109419,\n    53.4900750059897,\n    52.939458524079605,\n    52.16761562743534,\n    50.87140009591033,\n    53.144919157924924,\n    52.09084035473537,\n]\nxBar, n = mean(d), length(d)\nsig = 1.2\nalpha = 0.1\nz = quantile(Normal(), 1 - alpha / 2)\n\nprintln(\"Calculating formula: \", (xBar - z * sig / sqrt(n), xBar + z * sig / sqrt(n)))\nprintln(\"Using confint() function: \", confint(OneSampleZTest(xBar, sig, n); level=1 - alpha))\n\nCalculating formula: (52.514845578531826, 53.39756666402797)\nUsing confint() function: (52.514845578531826, 53.39756666402797)\n\n\n\n\n\n\n\n\nNote\n\n\n\nAssume \\(U \\sim N(0, 1)\\), and \\(X \\sim N(\\mu, \\sigma)\\), we have\n\\[\nU = \\frac{X-\\mu}{\\sigma}\n\\]\n\\[\nX = \\mu + U\\sigma\n\\]\n\\[\nP(-z_{1-\\frac{\\alpha}{2}} \\le U \\le z_{1-\\frac{\\alpha}{2}}) = 1-\\alpha\n\\]\n\\[\nP(\\mu - z_{1-\\frac{\\alpha}{2}}\\sigma \\le X \\le \\mu + z_{1-\\frac{\\alpha}{2}}\\sigma) = 1-\\alpha\n\\]\n\n\n\n\n9.1.2 Population variance unknown\nIn cases where the population variance is unknown, if we replace \\(\\sigma\\) by the sample standard deviation \\(s\\), we can use the T-distribution instead of the normal distribution to obtain the confidence interval for the mean\n\\[\n\\bar{x} \\pm t_{1-\\frac{\\alpha}{2}, n-1} \\frac{s}{\\sqrt{n}}\n\\]\nwhere \\(t_{1-\\frac{\\alpha}{2}, n-1}\\) is the \\(1-\\frac{\\alpha}{2}\\) quantile of a T-distribution with \\(n-1\\) degrees of freedom.\nFor small samples, the replacement of \\(z_{1-\\frac{\\alpha}{2}}\\) by \\(t_{1-\\frac{\\alpha}{2}, n-1}\\) significantly affects the width of the confidence interval, as for the same value of \\(\\alpha\\), the T case is wider.\nHowever, as \\(n \\rightarrow \\infty\\), we have, \\(t_{1-\\frac{\\alpha}{2}, n-1} \\rightarrow z_{1-\\frac{\\alpha}{2}}\\).\n\nusing Distributions, HypothesisTests\n\nd = [\n    53.35674558144255,\n    53.45887516134873,\n    52.282838627926125,\n    52.98746570643515,\n    51.993167774733486,\n    53.373333606198,\n    55.75410538860477,\n    50.279496381439365,\n    53.6359586914001,\n    53.517705831707495,\n    53.70044994508253,\n    54.15592592604583,\n    53.55054914606446,\n    52.37319589109419,\n    53.4900750059897,\n    52.939458524079605,\n    52.16761562743534,\n    50.87140009591033,\n    53.144919157924924,\n    52.09084035473537,\n]\nxBar, n = mean(d), length(d)\ns = std(d)\nalpha = 0.1\nt = quantile(TDist(n - 1), 1 - alpha / 2)\n\nprintln(\"Calculating formula: \", (xBar - t * s / sqrt(n), xBar + t * s / sqrt(n)))\nprintln(\"Using confint() function: \", confint(OneSampleTTest(xBar, s, n); level=1 - alpha))\n\nCalculating formula: (52.499893857795534, 53.41251838476426)\nUsing confint() function: (52.499893857795534, 53.41251838476426)\n\n\n\n\n\n9.2 Two sample confidence intervals for the difference in means\nIt is often of interest to estimate the difference between the population means, \\(\\mu_1 - \\mu_2\\).\nFirst we collect two random samples, \\(x_{i,1}, ..., x_{i,n}\\) for \\(i = 1,2\\), each with the sample mean \\(\\bar{x}_i\\) and sample standard deviation \\(s_i\\). In addition, the difference of sample means, \\(\\bar{x}_1 - \\bar{x}_2\\) serves as a point estimate for the difference in population means, \\(\\mu_1 - \\mu_2\\).\nA confidence interval for \\(\\mu_1 - \\mu_2\\) around the point estimate \\(\\bar{x}_1 - \\bar{x}_2\\) is then constructed via the same process seen previously\n\\[\n\\bar{x}_1 - \\bar{x}_2 \\pm K_\\alpha s_\\text{err}\n\\]\n\n9.2.1 Population variances known\nIn cases where the population variances are known, we may explicitly compute\n\\[\nVar(\\overline{X}_1 - \\overline{X}_2) = \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}\n\\]\nHence, the standard error is given by\n\\[\ns_\\text{err} = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}\n\\]\nWhen combined with the assumption that the data is normally distributed, we can derive the following confidence interval\n\\[\n\\bar{x}_1 - \\bar{x}_2 \\pm z_{1-\\frac{\\alpha}{2}} \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}\n\\]\n\n\n9.2.2 Population variances unknown and assumed equal\nIn cases where the population variances are unknown but assumed equal, denoted by \\(\\sigma^2\\). Based on this assumption, it is sensible to use both sample variances to estimate \\(\\sigma^2\\). This estimated variance using both samples is known as the pooled sample variance, and is given by\n\\[\nS_p^2 = \\frac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{n_1+n_2-2}\n\\]\nIn fact, it is a weighted average of the sample variances of the individual samples.\nIn this case, it can be shown that\n\\[\nT = \\frac{\\overline{X}_1 - \\overline{X}_2 - (\\mu_1 - \\mu_2)}{S_\\text{err}}\n\\]\nis distributed as a T-distribution with \\(n_1+n_2-2\\) degreees of freedom, where the standard error is\n\\[\nS_\\text{err} = S_p\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}\n\\]\nHence, we arrive at the following confidence interval\n\\[\n\\bar{x}_1 - \\bar{x}_2 \\pm t_{1-\\frac{\\alpha}{2}, n_1+n_2-2} S_p\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}\n\\]\n\nusing CSV, Distributions, HypothesisTests\n\nd1 = [\n    53.35674558144255,\n    53.45887516134873,\n    52.282838627926125,\n    52.98746570643515,\n    51.993167774733486,\n    53.373333606198,\n    55.75410538860477,\n    50.279496381439365,\n    53.6359586914001,\n    53.517705831707495,\n    53.70044994508253,\n    54.15592592604583,\n    53.55054914606446,\n    52.37319589109419,\n    53.4900750059897,\n    52.939458524079605,\n    52.16761562743534,\n    50.87140009591033,\n    53.144919157924924,\n    52.09084035473537,\n]\n\nd2 = [\n    48.23239011,\n    52.2735178,\n    52.07209917,\n    51.8813638,\n    50.89860065,\n    53.13910845,\n    50.88296219,\n    49.80725709,\n    49.04791179,\n    50.91491626,\n    50.73578183,\n    47.6154076,\n    50.89317122,\n    52.95593896,\n    51.90831274,\n    52.22159829,\n    51.60575821,\n    49.96704471,\n]\n\nxBar1, xBar2 = mean(d1), mean(d2)\nn1, n2 = length(d1), length(d2)\nalpha = 0.05\nt = quantile(TDist(n1 + n2 - 2), 1 - alpha / 2)\n\ns1, s2 = std(d1), std(d2)\nsP = sqrt(((n1 - 1) * s1^2 + (n2 - 1) * s2^2) / (n1 + n2 - 2))\n\nprintln(\"Calculating formula: \", (xBar1 - xBar2 - t * sP * sqrt(1 / n1 + 1 / n2), xBar1 - xBar2 + t * sP * sqrt(1 / n1 + 1 / n2)))\nprintln(\"Using confint() function: \", confint(EqualVarianceTTest(d1, d2); level=1 - alpha))\n\nCalculating formula: (1.1127539566753217, 2.9048648558844814)\nUsing confint() function: (1.1127539566753217, 2.9048648558844814)\n\n\n\n\n9.2.3 Population variances unkown and not assumed equal\nIn cases where the population variances are unknown and not assumed equal, the estimate for \\(S_\\text{err}\\) is given by\n\\[\nS_\\text{err} = \\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}\n\\]\nHence, in this case the statistic \\(T = \\frac{(\\overline{X}_1 - \\overline{X}_2) - (\\mu_1 - \\mu_2)}{S_\\text{err}}\\) is adapted to\n\\[\nT = \\frac{\\overline{X}_1 - \\overline{X}_2 - (\\mu_1 - \\mu_2)}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}\n\\]\nIt turns out that the above formula is only T-distributed with \\(n_1+n_2-2\\) degrees of freedom if the variances are equal, otherwise, it isn’t.\nHowever, the Satterthwaite approximation suggests that \\(T\\ \\ \\widetilde{approx}\\ \\ t(v)\\), where the degrees of freedom \\(v\\) is\n\\[\nv = \\frac{\\left(\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}\\right)^2}{\\frac{\\left(s_1^2/n_1\\right)^2}{n_1-1} + \\frac{\\left(s_2^2/n_2\\right)^2}{n_2-1}}\n\\]\nHence, we arrive at the confidence interval\n\\[\n\\bar{x}_1 - \\bar{x}_2 \\pm t_{1-\\frac{\\alpha}{2}, v} \\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}\n\\]\n\nusing CSV, Distributions, HypothesisTests\n\nd1 = [\n    53.35674558144255,\n    53.45887516134873,\n    52.282838627926125,\n    52.98746570643515,\n    51.993167774733486,\n    53.373333606198,\n    55.75410538860477,\n    50.279496381439365,\n    53.6359586914001,\n    53.517705831707495,\n    53.70044994508253,\n    54.15592592604583,\n    53.55054914606446,\n    52.37319589109419,\n    53.4900750059897,\n    52.939458524079605,\n    52.16761562743534,\n    50.87140009591033,\n    53.144919157924924,\n    52.09084035473537,\n]\n\nd2 = [\n    48.23239011,\n    52.2735178,\n    52.07209917,\n    51.8813638,\n    50.89860065,\n    53.13910845,\n    50.88296219,\n    49.80725709,\n    49.04791179,\n    50.91491626,\n    50.73578183,\n    47.6154076,\n    50.89317122,\n    52.95593896,\n    51.90831274,\n    52.22159829,\n    51.60575821,\n    49.96704471,\n]\n\nxBar1, xBar2 = mean(d1), mean(d2)\ns1, s2 = std(d1), std(d2)\nn1, n2 = length(d1), length(d2)\nalpha = 0.05\n\nv = (s1^2 / n1 + s2^2 / n2)^2 / ((s1^2 / n1)^2 / (n1 - 1) + (s2^2 / n2)^2 / (n2 - 1))\nt = quantile(TDist(v), 1 - alpha / 2)\n\nprintln(\"Calculating formula: \", (xBar1 - xBar2 - t * sqrt((s1^2 / n1 + s2^2 / n2)), xBar1 - xBar2 + t * sqrt((s1^2 / n1 + s2^2 / n2))))\nprintln(\"Using confint() function: \", confint(UnequalVarianceTTest(d1, d2); level=1 - alpha))\n\nCalculating formula: (1.0960161140340268, 2.9216026985257764)\nUsing confint() function: (1.0960161140340265, 2.921602698525777)\n\n\n\n\n9.2.4 More on the Satterthwaite approximation\nObserve that both sides of the “distributed as” (\\(\\sim\\)) symbol are random variables which depdend on the same random experiment.\nHence, the statement can be presented generally, as a case of the following format:\n\\[\nX(\\omega) \\sim F_{h(\\omega)}\n\\]\nwhere \\(\\omega\\) is a point in the sample space.\nHere, \\(X(\\omega)\\) is a random variabe, and \\(F\\) is a distribution that depends on a parameter \\(h\\), which depends on \\(\\omega\\).\nIn our case of the Satterthwaite approximation, \\(h\\) is \\(v\\), defined above.\n\n\n\n\n\n\nWhy both sides of the \\(\\sim\\) symbol are random variables which depend on the same random experiment\n\n\n\nWhen we had finished a random experiment, we obtained a sample \\(\\omega\\) from the sample space.\nThen, we can derive some statistic (\\(X(\\omega)\\)) from the sample, which means that \\(X\\) is a random variable. In addition, under the same experiment, \\(X\\) should be distributed as some distribution \\(F\\), which may be defined by some parameter \\(h\\), saying the degrees of freedom. Obviously, \\(h\\) itself depends on the same sample obtained from the sample space before.\n\n\nBy using the inverse probability transformation, the above formula is equivalent to\n\\[\nF_{h(\\omega)}\\left(X(\\omega)\\right) \\sim \\text{Uniform}(0, 1)\n\\]\nThis means that the Satterthwaite approximation is a better approximative distribution close to the true distribution which \\(T\\) calculated in the case of population variances unknown and not assumed equal is distributed as in comparison with the alternative of treating \\(h\\) as simply dependent on the number of observations made (\\(n_1+n_2-2\\)).\nWe can make a simple validation using Q-Q plot: \\(t(v)\\) is more similar with the true distribution of \\(T\\) than \\(t(n_1+n_2-2)\\)\n\nusing Distributions, Statistics, Random, CairoMakie\n\nRandom.seed!(0)\n\nmu1, sig1, n1 = 0, 2, 8\nmu2, sig2, n2 = 0, 30, 15\n\ndist1 = Normal(mu1, sig1)\ndist2 = Normal(mu2, sig2)\n\nN = 10^6\ntdArray = Array{Tuple{Float64,Float64}}(undef, N)\n\nfunc(s1, s2, n1, n2) = (s1^2 / n1 + s2^2 / n2)^2 / ((s1^2 / n1)^2 / (n1 - 1) + (s2^2 / n2)^2 / (n2 - 1))\n\nfor i in 1:N\n    x1Data = rand(dist1, n1)\n    x2Data = rand(dist2, n2)\n    x1Bar, x2Bar = mean(x1Data), mean(x2Data)\n    s1, s2 = std(x1Data), std(x2Data)\n    tStatistics = (x1Bar - x2Bar) / sqrt(s1^2 / n1 + s2^2 / n2)\n    tdArray[i] = (tStatistics, func(s1, s2, n1, n2))\nend\nsort!(tdArray, by=first)\n\ninvVal(v, i) = quantile(TDist(v), i / (N + 1))\n\nxCoords = Array{Float64}(undef, N)\nyCoords1 = Array{Float64}(undef, N)\nyCoords2 = Array{Float64}(undef, N)\n\nfor i in 1:N\n    xCoords[i] = first(tdArray[i])\n    yCoords1[i] = invVal(last(tdArray[i]), i)\n    yCoords2[i] = invVal(n1 + n2 - 2, i)\nend\n\nfig, ax = qqplot(xCoords, yCoords1; color=:blue, label=\"Calculated v\", qqline=:identity)\nqqplot!(ax, xCoords, yCoords2; color=:red, label=\"Fixed v\")\naxislegend(ax; position=:lt)\nfig\n\n\n\n\n\n\n\n9.3 Confidence intervals for proportions\nIn certain inference settings the parameter of interest is a population proportion.\nWhen carrying out inference for a proportion we assume that there exists some unknown population proportion \\(p \\in (0, 1)\\).\nWe then sample an i.i.d. sample of observations \\(I_1, ..., I_n\\), where for the \\(i\\)’th observation, \\(I_i = 0\\) if the event in question does not happen, and \\(I_i = 1\\) if the event occurs.\nA natural estimator for the proportion is then the sample mean of \\(I_1, ..., I_n\\), which we denote\n\\[\n\\hat{p} = \\frac{\\sum_{i=1}^{n}I_i}{n}\n\\]\nPlease note that \\(\\overline{X} \\sim N(\\mu, \\frac{\\sigma^2}{n})\\) as \\(n \\rightarrow \\infty\\), so is \\(\\hat{p}\\).\nNow observe that each \\(I_i\\) is a Bernoulli random variable with success probability \\(p\\). Under the i.i.d assumption this means that the numerator of the above formula (i.e. \\(\\sum_{i=1}^{n}I_i\\)) is binomially distributed with parameters \\(n\\) and \\(p\\). Hence\n\\[\nE\\left[\\sum_{i=1}^{n}I_i\\right] = np\n\\]\nand\n\\[\n\\text{Var}(\\sum_{i=1}^{n}I_i) = np(1-p)\n\\]\nSo we have\n\\[\nE(\\hat{p}) = p\n\\]\nand\n\\[\n\\text{Var}(\\hat{p}) = \\frac{p(1-p)}{n}\n\\]\nHence, \\(\\hat{p}\\) is an unbiased and consistent estimator of \\(p\\). That is, on average \\(\\hat{p}\\) estimates \\(p\\) perfectly (unbiased), and if more observations are collected the variance of the estimator vanishes and then \\(\\hat{p} \\rightarrow p\\) (consistent).\nFurthermore, we can use the central limit theorem to create a normal approximation for the distribution of \\(\\hat{p}\\) and yield an approximate condidence interval.\nDue to the fact \\(\\hat{p} \\sim N(p, \\frac{p(1-p)}{n})\\) as \\(n \\rightarrow \\infty\\), we have\n\\[\n\\tilde{Z}_n = \\frac{\\hat{p}-p}{\\sqrt{\\frac{p(1-p)}{n}}}\n\\]\nwhich is a random variable that approximately follows a standard normal distribution. The approximation becomes exact as \\(n\\) grows. Due to the fact that \\(\\hat{p}\\) is an unbiased and consistent estimator of \\(p\\), it’s reasonable that we replace \\(p\\) with \\(\\hat{p}\\), and then we have\n\\[\n\\hat{Z}_n = \\frac{\\hat{p}-p}{\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}}\n\\]\nSo we have\n\\[\nP(z_\\frac{\\alpha}{2} \\le \\hat{Z}_n \\le z_{1-\\frac{\\alpha}{2}}) \\approx 1-\\alpha\n\\]\nand then along with the fact that \\(z_\\frac{\\alpha}{2} = -z_{1-\\frac{\\alpha}{2}}\\) as follows\n\\[\n\\begin{align}\n1-\\alpha &\\approx P(-z_{1-\\frac{\\alpha}{2}} \\le \\hat{Z}_n \\le z_{1-\\frac{\\alpha}{2}}) \\\\\n&= P(-z_{1-\\frac{\\alpha}{2}} \\le \\frac{\\hat{p}-p}{\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}} \\le z_{1-\\frac{\\alpha}{2}}) \\\\\n&= P(\\hat{p} - z_{1-\\frac{\\alpha}{2}} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\le p \\le \\hat{p} + z_{1-\\frac{\\alpha}{2}} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}})\n\\end{align}\n\\]\nWe thus arrive the following approximate confidence interval for proportions\n\\[\n\\hat{p} \\pm z_{1-\\frac{\\alpha}{2}} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n\\]\nSimilarly, we have the confidence interval for the case of two populations\n\\[\n\\hat{p}_1 - \\hat{p}_2 \\pm z_{1-\\frac{\\alpha}{2}} \\sqrt{\\frac{\\hat{p}_1(1-\\hat{p}_1)}{n} + \\frac{\\hat{p}_2(1-\\hat{p}_2)}{n}}\n\\]\n\nusing CSV, DataFrames, CategoricalArrays, Distributions\n\ndat = CSV.read(\"./data/purchaseData.csv\", DataFrame)\nprintln(\"Levels of Grade: \", levels(dat.Grade))\nprintln(\"Data points: \", nrow(dat))\n\nn = sum(.!(ismissing.(dat.Grade)))\nprintln(\"Non-missing data points: \", n)\ndat2 = dropmissing(dat[:, [:Grade]], :Grade)\n\ngradeInQuestion = \"E\"\nindicatorVector = dat2.Grade .== gradeInQuestion\nnumSuccess = sum(indicatorVector)\nphat = numSuccess / n\nserr = sqrt(phat * (1 - phat) / n)\n\nalpha = 0.05\nconfidencePercent = 100 * (1 - alpha)\nzVal = quantile(Normal(), 1 - alpha / 2)\nconfInt = (phat - zVal * serr, phat + zVal * serr)\n\nprintln(\"\\nOut of $n non-missing observations, $numSuccess are at level $gradeInQuestion.\")\nprintln(\"Hence a point estimate for the proportion of grades at level $gradeInQuestion is $phat.\")\nprintln(\"A $confidencePercent% confidence interval for the proportion of level $gradeInQuestion is:\\n$confInt\")\n\nLevels of Grade: String1[\"A\", \"B\", \"C\", \"D\", \"E\"]\nData points: 200\nNon-missing data points: 187\n\nOut of 187 non-missing observations, 61 are at level E.\nHence a point estimate for the proportion of grades at level E is 0.32620320855614976.\nA 95.0% confidence interval for the proportion of level E is:\n(0.2590083767381328, 0.3933980403741667)\n\n\n\n9.3.1 Sample size planing\nDenote the confidence interval of the proportion as \\(\\hat{p} \\pm E\\) where \\(E\\) is the margin of error or half the width of the confidence interval, denoted by\n\\[\nE = z_{1-\\frac{\\alpha}{2}}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n\\]\nWe may often want to plan an experiment or a sampling scheme such that \\(E\\) is not too wide.\nSay we want \\(E \\le \\epsilon\\) with the confidence probability \\(1-\\alpha\\), we have\n\\[\nE = z_{1-\\frac{\\alpha}{2}}\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\le \\epsilon\n\\]\nGiven that \\(x(1-x)\\) is maximized at \\(x=1/2\\) with a maximal value of \\(1/4\\). Hence,\n\\[\nE \\le \\frac{z_{1-\\frac{\\alpha}{2}}}{2\\sqrt{n}} \\le \\epsilon\n\\]\nFinally, we have\n\\[\nn \\ge \\frac{z_{1-\\frac{\\alpha}{2}}^2}{4\\epsilon^2}\n\\]\n\n\n9.3.2 Validity of the approximation\nIn many cases, this confidence interval approximation for the proportion works well, however for small sample sizes \\(n\\) or values of \\(p\\) near \\(0\\) or \\(1\\), this is often too crude of an approximation. A consequence is that one may obtain a confidence interval that isn’t actually a \\(1-\\alpha\\) confidence interval, but rather has a different coverage probability.\nOne common rule of thumb used to decide if the confidence interval for the proportion is valid is to require that both the product \\(np\\) and the product \\(n(1-p)\\) be at least \\(10\\).\nHere, we expore some combinations of \\(n\\) and \\(p\\). For each combination, we use \\(N\\) Monte Carlo expriments and calculate the following\n\\[\n(1-\\alpha) - \\frac{1}{N} \\sum_{k=1}^{N}\\mathbf{1}\\left\\{p \\in \\left[\\hat{p} - z_{1-\\frac{\\alpha}{2}} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}, \\hat{p} + z_{1-\\frac{\\alpha}{2}} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\\right]\\right\\}\n\\]\nThis estimated difference of the actual converage probability of the confidence interval and the desired confidence level \\(1-\\alpha\\) is a measure of the accuracy of the confidence level. We expect this difference to be almost \\(0\\) if the approximation is good. Otherwise, a higher absolute difference is oberved.\n\nusing Random, Distributions, CairoMakie\n\nN = 5e3\nalpha = 0.05\nconfLevel = 1 - alpha\nz = quantile(Normal(), 1 - alpha / 2)\n\nfunction randCI(n, p)\n    sample = rand(n) .&lt; p\n    pHat = sum(sample) / n\n    serr = sqrt(pHat * (1 - pHat) / n)\n    (pHat - z * serr, pHat + z * serr)\nend\ncover(p, ci) = ci[1] &lt;= p && p &lt;= ci[2]\n\npGrid = 0.1:0.01:0.9\nnGrid = 5:1:50\nerrs = zeros(length(nGrid), length(pGrid))\n\nfor i in 1:length(nGrid)\n    for j in 1:length(pGrid)\n        Random.seed!(1234)\n        n, p = nGrid[i], pGrid[j]\n        coverageRatio = sum([cover(p, randCI(n, p)) for _ in 1:N]) / N\n        errs[i, j] = confLevel - coverageRatio\n    end\nend\n\nfig, ax1, hm1 = heatmap(pGrid, nGrid, errs'; colormap=to_colormap([\"white\", \"black\"]))\nax2, hm2 = heatmap(fig[2, 1], pGrid, nGrid, errs' .&lt;= 0.04; colormap=to_colormap([\"black\", \"white\"]))\nColorbar(fig[1, 2], hm1)\nfig\n\n\n\n\n\n\n\n9.4 Confidence interval for the variance of a normal population\nFirst, a point estimator of the population variance is the sample variance\n\\[\ns^2 = \\frac{1}{n-1}\\sum_{i=1}^{n}(X_i-\\overline{X})^2\n\\]\nWe have known that \\(\\frac{(n-1)s^2}{\\sigma^2} \\sim \\chi_{n-1}^2\\). So denoting the \\(\\gamma\\)-quantile of this distribution via \\(\\chi_{\\gamma,n-1}^2\\), we have\n\\[\nP(\\chi_{\\frac{\\alpha}{2},n-1}^2 \\le \\frac{(n-1)s^2}{\\sigma^2} \\le \\chi_{1-\\frac{\\alpha}{2},n-1}^2) = 1-\\alpha\n\\]\nThen we have\n\\[\nP(\\frac{(n-1)s^2}{\\chi_{1-\\frac{\\alpha}{2},n-1}^2} \\le \\sigma^2 \\le \\frac{(n-1)s^2}{\\chi_{\\frac{\\alpha}{2},n-1}^2}) = 1-\\alpha\n\\]\nNote: this equality holds only if the data is normally distributed.\n\nusing Distributions\n\ndat = rand(Normal(0, 1), 1000)\nn, s, alpha = length(dat), std(dat), 0.05\n\nci = ((n - 1) * s^2 / quantile(Chisq(n - 1), 1 - alpha / 2),\n    (n - 1) * s^2 / quantile(Chisq(n - 1), alpha / 2))\n\nprintln(\"Point estimate for the variance: \", s^2)\nprintln(\"Confidence interval for the variance: \", ci)\n\nPoint estimate for the variance: 0.9999905881991535\nConfidence interval for the variance: (0.9177790230416273, 1.0938240508530526)\n\n\n\n9.4.1 Sensitivity of the normal assumption\nAs mentioned before, this confidence interval for the variance of a normal population only holds for normally distributed population and is more sensitive about the normal assumption than the other confidence intervals constructed before.\nWe’ll find that the sample variance distributions of a normal distribution and a logistic distribution are quite different, though they have the same pupulation mean \\(\\mu\\) and population variance \\(\\sigma^2\\), and the PDF’s curve shape of the logistic distribution is somewhat similar with the normal.\nThe logistic distribution is defined by the location and scale parameters \\(\\mu\\) and \\(\\eta\\), and the PDF is\n\\[\nf(x) = \\frac{e^{-\\frac{x-\\mu}{\\eta}}}{\\eta(1+e^{-\\frac{x-\\mu}{\\eta}})^2}\n\\]\nwith mean \\(\\mu\\) and variance \\(\\sigma^2 = \\eta^2\\pi^2/3\\).\n\nusing Distributions, CairoMakie\n\nmu, sig = 2, 3\neta = sqrt(3) * sig / pi\n\nn, N = 15, 10^7\ndNormal = Normal(mu, sig)\ndLogistic = Logistic(mu, eta)\nxGrid = -8:0.1:12\n\nsNormal = [var(rand(dNormal, n)) for _ in 1:N]\nsLogistic = [var(rand(dLogistic, n)) for _ in 1:N]\n\nfig = Figure()\nax1 = Axis(fig[1, 1];\n    xlabel=\"x\",\n    ylabel=\"Density\")\nlines!(ax1, xGrid, pdf.(dNormal, xGrid); color=:blue, label=\"Normal\")\nlines!(ax1, xGrid, pdf.(dLogistic, xGrid); color=:red, label=\"Logistic\")\naxislegend(ax1)\nax2 = Axis(fig[2, 1],\n    xlabel=\"Sample Variance\",\n    ylabel=\"Density\",\n    limits=(0, 30, 0, 0.14))\nstephist!(ax2, sNormal; bins=200, color=:blue, normalization=:pdf, label=\"Normal\")\nstephist!(ax2, sLogistic; bins=200, color=:red, normalization=:pdf, label=\"Logistic\")\naxislegend(ax2)\nfig\n\n\n\n\nIn addition, we can check the actual confidence interval coverage under different model assumptions:\n\nusing Distributions, CairoMakie\n\nmu, sig = 2, 3\neta = sqrt(3) * sig / pi\nn, N = 15, 10^4\ndNormal = Normal(mu, sig)\ndLogistic = Logistic(mu, eta)\nalphaUsed = 0.001:0.001:0.1\n\nfunction alphaSimulator(dist, n, alpha)\n    popVar = var(dist)\n    coverageCount = 0\n    for _ in 1:N\n        sVar = var(rand(dist, n))\n        Lo = (n - 1) * sVar / quantile(Chisq(n - 1), 1 - alpha / 2)\n        Up = (n - 1) * sVar / quantile(Chisq(n - 1), alpha / 2)\n        coverageCount += Lo &lt; popVar && popVar &lt; Up\n    end\n    1 - coverageCount / N\nend\n\nfig, ax = ablines(0, 1; color=:green, label=\"y = x\")\nscatter!(ax, alphaUsed, alphaSimulator.(dNormal, n, alphaUsed); color=:blue, label=\"Normal\")\nscatter!(ax, alphaUsed, alphaSimulator.(dLogistic, n, alphaUsed); color=:red, label=\"Logistic\")\naxislegend(ax; position=:lt)\nfig\n\n\n\n\n\n\n\n9.5 Bootstrap confidence intervals\nBootstrap, also called empirical bootstrap, is a useful technique which relies on resampling from the observed data \\(x_1, ..., x_n\\) with replacement in order to empirically construct the distribution of the point estimator for some unknown population parameters.\nOne way in which this resampling can be conducted is to apply the inverse probability transform on the empirical cumulative distribution function.\n\n\n\n\n\n\nNote\n\n\n\n\nObtain a sample: \\(\\mathbf{X} = (x_1, ..., x_n)\\).\nObtain the empirical cumulative distribution function \\(F_X(\\mathbf{X})\\) based on \\(\\mathbf{X}\\).\nUse the inverse probability transformation: \\(\\mathbf{U} = F_X(\\mathbf{X}) \\Longrightarrow \\mathbf{X} = F_X^{-1}(\\mathbf{U})\\).\nResample \\(\\mathbf{X}\\) via resampling \\(\\mathbf{U} \\sim U(0, 1)\\) with replacement.\n\nIt seems that we sample a large number of “new” samples from the population, and then we can get a large number of point estimators, which then are used to construct the empirical distribution of the point estimator. Finally, to get the \\(1-\\alpha\\) confidence interval, we can just get the quantiles of \\(\\frac{\\alpha}{2}\\) and \\(1-\\frac{\\alpha}{2}\\).\nBootstrap requires that the number of observations is not too small.\n\n\nHowever, from an implementation perspective, a simpler alternative is to consider the data points \\(x_1, ..., x_n\\), and then randomly sample \\(n\\) discrete uniform indexes, \\(j_1, ..., j_n\\) each in the range \\(\\{1, ..., n\\}\\). The resampled data denoted by \\(x^* = (x_1^*, ..., x_n^*)\\) is then\n\\[\nx^* = (x_{j_1}, ..., x_{j_n})\n\\]\nThat is, each point in the resampeld data is a random observation from the original data, where we allow to sample with replacement.\nIn Julia, \\(x^* = \\text{rand}(\\mathbf{X}, n)\\), where we use the rand() method to uniformally sample \\(n\\) random copies of elements in \\(\\mathbf{X}\\) with replacement.\nThe idea of empirical bootstrap is now to repeat the resampling a large number of times, say \\(N\\), and for each resampled data vector, \\(x^*(1), ..., x^*(N)\\) to compute the parameter estimate. If the parameter estimate is denoted by the function \\(h: R^n \\mapsto R\\), then we end up with values\n\\[\n\\begin{align}\nh^*(1) &= h(x_1^*(1), ..., x_n^*(1)) \\\\\nh^*(2) &= h(x_1^*(2), ..., x_n^*(2)) \\\\\n&\\vdots \\\\\nh^*(N) &= h(x_1^*(N), ..., x_n^*(N))\n\\end{align}\n\\]\nFinally, a bootstrap confidence interval is determined by computing the respective lower and upper \\((\\frac{\\alpha}{2}, 1-\\frac{\\alpha}{2})\\) quantiles of the sequence \\(h^*(1), ..., h^*(N)\\).\n\nusing Random, Distributions, CairoMakie\n\nRandom.seed!(0)\n\nsampleData = [\n    53.35674558144255,\n    53.45887516134873,\n    52.282838627926125,\n    52.98746570643515,\n    51.993167774733486,\n    53.373333606198,\n    55.75410538860477,\n    50.279496381439365,\n    53.6359586914001,\n    53.517705831707495,\n    53.70044994508253,\n    54.15592592604583,\n    53.55054914606446,\n    52.37319589109419,\n    53.4900750059897,\n    52.939458524079605,\n    52.16761562743534,\n    50.87140009591033,\n    53.144919157924924,\n    52.09084035473537,\n]\nn, N = length(sampleData), 10^6\nalpha = 0.1\n\n# sampling with replacement\nbootstrapSampleMeans = [mean(rand(sampleData, n)) for _ in 1:N]\nLmean = quantile(bootstrapSampleMeans, alpha / 2)\nUmean = quantile(bootstrapSampleMeans, 1 - alpha / 2)\n\nprintln(\"Bootstrap confidence interval for the mean: \", (Lmean, Umean))\n\nfig, ax = stephist(bootstrapSampleMeans; bins=1000, color=:blue, normalization=:pdf, label=\"Sample means\")\nvlines!(ax, [Lmean, Umean]; color=:red, label=\"90% CI\")\naxislegend(ax)\nfig\n\nBootstrap confidence interval for the mean: (52.52963545344743, 53.375601378187525)\n\n\n\n\n\nSimply, we can carry out a computational experiment to show that if the number of sample observations is not very large, then the coverage probability of bootstrapped confidence interval is only approximately \\(1-\\alpha\\), but not exactly. However, as the sample size \\(n\\) grows, the coverage probability converges to the desired \\(1-\\alpha\\).\n\nusing Random, Distributions\n\nRandom.seed!(0)\n\nlambda = 0.1\ndist = Exponential(1 / lambda)\nactualMedian = median(dist)\n\nM = 10^3\nN = 10^4\nnRange = 2:2:20\nalpha = 0.05\n\nfor n in nRange\n    coverageCount = 0\n    for _ in 1:M\n        sampleData = rand(dist, n)\n        bootstrapSampleMeans = [median(rand(sampleData, n)) for _ in 1:N]\n        Lo = quantile(bootstrapSampleMeans, alpha / 2)\n        Up = quantile(bootstrapSampleMeans, 1 - alpha / 2)\n        coverageCount += Lo &lt; actualMedian && actualMedian &lt; Up\n    end\n    println(\"n = \", n, \"\\t coverage = \", coverageCount / M)\nend\n\nn = 2    coverage = 0.499\nn = 4    coverage = 0.889\nn = 6    coverage = 0.942\nn = 8    coverage = 0.924\nn = 10   coverage = 0.936\nn = 12   coverage = 0.934\nn = 14   coverage = 0.943\nn = 16   coverage = 0.945\nn = 18   coverage = 0.954\nn = 20   coverage = 0.927\n\n\n\n\n9.6 Prediction intervals\nA prediction interval tells us a predicted range that a single next observation of data is expected to fall within with some level of confidence. This differs from a confidence interval which indicates how confident we are of a particular parameter that we are trying to estimate.\nIn brief, a prediction interval is constructed based on the distribution of a population itself from which we sample observations, while a confidence interval is constructed based on the distribution of a particular parameter which we are trying to estimate (e.g. \\(\\overline{X} \\sim N(\\mu, \\frac{\\sigma^2}{n})\\)).\nSuppose we have a sequence of data points (observations) \\(x_1, x_2, x_3, ...\\), which come from a normal distribution and are assumed i.i.d. Further assume that we observed the first \\(n\\) data points \\(x_1, ..., x_n\\), but have not yet observed \\(X_{n+1}\\). Note that we use lower case \\(x\\) for values observed and upper case \\(X\\) for yet unobserved random variables.\nIn this case, a \\(1-\\alpha\\) prediction interval for the single future observation \\(X_{n+1}\\) is given by\n\\[\n\\bar{x} - t_{1-\\frac{\\alpha}{2},n-1}s\\sqrt{1+\\frac{1}{n}} \\le X_{n+1} \\le \\bar{x} + t_{1-\\frac{\\alpha}{2},n-1}s\\sqrt{1+\\frac{1}{n}}\n\\]\nwhere \\(\\bar{x}\\) and \\(s\\) are respectively the sample mean and sample standard deviation computed from \\(x_1, ..., x_n\\).\nNote that as the number of observations \\(n\\) grows, the bounds of the prediction interval decreases towards\n\\[\n\\bar{x} - z_{1-\\frac{\\alpha}{2}}s \\le X_{n+1} \\le \\bar{x} - z_{1-\\frac{\\alpha}{2}}s\n\\]\nand finally has an expected width close to \\(2z_{1-\\frac{\\alpha}{2}}\\sigma\\).\n\n\n\n\n\n\nNote\n\n\n\nSuppose \\(X\\) is a normally distributed variable (i.e. \\(X \\sim N(\\mu, \\sigma^2)\\)), and then we have \\(U = \\frac{X-\\mu}{\\sigma} \\sim N(0, 1)\\).\nFor \\(U\\), we have a \\(1-\\alpha\\) prediction interval \\(-z_{1-\\frac{\\alpha}{2}} \\le U \\le z_{1-\\frac{\\alpha}{2}}\\), and then we have \\(\\mu - z_{1-\\frac{\\alpha}{2}}\\sigma \\le X \\le \\mu + z_{1-\\frac{\\alpha}{2}}\\sigma\\), which is a \\(1-\\alpha\\) prediction interval of \\(X\\) in the case of population mean and population variance known.\nSimply, a prediction interval is such an interval constructed based on the distribution of observations and needs to cover a \\(1-\\alpha\\) proportion of this distribution.\n\n\n\nusing Random, Statistics, Distributions, CairoMakie\n\nRandom.seed!(0)\n\nmu, sig = 50, 5\ndist = Normal(mu, sig)\nalpha = 0.01\nnMax = 40\n\nobservations = rand(dist, 1)\npiLarray, piUarray = [], []\n\nfor _ in 2:nMax\n    xNew = rand(dist)\n    push!(observations, xNew)\n\n    xBar, sd = mean(observations), std(observations)\n    n = length(observations)\n    tVal = quantile(TDist(n - 1), 1 - alpha / 2)\n    delta = tVal * sd * sqrt(1 + 1 / n)\n    piL, piU = xBar - delta, xBar + delta\n\n    push!(piLarray, piL)\n    push!(piUarray, piU)\nend\n\nfig, ax = scatter(1:nMax, observations; color=:blue, label=\"Observations\")\nscatterlines!(2:nMax, piUarray; marker=:cross, color=:red, markercolor=:black, label=\"Prediction Interval\")\n\nscatterlines!(2:nMax, piLarray; marker=:cross, color=:red, markercolor=:black)\naxislegend(ax)\nax.xlabel = \"Number of observations\"\nax.ylabel = \"Value\"\nfig\n\n\n\n\n\n\n9.7 Credible intervals\nThe concept of credible intervals comes from the field of Bayesian statistics.\nIn general, we often need to find an interval \\([l, u]\\) such that given some probability density \\(f(x)\\), the interval satisfies\n\\[\n\\int_l^u f(x)dx = 1-\\alpha\n\\]\nThis is needed for confidence intervals, prediction intervals, and credible intervals.\nHowever, as long as \\(\\alpha &lt; 1\\), there is more than one interval \\([l, u]\\) that satisfies the above formula.\nIn certain cases, there is a “natural” interval. For example, for a symmetric distribution, using equal quantiles is natural (i.e. \\(l = z_{\\frac{\\alpha}{2}}\\) and \\(u = z_{1-\\frac{\\alpha}{2}}\\)). In such cases, the mean is also the median and further if the density is unimodal (has a single maximum) the mean and median are also the mode.\nHowever, consider asymmetric distribution, there isn’t an immediate “natrual” choice for \\(l\\) and \\(u\\). There are three types of intervals we often use:\n\nClassic interval: this type of interval has the mode of the density (assuming the density is unimodal) at its center between \\(l\\) and \\(u\\). An alternative is to use mean or median at the center. That is, assuming the centrality measure (mode, mean, or median) is \\(m\\), we have \\([l, u] = [m-E, m+E]\\). One way to define \\(E\\) is via\n\n\\[\nE = \\max\\{\\epsilon \\ge 0: \\int_{m-\\epsilon}^{m+\\epsilon} f(x)dx \\le 1-\\alpha\\}\n\\]\n\nEqual tail interval: this type of interval simply sets \\(l\\) and \\(u\\) as the \\(\\frac{\\alpha}{2}\\) and \\(1-\\frac{\\alpha}{2}\\) quantiles, respectively. Namely,\n\n\\[\n\\frac{\\alpha}{2} = \\int_{-\\infty}^l f(x)dx\n\\]\nand\n\\[\n1 - \\frac{\\alpha}{2} = \\int_{u}^{\\infty} f(x)dx\n\\]\n\nHighest density interval: this type of interval seeks to cover the part of the support that is most probable. A consequence is that if the density is unimodal then this highest density interval is also the narrowest possible confidence interval. We can crudely does so by starting with a high-density value and decreasing it gradually while seeking for the associated interval \\([l, u]\\). An alternative would be to gradually increment \\(l\\) each time finding a corresponding \\(u\\) that satisfies the above formula and within this search to choose the interval that minimizes the width \\(u-l\\).\n\nFor a symmetric and unimodal distribution, all three of these confidence intervals agree.\nWe now explain the credible intervals. In the Bayesian setting, we treat the unknown parameter \\(\\theta\\) as a random variable, this is totally different from the classical case where we treat the unknown parameter \\(\\theta\\) as a fixed value. The process of inference is based on observing data, \\(x = (x_1, ..., x_n)\\) which has a distribution depending on the unknown parameter \\(\\theta\\), and fusing it with the prior distribution \\(f(\\theta)\\) that the unknown parameter \\(\\theta\\) is distributed as before observing data \\(x = (x_1, ..., x_n)\\) to obtain the posterior distribution \\(f(\\theta|x)\\) which the unknown parameter \\(\\theta\\) is distributed as after observing data \\(x = (x_1, ..., x_n\\).\nHere too, as in the frequentist case, we may wish to describe an interval where it is likely that our parameter lies. Then for a fixed confidence interval \\(1-\\alpha\\), seek \\([l, u]\\), such that\n\\[\n\\int_l^u f(\\theta|x)d\\theta = 1-\\alpha\n\\]\nThere is a basic difference between confidence intervals in the frequentist setting and credible intervals in the Bayesian setting:\nFor a given \\(1-\\alpha\\) interval \\([L, U]\\),\n\nIn the frequentist setting, the unknown parameter \\(\\theta\\) is a fixed value while \\(L\\) and \\(U\\) are random variables depending on observed data \\(X\\) which is a random variable. So this is why we often say the confidence interval \\([L, U]\\) will cover the unknown but fixed parameter \\(\\theta\\) under the confidence level \\(1-\\alpha\\).\nIn the Bayesian setting, the unknown parameter \\(\\theta\\) is a random variable while \\(L\\) and \\(U\\) are deterministic values. So we will see the unknown parameter \\(\\theta\\) will fall within the credible interval \\([L, U]\\) with the probability \\(1-\\alpha\\).\n\n\nusing Distributions, CairoMakie\n\nalpha, beta = 8, 2\ndat = [2, 1, 0, 0, 1, 0, 2, 2, 5, 2, 4, 0, 3, 2, 5, 0]\n\nnewAlpha, newBeta = alpha + sum(dat), beta + length(dat)\npost = Gamma(newAlpha, newBeta)\n\nxGrid = quantile(post, 0.01):0.001:quantile(post, 0.99)\nsignificance = 0.9\nhalfAlpha = (1 - significance) / 2\n\ncoverage(l, u) = cdf(post, u) - cdf(post, l)\n\nfunction classicCI(dist)\n    l, u = mode(dist), mode(dist)\n    while coverage(l, u) &lt; significance\n        l -= 0.00001\n        u += 0.00001\n    end\n    (l, u)\nend\nequalTailCI(dist) = (quantile(dist, halfAlpha), quantile(dist, 1 - halfAlpha))\nfunction highestDensityCI(dist)\n    height = 0.999 * maximum(pdf.(dist, xGrid))\n    l, u = mode(dist), mode(dist)\n    while coverage(l, u) &lt; significance\n        range = filter(theta -&gt; pdf(dist, theta) &gt; height, xGrid)\n        l, u = minimum(range), maximum(range)\n        height -= 0.00001\n    end\n    (l, u)\nend\n\nl1, u1 = classicCI(post)\nl2, u2 = equalTailCI(post)\nl3, u3 = highestDensityCI(post)\n\nprintln(\"Classical: \", (l1, u1), \"\\tWidth: \", u1 - l1, \"\\tCoverage: \", coverage(l1, u1))\nprintln(\"Equal tails: \", (l2, u2), \"\\tWidth: \", u2 - l2, \"\\tCoverage: \", coverage(l2, u2))\nprintln(\"Highest density: \", (l3, u3), \"\\tWidth: \", u3 - l3, \"\\tCoverage: \", coverage(l3, u3))\n\nfig, ax = lines(xGrid, pdf.(post, xGrid); color=:black, label=\"Gamma Posterior Distribution\")\nrangebars!(ax, [-0.00025], [l1], [u1]; direction=:x, whiskerwidth=10, color=:blue, label=\"Classic CI\")\nrangebars!(ax, [-0.0005], [l2], [u2]; direction=:x, whiskerwidth=10, color=:red, label=\"Equal Tail CI\")\nrangebars!(ax, [-0.00075], [l3], [u3]; direction=:x, whiskerwidth=10, color=:green, label=\"Highest Density CI\")\naxislegend(ax)\nfig\n\nClassical: (467.4288304558984, 828.5711695441016)   Width: 361.14233908820324   Coverage: 0.9000000065035687\nEqual tails: (496.70307973762834, 855.7332000231892)    Width: 359.0301202855608    Coverage: 0.9\nHighest density: (485.57452668179576, 843.1445266817958)    Width: 357.57000000000005   Coverage: 0.9006729463099745"
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#hypothesis-testing",
    "href": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#hypothesis-testing",
    "title": "Probability and statistics with Julia",
    "section": "10 Hypothesis testing",
    "text": "10 Hypothesis testing\nTo perform a hypothesis testing, first, we need to partition the parameter space \\(\\Theta\\) as two hypotheses:\n\nNull hypothesis: \\(H_0: \\theta \\in \\Theta_0\\)\nAlternative hypothesis: \\(H_1: \\theta \\in \\Theta_1\\)\n\nAnd then, we need to determine the test statistic used to perform the hypothesis testing. Once this is done, we can calculate the test statistic and then get the rejection region (e.g. \\((-\\infty, ICDF(\\frac{\\alpha}{2}))\\) and \\((ICDF(1-\\frac{\\alpha}{2}), +\\infty)\\) for a two-sided hypothesis test) or the p-value (\\(CDF(\\text{the value of test statistic})\\)) under certain confidence level \\(1-\\alpha\\) under \\(H_0\\) (the distribution of the test statistic is often known under \\(H_0\\) but it’s usually unknown under \\(H_1\\)).\nFinally, make a statement (rejecting or not rejecting \\(H_0\\)) under the assumption of null hypothesis based on some confidence level.\nSo there are several key concepts concerning a hypothesis testing: two alternative hypotheses, confidence level, test statistic, the distribution of the test statistic under the null hypothesis, rejection region or \\(p\\)-value.\n\n10.1 Single sample hypothesis tests for the mean\nAssume that the observations \\(X_1, ..., X_n\\) are normally distributed and we want to know whether this sample is from a population with \\(\\mu = \\mu_0\\) or not (\\(\\mu \\ne \\mu_0\\)).\nIn this case, we set up the hypothesis as two-sided (which means that \\(\\mu &lt; \\mu_0\\) and \\(\\mu &gt; \\mu_0\\) are both plausible) and the confidence level \\(1-\\alpha\\).\n\n10.1.1 Population variance known (Z-Test)\nAssume that \\(\\sigma\\) is known. Under \\(H_0\\), \\(\\overline{X}\\) follows a normal distribution with mean \\(\\mu_0\\) and variance \\(\\frac{\\sigma^2}{n}\\). Hence, it holds that under \\(H_0\\) the Z-statistic\n\\[\nZ = \\frac{\\overline{X}-\\mu_0}{\\sigma/n}\n\\]\nfollows a standard normal distribution (\\(Z \\sim N(0, 1)\\)).\nIn this case, under the null hypothesis, \\(Z\\) is a standard normal random variable, and hence to carry out a hypothesis test we observe its position relative to a standard normal distribution. Specifically, we check if it lies within the rejection region or not, and if it does, we reject the null hypothesis, otherwise we don’t. In addition, we can also calculate the \\(p\\)-value (\\(p = 2P(Z &gt; |z|)\\)). If \\(p\\)-value is less than some pre-designated significance level \\(\\alpha\\), then we can reject \\(H_0\\) or we don’t.\n\nusing Random, Distributions, HypothesisTests\n\nRandom.seed!(0)\n\nmu0 = 25\nmu1, sigma = 27, 2\nn = 100\nd = rand(Normal(mu1, sigma), n)\nxBar = mean(d)\n\ntestStatistic = (xBar - mu0) / (sigma / sqrt(n))\npVal = 2 * ccdf(Normal(), testStatistic)\nprintln(\"Manual hypothesis testing: \\nz-statistic: \", testStatistic, \"\\np-value: \", pVal, \"\\n\")\n\nOneSampleZTest(xBar, sigma, n, mu0)\n\nManual hypothesis testing: \nz-statistic: 10.322959784979435\np-value: 5.548583144318553e-25\n\n\n\nOne sample z-test\n-----------------\nPopulation details:\n    parameter of interest:   Mean\n    value under h_0:         25\n    point estimate:          27.0646\n    95% confidence interval: (26.67, 27.46)\n\nTest summary:\n    outcome with 95% confidence: reject h_0\n    two-sided p-value:           &lt;1e-24\n\nDetails:\n    number of observations:   100\n    z-statistic:              10.322959784979435\n    population standard error: 0.2\n\n\n\n\n10.1.2 Population variance unknown (T-Test)\nWhen the population variance is unknown, then \\(\\overline{X}\\) does not subject to \\(N(\\mu, \\frac{s}{\\sqrt{n}})\\). But we know that\n\\[\nT = \\frac{\\overline{X} - \\mu_0}{S/\\sqrt{n}} \\sim T(n-1)\n\\]\nunder the null hypothesis.\nThe observed test statistic from the data is then\n\\[\nt = \\frac{\\bar{x} - \\mu_0}{s/\\sqrt{n}}\n\\]\nand the corresponding \\(p\\)-value for a two-sided test is\n\\[\np = 2P(T_{n-1} &gt; |t|)\n\\]\nwhere \\(T_{n-1}\\) is a random variable distributed according to a T-distribution with \\(n-1\\) degrees of freedom.\n\nusing Random, Distributions, HypothesisTests\n\nRandom.seed!(0)\n\nmu0, mu1, sigma = 51, 53, 2\ndist = Normal(mu1, sigma)\nd = rand(dist, 20)\n\nxBar, n, s = mean(d), length(d), std(d)\ntStatistic = (xBar - mu0) / (s / sqrt(n))\npVal = 2 * ccdf(TDist(n - 1), abs(tStatistic))\n\nprintln(\"Manually calculated t-statistic: \", tStatistic)\nprintln(\"Manually calculated p-value: \", pVal)\n\nOneSampleTTest(d, mu0)\n\nManually calculated t-statistic: 5.181941732141548\nManually calculated p-value: 5.303859808841965e-5\n\n\nOne sample t-test\n-----------------\nPopulation details:\n    parameter of interest:   Mean\n    value under h_0:         51\n    point estimate:          53.1999\n    95% confidence interval: (52.31, 54.09)\n\nTest summary:\n    outcome with 95% confidence: reject h_0\n    two-sided p-value:           &lt;1e-04\n\nDetails:\n    number of observations:   20\n    t-statistic:              5.181941732141548\n    degrees of freedom:       19\n    empirical standard error: 0.4245336299010766\n\n\n\n\n10.1.3 Non-parametric sign test\nThe validity of Z-Test or T-Test relies heavily on the assumption that the sample \\(X_1, ..., X_n\\) is comprised of independent normal random variables with variance known or unknown. This is because only under this assunmption does \\(\\overline{X} \\sim N(\\mu, \\frac{\\sigma^2}{n})\\) or \\(T \\sim T(n-1)\\).\nFor the non-parametric sign test, non-parametric implies that the distribution of the test statistic does not depend on any particular distributional assumption for the population.\nFor the sign test, we begin by denoting the random variables\n\\[\nX^+ = \\sum_{i=1}^{n}\\mathbf{1}\\{X_i &gt; \\mu_0\\} \\quad\\text{and}\\quad X^- = \\sum_{i=1}^{n}\\mathbf{1}\\{X_i &lt; \\mu_0\\} = n - X^+\n\\]\nwhere \\(\\mathbf{1}\\) is the indicator function. The variable \\(X^+\\) is a count of the number of observations that exceed \\(\\mu_0\\), and similarly \\(X^-\\) is a count of the number of observations that are below \\(\\mu_0\\).\nObserve that under \\(H_0: \\mu = \\mu_0\\), it holds that \\(P(X_i &gt; \\mu_0) = P(X_i &lt; \\mu_0) = 1/2\\). Note that here we are actually taking \\(\\mu_0\\) as the median of the distribution and assuming that \\(P(X_i = \\mu_0) = 0\\) as is the case for a continuous distribution.\nHence, under \\(H_0\\), the random variables \\(X^+\\) and \\(X^-\\) both follow a binomial \\((n, 1/2)\\) distribution. Given the symmetry of this binomial distribution we define the test statistic to be\n\\[\nU = max\\{X^+, X^-\\}\n\\]\nHence, with observed data, and an observed test statistic \\(u\\), the \\(p\\)-value can be calculated via\n\\[\np = 2P(B &gt; u)\n\\]\nwhere \\(B \\sim B(n, 1/2)\\).\n\nusing Random, Distributions\n\nRandom.seed!(0)\n\nmu0, mu1, sigma = 51, 53, 2\ndist = Normal(mu1, sigma)\nd = rand(dist, 20)\nn = length(d)\n\nxPos = sum(d .&gt; mu0)\ntestStat = max(xPos, n - xPos)\n\nbinom = Binomial(n, 0.5)\npVal = 2 * ccdf(binom, testStat)\n\nprintln(\"mu0: \", mu0, \"\\nmu1: \", mu1)\nprintln(\"Binomial mean: \", mean(binom), \"\\nTest statistic: \", testStat)\nprintln(\"p-value: \", pVal)\n\nmu0: 51\nmu1: 53\nBinomial mean: 10.0\nTest statistic: 18\np-value: 4.005432128906249e-5\n\n\n\n\n10.1.4 Sign test vs. T-test\nWhen the normality assumption holds, the T-test is often more powerful than the sign test. That is, for a fixed \\(\\alpha\\), the probability of detecting \\(H_1\\) is higher for the T-test than for the sign test if \\(H_1 \\ne H_0\\). This makes it a more effective test to use, if the data can be assumed normally distributed.\n\nusing Random, Distributions, CairoMakie\n\nRandom.seed!(0)\n\nActualMuRange = 51:0.02:55\nsigma = 1.2\nmu0 = 53\nn, N = 50, 10^4\npowerT, powerU = [], []\n\nfor ActualMu in ActualMuRange\n    dist = Normal(ActualMu, sigma)\n    rejectT, rejectU = 0, 0\n\n    for _ in 1:N\n        d = rand(dist, n)\n        xBar, stdDev = mean(d), std(d)\n\n        tStatistics = (xBar - mu0) / (stdDev / sqrt(n))\n        pValT = 2 * ccdf(TDist(n - 1), abs(tStatistics))\n\n        xPos = sum(d .&gt; mu0)\n        uStat = max(xPos, n - xPos)\n        pValSign = 2 * ccdf(Binomial(n, 0.5), uStat)\n\n        rejectT += pValT &lt; 0.05\n        rejectU += pValSign &lt; 0.05\n    end\n\n    push!(powerT, rejectT / N)\n    push!(powerU, rejectU / N)\nend\n\nfig, ax = lines(ActualMuRange, powerT; color=:blue, label=\"T test\")\nlines!(ax, ActualMuRange, powerU; color=:red, label=\"Sign test\")\nhlines!(ax, [0.05]; color=:green, label=\"Alpha\")\nvlines!(ax, [mu0 - sigma, mu0 + sigma]; color=:black, label=\"mu0 ± sigma\")\naxislegend(ax; position=:rb)\nax.xlabel = \"Different values of muActual\"\nax.ylabel = \"Proportion of times H0 rejected (power)\"\nfig\n\n\n\n\nFrom the result, under the normality assumption, we obsered that\n\nWhen \\(H_1 = H_0\\), then the power is \\(\\alpha\\) (i.e. the probability of rejecting \\(H_0\\)).\nT-test is more powerful than sign test when \\(H_1 \\ne H_0\\).\nWhen \\(H_1 \\to H_0\\), sign test will make higher \\(\\alpha\\) error than T-test.\nWhen \\(H_1\\) is away from \\(H_0\\) by one \\(\\sigma\\) or more, then the powers of T-test and sign test are really similar.\n\n\n\n\n10.2 Two sample hypothesis tests for comparing means\nWe now present some common hypothesis tests for the inference on the difference in means of two populations.\nCommonly, we wish to investigate if the population difference, \\(\\Delta_0\\), takes on a specific value.\nHence, we may wish to set up a two-sided hypothesis test as\n\\[\nH_0: \\mu_1 - \\mu_2 = \\Delta_0 \\quad\\text{and}\\quad H_1: \\mu_1 - \\mu_2 \\ne \\Delta_0\n\\]\nor one could formulate a one-sided hypothesis test, such as\n\\[\nH_0: \\mu_1 - \\mu_2 \\le \\Delta_0 \\quad\\text{and}\\quad H_1: \\mu_1 - \\mu_2 &gt; \\Delta_0\n\\]\nor the reverse if desired.\nIt is common to consider \\(\\Delta_0 = 0\\), in which case the hypothesis test can be stated as \\(H_0: \\mu_1 = \\mu_2\\), and \\(H_1: \\mu_1 \\ne \\mu_2\\).\nFor the tests introduced below, we assume that the observations \\(X_1^{(1)}, ..., X_n^{(1)}\\) from population \\(1\\) and \\(X_1^{(2)}, ..., X_n^{(2)}\\) from population \\(2\\) are all normally distributed, where \\(X_i^{(j)}\\) has mean \\(\\mu_j\\) and variance \\(\\sigma_j^2\\).\nThe testing methodology then differs based on the following three cases:\n\nThe population variances \\(\\sigma_1\\) and \\(\\sigma_2\\) are known.\nThe population variances \\(\\sigma_1\\) and \\(\\sigma_2\\) are unknown but assumed equal.\nThe population variances \\(\\sigma_1\\) and \\(\\sigma_2\\) are unknown and not assumed equal.\n\nIn each of these cases, the test statistic is given by\n\\[\n\\frac{(\\overline{X}_1 - \\overline{X}_2) - \\Delta_0}{S_{err}}\n\\]\nwhere \\(\\overline{X}_j\\) is the sample mean of \\(X_1^{(j)}, ..., x_n^{(j)}\\), and the standard error \\(S_{err}\\) varies according to the case (\\(1-3\\)).\n\n10.2.1 Population variances known\nWhen the population variances \\(\\sigma_1^2\\) and \\(\\sigma_2^2\\) are known, we have \\(\\overline{X}_1 \\sim N(\\mu_1, \\frac{\\sigma_1^2}{n_1})\\) and \\(\\overline{X}_2 \\sim N(\\mu_2, \\frac{\\sigma_2^2}{n_2})\\), and then \\(\\overline{X}_1 - \\overline{X}_2 \\sim N(\\mu_1 - \\mu_2, \\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2})\\). Hence we set\n\\[\nS_{err} = \\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}\n\\]\nIn this case, the test statistic follows a standard normal distribution under \\(H_0\\), so we have\n\\[\nz = \\frac{(\\bar{x}_1 - \\bar{x}_2) - \\Delta_0}{\\sqrt{\\frac{\\sigma_1^2}{n_1} + \\frac{\\sigma_2^2}{n_2}}}\n\\]\n\nusing Random, Distributions\n\nRandom.seed!(0)\n\nmu1, sigma1 = 10, 2\nmu2, sigma2 = 12, 1.5\n\nd1 = rand(Normal(mu1, sigma1), 20)\nd2 = rand(Normal(mu2, sigma2), 30)\n\nxBar1, n1 = mean(d1), length(d1)\nxBar2, n2 = mean(d2), length(d2)\n\n# to test whether μ1 = μ2 (two-sided)\ndelta0 = 0\n\ntestStat = (xBar1 - xBar2 - delta0) / sqrt(sigma1^2 / n1 + sigma2^2 / n2)\npVal = 2 * ccdf(Normal(), abs(testStat))\n\nprintln(\"μ1 = \", mu1, \"\\nμ2 = \", mu2)\nprintln(\"Manually calculated test statistic: \", testStat)\nprintln(\"Manually calculated p-value: \", pVal)\n\nμ1 = 10\nμ2 = 12\nManually calculated test statistic: -3.1025769505420775\nManually calculated p-value: 0.001918436654992464\n\n\n\n\n10.2.2 Population variances unknown and assumed equal\nIn case the population variances are unknown and assumed equal (\\(\\sigma^2 := \\sigma_1^2 = \\sigma_2^2\\)), the pooled sample variance (weighted arithmetic mean), \\(S_p^2\\) is used to estimate \\(\\sigma^2\\) based on both samples. It is given by\n\\[\nS_p^2 = \\frac{(n_1-1)S_1^2 + (n_2-1)S_2^2}{n_1+n_2-2}\n\\]\nwhere \\(S_j^2\\) is the sample variance of sample \\(j\\). It can be shown that under \\(H_0\\), if we set\n\\[\nS_{err} = \\sqrt{\\frac{S_p^2}{n_1} + \\frac{S_p^2}{n_2}} = S_p\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}\n\\]\nthe test statistic is distributed as a T-distribution with \\(n_1+n_2-2\\) degrees of freedom.\nFor this case, the observed test statistic is\n\\[\nt = \\frac{(\\bar{x}_1 - \\bar{x}_2) - \\Delta_0}{S_p\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n\\]\n\nusing Random, Distributions, HypothesisTests\n\nRandom.seed!(0)\n\nmu1, sigma1 = 10, 2\nmu2, sigma2 = 12, 2\n\nd1 = rand(Normal(mu1, sigma1), 20)\nd2 = rand(Normal(mu2, sigma2), 30)\n\nxBar1, s1, n1 = mean(d1), std(d1), length(d1)\nxBar2, s2, n2 = mean(d2), std(d2), length(d2)\n\n# to test whether μ1 = μ2 (two-sided)\ndelta0 = 0\n\nsP = sqrt(((n1 - 1) * s1^2 + (n2 - 1) * s2^2) / (n1 + n2 - 2))\ntestStat = (xBar1 - xBar2 - delta0) / (sP * sqrt(1 / n1 + 1 / n2))\npVal = 2 * ccdf(TDist(n1 + n2 - 2), abs(testStat))\n\nprintln(\"Manually calculated test statistic: \", testStat)\nprintln(\"Manually calculated p-value: \", pVal)\n\nEqualVarianceTTest(d1, d2, delta0)\n\nManually calculated test statistic: -2.870462082198691\nManually calculated p-value: 0.006080203814276703\n\n\nTwo sample t-test (equal variance)\n----------------------------------\nPopulation details:\n    parameter of interest:   Mean difference\n    value under h_0:         0\n    point estimate:          -1.56931\n    95% confidence interval: (-2.669, -0.4701)\n\nTest summary:\n    outcome with 95% confidence: reject h_0\n    two-sided p-value:           0.0061\n\nDetails:\n    number of observations:   [20,30]\n    t-statistic:              -2.870462082198691\n    degrees of freedom:       48\n    empirical standard error: 0.546709753154726\n\n\n\n\n10.2.3 Population variances unknown and not assumed equal\nWhere the population variances are unknown and not assumed equal (\\(\\sigma_1^2 \\ne \\sigma_2^2\\)), we set\n\\[\nS_{err} = \\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}\n\\]\nThen the observed test statistic is given by\n\\[\nt = \\frac{(\\bar{x}_1 - \\bar{x}_2) - \\Delta_0}{\\sqrt{\\frac{S_1^2}{n_1} + \\frac{S_2^2}{n_2}}}\n\\]\nThe distribution of the test statistic does not follow an exact T-distribution with \\(n_1+n_2-2\\) degrees of freedom. Instead, we use the Satterthwaite approxmation, and determine the degrees of freedom via\n\\[\nv = \\frac{(s_1^2n_1 + s_2^2n_2)^2}{\\frac{(s_1^2/n_1)^2}{n_1-1} + \\frac{(s_2^2/n_2)^2}{n2-1}}\n\\]\n\nusing Random, Distributions, HypothesisTests\n\nRandom.seed!(0)\n\nmu1, sigma1 = 10, 2\nmu2, sigma2 = 12, 1.5\n\nd1 = rand(Normal(mu1, sigma1), 20)\nd2 = rand(Normal(mu2, sigma2), 30)\n\nxBar1, s1, n1 = mean(d1), std(d1), length(d1)\nxBar2, s2, n2 = mean(d2), std(d2), length(d2)\n\n# to test whether μ1 = μ2 (two-sided)\ndelta0 = 0\n\nv = (s1^2 / n1 + s2^2 / n2)^2 / ((s1^2 / n1)^2 / (n1 - 1) + (s2^2 / n2)^2 / (n2 - 1))\ntestStat = (xBar1 - xBar2 - delta0) / sqrt(s1^2 / n1 + s2^2 / n2)\npVal = 2 * ccdf(TDist(v), abs(testStat))\n\nprintln(\"Manually calculated degrees of freedom, v: \", v)\nprintln(\"Manually calculated test statistic: \", testStat)\nprintln(\"Manually calculated p-value: \", pVal)\nUnequalVarianceTTest(d1, d2, delta0)\n\nManually calculated degrees of freedom, v: 32.78958178466954\nManually calculated test statistic: -3.2719914674400004\nManually calculated p-value: 0.002517632534475486\n\n\nTwo sample t-test (unequal variance)\n------------------------------------\nPopulation details:\n    parameter of interest:   Mean difference\n    value under h_0:         0\n    point estimate:          -1.62701\n    95% confidence interval: (-2.639, -0.6151)\n\nTest summary:\n    outcome with 95% confidence: reject h_0\n    two-sided p-value:           0.0025\n\nDetails:\n    number of observations:   [20,30]\n    t-statistic:              -3.2719914674400004\n    degrees of freedom:       32.78958178466954\n    empirical standard error: 0.49725223770269017\n\n\n\n\n\n10.3 Analysis of variance (ANOVA or F-test)\nAs mentioned above, Z-test or T-test can handle the problems of comparing means of two populations. However, what if there are more than two populations that need to be compared? You may say that we can compare each pair of them, but in fact, this will reduce the hypothesis test power.\nWhen we have more than two populatons to be compared, we call each population a treatment or a group. It is of interest to see if vairous “treatments” have an effect on some mean value or not.\nMore formally, assume that there is some overall mean \\(\\mu\\) and there are \\(L \\ge 2\\) treatments, where each treatment may potentially alter the mean by \\(\\tau_i\\). In this case, the mean of the population under treatment \\(i\\) can be represented by \\(\\mu_i = \\mu + \\tau_i\\), with \\(\\mu\\) an overall mean, and\n\\[\n\\sum_{i=1}^{L} \\tau_i = 0\n\\]\nThis condition on the parameters \\(\\tau_1, ..., \\tau_L\\) ensures that given \\(\\mu_1, ..., \\mu_L\\), the overall mean \\(\\mu\\) and \\(\\tau_1, ..., \\tau_L\\) are well defined.\nGiven \\(\\mu_1, ..., \\mu_L\\), we have\n\\[\n\\mu = \\frac{1}{L} \\sum_{i=1}^{L} \\mu_i \\quad\\text{and}\\quad \\tau_i = \\mu_i - \\mu\n\\]\nThe question is then: Do the treatments have any effect or not?\nSuch a question is presented via the hypothesis formulation:\n\\[\nH_0: \\tau_1 = \\tau_2 = \\cdots = \\tau_L = 0 \\quad\\text{vs.}\\quad H_1: \\exists i\\ |\\ \\tau_i \\ne 0\n\\]\nNote that \\(H_0\\) is equivalent to the statement that \\(\\mu_1 = \\mu_2 = \\cdots = \\mu_L\\), indicating that the treatments do not have an effect. Furthermore, \\(H_1\\) states that there exists an \\(i\\) with \\(\\tau_i \\ne 0\\) is equivalent to the case where there exist at least two treatments, \\(i\\) and \\(j\\) such that \\(\\mu_i \\ne \\mu_j\\).\nAssume that we collect observations as follows:\n\\[\n\\begin{align}\n\\text{Treatment 1: } &x_{11}, x_{12}, ..., x_{1n_1} \\\\\n\\text{Treatment 2: } &x_{21}, x_{22}, ..., x_{2n_2} \\\\\n&\\vdots \\\\\n\\text{Treatment L: } &x_{L1}, x_{L2}, ..., x_{Ln_L}\n\\end{align}\n\\]\nwhere \\(n_1, n_2, ..., n_L\\) are the sample sizes for each treatment.\nThen denote the total number of observations via\n\\[\nm = \\sum_{i=1}^{L} n_i\n\\]\nWe also consider the sample means for each treatment\n\\[\n\\bar{x}_i = \\frac{1}{n_i} \\sum_{i=1}^{n_i} x_{ij}\n\\]\nand the overall sample mean\n\\[\n\\bar{x} = \\frac{1}{m} \\sum_{i=1}^{L} \\sum_{i=1}^{n_i} x_{ij} = \\sum_{i=1}^{L} \\frac{n_i}{m} x_{ij}\n\\]\nIn ANOVA, the statistical model assumes that the observations of each treatment come from an underlying model of the following form:\n\\[\nX_i = \\mu_i + \\epsilon = \\mu + \\tau_i + \\epsilon \\quad\\text{where}\\quad \\epsilon \\sim N(0, \\sigma^2)\n\\]\nwhere \\(X_i\\) is the model for the \\(i\\)th treatment, and \\(\\epsilon\\) is some noise term with common unknown variance across all treatment groups, independent across measurements.\n\n10.3.1 Decomposing sum of squares\nA key idea of ANOVA is the decomposition of the total variability into two components: the variablity between the treatments, and the variability within the treatments.\nThe total sum of squares (\\(SS_\\text{Total}\\)) is a measure of the total variability of all observations, and is calculated as follows:\n\\[\nSS_\\text{Total} = \\sum_{i=1}^{L} \\sum_{j=1}^{n_i} (x_{ij} - \\bar{x})^2\n\\]\nwhere \\(\\bar{x}\\) is the overall mean.\nNow we decompose \\(SS_\\text{Total}\\) into two parts:\n\\[\n\\begin{align}\n\\sum_{i=1}^{L} \\sum_{j=1}^{n_i} (x_{ij} - \\bar{x})^2 &= \\sum_{i=1}^{L} \\sum_{j=1}^{n_i} (x_{ij} - \\bar{x}_i + \\bar{x}_i - \\bar{x})^2 \\\\\n&= \\sum_{i=1}^{L} \\sum_{j=1}^{n_i} \\left((x_{ij} - \\bar{x}_i)^2 + 2(x_{ij} - \\bar{x}_i)(\\bar{x}_i - \\bar{x}) + (\\bar{x}_i - \\bar{x})^2\\right) \\\\\n&= \\underbrace{\\sum_{i=1}^{L} \\sum_{j=1}^{n_i} (x_{ij} - \\bar{x}_i)^2}_{SS_\\text{Error}} + \\underbrace{\\sum_{i=1}^{L} n_i (\\bar{x}_i - \\bar{x})^2}_{SS_\\text{Treatment}}\n\\end{align}\n\\]\nNote \\(\\sum_{i=1}^{n_i} (x_{ij} - \\bar{x}_i) = 0\\). So we have\n\\[\nSS_\\text{Total} = SS_\\text{Error} + SS_\\text{Treatment}\n\\]\nNote that \\(SS_\\text{Error}\\) is also known as the sum of variability within the groups, and that \\(SS_\\text{Treatment}\\) is also known as the variability between the groups.\nThe decomposition holds under both \\(H_0\\) and \\(H_1\\), and hence allows us to construct a test statistic. Intuitively, under \\(H_0\\), both \\(SS_\\text{Error}\\) and \\(SS_\\text{Treatment}\\) should contribute to \\(SS_\\text{Total}\\) in the same manner (once properly normalized). Alternatively, under \\(H_1\\), it is expected that \\(SS_\\text{Treatment}\\) would contribute more heavily to the total variability.\nThe test statistic we constructed is called F-statistic, defined as the ratio of \\(SS_\\text{Treatment}\\) and \\(SS_\\text{Error}\\) normalized by their respective degrees of freedom \\(L-1\\) and \\(m-L\\):\n\\[\nF = \\frac{SS_\\text{Treatment}/(L-1)}{SS_\\text{Error}/(m-L)}\n\\]\nThese normalized quantities are, respectively, denoted by \\(MS_\\text{Treatment}\\) and \\(MS_\\text{Error}\\) standing for “Mean Squared”. Hence, \\(F = \\frac{MS_\\text{Treatment}}{MS_\\text{Error}}\\)\nUnder \\(H_0\\), the F-statistic follows an F-distribution with \\(L-1\\) degrees of freedom for the numerator and \\(m-L\\) degrees of freedom for the denominator. Intuitively, under \\(H_0\\), we expect the numerator and denominator to have similar values, hence expect \\(F\\) to be around \\(1\\) (indeed most of the mass of \\(F\\) distributions is concentrated around \\(1\\)). However, if \\(MS_\\text{Treatment}\\) is significantly larger, then it indicates that \\(H_0\\) may not hold. Hence, the approach of the F-test is to reject \\(H_0\\) if the F-statistic is geater than the \\(1-\\alpha\\) quantile of the respective F-distribution. Similarly, the \\(p\\)-value for an observed F-statistic \\(f_o\\) is given by\n\\[\np = P(F_{L-1, m-L} &gt; f_o)\n\\]\nwhere \\(F_{L-1, m-L}\\) is an F-distributed random variable with \\(L-1\\) numerator degrees of freedom and \\(m-L\\) denominator degrees of freedom.\n\nusing Random, Distributions, DataFrames, GLM, CategoricalArrays\n\nRandom.seed!(0)\n\nallData = [rand(Normal(10, 1), 20), rand(Normal(11, 2), 30), rand(Normal(11, 2), 25)]\n\n# manual ANOVA\n# the decomposition of the sum of squares\n# F-test\nnArray = length.(allData)\nd = length(nArray)\n\nxBarTotal = mean(vcat(allData...))\nxBarArray = mean.(allData)\n\nssBetween = sum([nArray[i] * (xBarArray[i] - xBarTotal)^2 for i in 1:d])\nssWithin = sum([sum([(ob - xBarArray[i])^2 for ob in allData[i]]) for i in 1:d])\n\ndfBetween = d - 1\ndfError = sum(nArray) - d\n\nmsBetween = ssBetween / dfBetween\nmsError = ssWithin / dfError\n\nfStat = msBetween / msError\npVal = ccdf(FDist(dfBetween, dfError), fStat)\n\nprintln(\"Maunal ANOVA: \\nF-Statistic: \", fStat, \"\\np-value: \", pVal)\n\n# ANOVA using GLM package which requires the DataFrames package\nnArray = length.(allData)\nd = length(nArray)\n\ntreatment = vcat([fill(k, nArray[k]) for k in 1:d]...)\nresponse = vcat(allData...)\ndf = DataFrame(Response=response, Treatment=categorical(treatment))\nmodelH0 = lm(@formula(Response ~ 1), df)\nmodelH1 = lm(@formula(Response ~ 1 + Treatment), df)\nres = ftest(modelH1.model, modelH0.model)\n\nprintln(\"GLM ANOVA: \\nF-Statistic: \", res.fstat[2], \"\\np-value: \", res.pval[2])\n\nMaunal ANOVA: \nF-Statistic: 3.3657643096267207\np-value: 0.040051359435068816\nGLM ANOVA: \nF-Statistic: 3.3657643096267127\np-value: 0.040051359435069135\n\n\n\n\n10.3.2 More on the distribution of the F-Statistic\nHere we use the Monte Carlo simulation to generate the distribution of the F-Statistic for two different cases (\\(H_0\\) and \\(H_1\\)).\nUnder \\(H_0\\), the distribution of F-Statistic obtained via Monte Carlo should be exactly the same as the analytical F-distribution with the same numerator and denominator degrees of freedom, but it’s not for the distribution of F-Statistic under \\(H_1\\).\n\nusing Random, Distributions, CairoMakie\n\nRandom.seed!(0)\n\nfunction anovaFStat(allData)\n    xBarArray = mean.(allData)\n    nArray = length.(allData)\n    xBarTotal = mean(vcat(allData...))\n    Le = length(nArray)\n\n    ssBetween = sum([nArray[i] * (xBarArray[i] - xBarTotal)^2 for i in 1:Le])\n    ssWithin = sum([sum([(ob - xBarArray[i])^2 for ob in allData[i]]) for i in 1:Le])\n\n    return ((ssBetween / (Le - 1)) / (ssWithin / (sum(nArray) - Le)))\nend\n\ncase1 = [13.4, 13.4, 13.4, 13.4, 13.4]\ncase2 = [12.7, 11.8, 13.4, 12.7, 12.9]\nstdDevs = [2, 2, 2, 2, 2]\nnumObs = [24, 15, 13, 23, 9]\nLe = length(case1)\n\nN = 10^5\n\nmcFstatsH0 = Array{Float64}(undef, N)\nfor i in 1:N\n    mcFstatsH0[i] = anovaFStat([rand(Normal(case1[j], stdDevs[j]), numObs[j]) for j in 1:Le])\nend\n\nmcFstatsH1 = Array{Float64}(undef, N)\nfor i in 1:N\n    mcFstatsH1[i] = anovaFStat([rand(Normal(case2[j], stdDevs[j]), numObs[j]) for j in 1:Le])\nend\n\nfig, ax = stephist(mcFstatsH0; bins=100, color=:blue, normalization=:pdf, label=\"H0\")\nstephist!(ax, mcFstatsH1; bins=100, color=:red, normalization=:pdf, label=\"H1\")\n\ndfBetween = Le - 1\ndfError = sum(numObs) - Le\nxGrid = 0:0.01:10\n\nlines!(ax, xGrid, pdf.(FDist(dfBetween, dfError), xGrid); color=:green, label=\"F-Statistic analytic\")\n\ncritVal = quantile(FDist(dfBetween, dfError), 0.95)\n\nvlines!(ax, [critVal]; color=:black, linestyle=:dash, label=\"Critical value boundary\")\n\naxislegend(ax)\nax.xlabel = \"F-value\"\nax.ylabel = \"Density\"\nfig\n\n\n\n\nAnalysis presented here is just the one-way ANOVA, which means that we have only one treatment category having different treatment levels. Often we may have two treatment categories, each of which has different treatment levels (two-way ANOVA). This can be extended to higher dimensional extensions, which are often considered in block factorial design. In addition, once we reject \\(H_0\\), we often want to known which specific treatments have an effect and in which way. This involves multiple comparisons.\n\n\n\n10.4 Independence and goodness of fit\n\n10.4.1 Testing for an indenpendent sequence\nHere, we’ll use the Wald-Wolfowitz runs test to perform hypothesis testing for checking if a sequence of random variables is i.i.d. (indenpendent and identically distributed).\nConsider a sequence of data points \\(x_1, ..., x_n\\) with sample mean \\(\\bar{x}\\). For simplicity, assume that no point equals the sample mean. Now transform the sequence to \\(y_1, ..., y_n\\) via \\(y_i = x_i - \\bar{x}\\).\nWe now consider the signs of \\(y_i\\). For example, in a dataset with \\(20\\) observations, once considering the signs we may have a sequence such as\n\\[\n+-+-----++--+---++++\n\\]\nindicating that the first is positive (greater than the mean), the second is negative (less than the mean), and so on.\nNote that we assume no exact \\(0\\) for \\(y_i\\) and if such exist we can arbitrarily assign them to be either positive or negative. We then create a random variable \\(R\\) by counting the number of runs in this sequence, where a run is a consecutive sequence of points having the same sign. In our example, the runs (visually separated by white space) are\n\\[\n+\\ -\\ +\\ -----\\ ++\\ --\\ +\\ ---\\ ++++\n\\]\nHance \\(R = 9\\).\nThe essence of the Wald-Wolfowitz runs test is an approximation of the distribution of \\(R\\) under \\(H_0\\). The null hypothesis is that the data is i.i.d. Under \\(H_0\\), \\(R\\) can be shown to be approximately follow a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma^2\\), where\n\\[\n\\mu = 2 \\frac{n_+n_-}{n} + 1,\\qquad \\sigma^2 = \\frac{(\\mu - 1)(\\mu - 2)}{n - 1}\n\\]\nHere \\(n_+\\) is the number of positive signs and \\(n_-\\) is the number of negative signs. Note that \\(n_+\\) and \\(n_-\\) are also random variables. Clearly, \\(n_+ + n_- = n\\), the total number of observations. With such values at hand the test creates the \\(p\\)-value via\n\\[\n2P(Z &gt; \\left|\\frac{R - \\mu}{\\sigma}\\right|)\n\\]\nwhere \\(Z\\) is a standard normal variable.\nIn the following code, we’ll validate that the random variable \\(R\\) (i.e. runs) is approximately distributed as a normal distribution with mean \\(\\mu\\) and variance \\(\\sigma\\) defined above under \\(H_0\\) (i.e. the data points are i.i.d.). In other words, the distribution of the \\(p\\)-value is \\(U(0, 1)\\).\n\nusing Random, StatsBase, Distributions, CairoMakie\n\nRandom.seed!(0)\n\n# we'll use a Monte Carlo simulation to obtain the empirical distribution of the p-value\n# sample size: n\n# experimental numbers: N\nn, N = 10^3, 10^6\n\n# calculate the p-value for each sample\nfunction waldWolfowitz(data)\n    n = length(data)\n    sgns = data .&gt; mean(data)\n    nPlus, nMinus = sum(sgns), n - sum(sgns)\n    wwMu = 2 * nPlus * nMinus / n + 1\n    wwVar = (wwMu - 1) * (wwMu - 2) / (n - 1)\n\n    R = 1\n    for i in 1:(n-1)\n        R += sgns[i] != sgns[i+1]\n    end\n\n    zStat = abs((R - wwMu) / sqrt(wwVar))\n    2 * ccdf(Normal(), zStat)\nend\n\n# repeat the process for N times\npVals = [waldWolfowitz(rand(Normal(), n)) for _ in 1:N]\n# here, we calculate the hypothesis testing power\n# under H0, the power is equal to α\nfor alpha in [0.001, 0.005, 0.01, 0.05, 0.1]\n    pva = sum(pVals .&lt; alpha) / N\n    println(\"For alpha = $(alpha), p-value area = $(pva)\")\nend\n\nfig = Figure(size=(500, 800))\n# we can see that the distributio of the p-value is U(0, 1)\n# the reason why spikes of high density appear is that\n# we are approximating a discrete random variable R (can only have positive integers) with a normal random variable\nax1 = Axis(fig[1, 1]; xlabel=\"p-value\", ylabel=\"Frequency\")\nhist!(ax1, pVals; bins=5 * n)\n\npGrid = 0:0.001:1\n# get the ECDF using the ecdf function from StatsBase package\nFhat = ecdf(pVals)\n\n# the ECDF indicates that the distribution is almost uniform\nax2 = Axis(fig[2, 1]; xlabel=\"p-value\", ylabel=\"ECDF\")\nlines!(ax2, pGrid, Fhat.(pGrid))\nfig\n\nFor alpha = 0.001, p-value area = 0.000925\nFor alpha = 0.005, p-value area = 0.004769\nFor alpha = 0.01, p-value area = 0.010113\nFor alpha = 0.05, p-value area = 0.050592\nFor alpha = 0.1, p-value area = 0.100888\n\n\n\n\n\n\n\n\n10.5 More on power\n\n10.5.1 Parameters affecting power\nEstimate the hypothesis testing powers under different scenarios:\n\nusing Random, Distributions, KernelDensity, CairoMakie\n\nRandom.seed!(1)\n\n# calculate T-statistic by sampling n observations from a given normal distribution\nfunction tSat(mu0, mu, sig, n)\n    sample = rand(Normal(mu, sig), n)\n    xBar = mean(sample)\n    s = std(sample)\n    (xBar - mu0) / (s / sqrt(n))\nend\n\nmu0, mu1A, mu1B = 20, 22, 24\nsig, n = 7, 5\nN = 10^6\nalpha = 0.05\n\n# the underlying mean equals the mean under the null hypothesis\n# the power is α\ndataH0 = [tSat(mu0, mu0, sig, n) for _ in 1:N]\n# the underlying mean is increased\ndataH1A = [tSat(mu0, mu1A, sig, n) for _ in 1:N]\n# the underlying mean is increased further\ndataH1B = [tSat(mu0, mu1B, sig, n) for _ in 1:N]\n# increase the sample size\ndataH1C = [tSat(mu0, mu1B, sig, 2 * n) for _ in 1:N]\n# the underlying variance is decreased\ndataH1D = [tSat(mu0, mu1B, sig / 2, 2 * n) for _ in 1:N]\n\n# calculate the quantile of alpha\ntCrit = quantile(TDist(n - 1), 1 - alpha)\n# estimate the power\nestPwr(sample) = sum(sample .&gt; tCrit) / N\n\nprintln(\"Rejection boundary: \", tCrit)\nprintln(\"Power under H0 (equal α): \", estPwr(dataH0))\nprintln(\"Power under H1A (increase μ): \", estPwr(dataH1A))\nprintln(\"Power under H1B (increase μ further): \", estPwr(dataH1B))\nprintln(\"Power under H1C (increase sample size n to 2n): \", estPwr(dataH1C))\nprintln(\"Power under H1D (decrease σ to σ/2): \", estPwr(dataH1D))\n\nkH0 = kde(dataH0)\nkH1A = kde(dataH1A)\nkH1B = kde(dataH1B)\nkH1C = kde(dataH1C)\nkH1D = kde(dataH1D)\n\nxGrid = -10:0.1:15\n\nfig, ax = lines(xGrid, pdf(kH0, xGrid); color=:blue, label=\"Distribution under H0\")\nlines!(ax, xGrid, pdf(kH1A, xGrid); color=:red, label=\"Distribution under H1A\")\nlines!(ax, xGrid, pdf(kH1B, xGrid); color=:green, label=\"Distribution under H1B\")\nlines!(ax, xGrid, pdf(kH1C, xGrid); color=:orange, label=\"Distribution under H1C\")\nlines!(ax, xGrid, pdf(kH1D, xGrid); color=:purple, label=\"Distribution under H1D\")\nvlines!(ax, [tCrit]; color=:black, label=\"Critical value boundary\")\nax.xlabel = L\"\\Delta = \\mu - \\mu_0\"\nax.ylabel = \"Density\"\naxislegend(ax)\nfig\n\nRejection boundary: 2.1318467863266495\nPower under H0 (equal α): 0.050195\nPower under H1A (increase μ): 0.13399\nPower under H1B (increase μ further): 0.281885\nPower under H1C (increase sample size n to 2n): 0.407785\nPower under H1D (decrease σ to σ/2): 0.91574\n\n\n\n\n\nUnder a normal population, \\(\\mu\\), \\(\\sigma\\), \\(\\alpha\\), and sample size all have an effect on the power. But in practice, if keeping \\(\\alpha\\) constant, it is only the sample size can be controlled.\nAs a consequence, we need to know what is the sample size for our expected power.\n\n\n10.5.2 Power curves\nAs mentioned before, if keeeping \\(\\alpha\\) constant, it is only the sample size can be controlled. Therefore, underlying a given \\(\\alpha\\), we must know\n\nTo obtain a given power, how many observations (i.e. sample size \\(n\\)) do we need?\nFor a few of available sample sizes, what’s the largest power we can obtain?\n\nA power curve is a plot of the power as a function of certain parameters we are interested in.\nFor example, under the hypothesis test setup:\n\\[\nH_0: \\mu = \\mu_0\\ \\ \\ \\ \\text{and}\\ \\ \\ \\ H_1: \\mu &gt; \\mu_0\n\\]\nwe want to estimate the power of a one-sided T-test for different scenarios combining the mean \\(\\mu\\) and the sample size \\(n\\) under normality assumption.\n\nusing Random, Distributions, CairoMakie\n\n# calculate T-statistic by sampling n observations from a given normal distribution\nfunction tSat(mu0, mu, sig, n)\n    sample = rand(Normal(mu, sig), n)\n    xBar = mean(sample)\n    s = std(sample)\n    (xBar - mu0) / (s / sqrt(n))\nend\n\n# estimate the statistical power under a given scenario (μ, n)\nfunction powerEstimate(mu0, mu1, sig, n, alpha, N)\n    Random.seed!(0)\n    sampleH1 = [tSat(mu0, mu1, sig, n) for _ in 1:N]\n    critVal = quantile(TDist(n - 1), 1 - alpha)\n    sum(sampleH1 .&gt; critVal) / N\nend\n\nmu0 = 20\nsig = 5\nalpha = 0.05\nN = 10^4\nrangeMu1 = 16:0.1:30\nnList = [5, 10, 20, 30]\n\npowerCurves = [powerEstimate.(mu0, rangeMu1, sig, n, alpha, N) for n in nList]\n\nfig, ax = lines(rangeMu1, powerCurves[1]; color=:blue, label=\"n = $(nList[1])\")\nlines!(ax, rangeMu1, powerCurves[2]; color=:red, label=\"n = $(nList[2])\")\nlines!(ax, rangeMu1, powerCurves[3]; color=:green, label=\"n = $(nList[3])\")\nlines!(ax, rangeMu1, powerCurves[4]; color=:purple, label=\"n = $(nList[4])\")\nax.xlabel = L\"\\mu\"\nax.ylabel = \"Power\"\naxislegend(ax; position=:lt)\nfig\n\n\n\n\nAs seen in the above figure, under a given power, if \\(\\mu\\) is away from \\(\\mu_0\\) further, then we can take less observations. On the other hand, for a given \\(\\mu\\), if we hope to increase the power, we need to increase the sample size.\nAnother point to note is that the x-axis could be adjusted to represent the difference \\(\\Delta = \\mu - \\mu_0\\). Furthermore, one could make the axis scale invariant by dividing \\(\\Delta\\) by the standard deviation.\n\n\n10.5.3 Distribution of the \\(p\\)-value\nFor a uniform \\(U(0, 1)\\) random variable, we have its CDF \\(F(x) = x, x \\in [0, 1]\\), and CCDF \\(F_c(x) = 1 - x, x \\in [0, 1]\\).\n\\(p\\)-value is defined as \\(p = P(S &gt; u)\\), where \\(S\\) is a random variable representing the test statistic, \\(u\\) is the observed test statistic, and \\(p\\) is the \\(p\\)-value of the observed test statistic.\nTo discuss the distribution of the \\(p\\)-value, denote the random variable of the \\(p\\)-value by \\(P\\). Hence \\(P = 1 - F(S)\\), where \\(F(\\cdot)\\) is the CDF of the test statistic under \\(H_0\\). Note that \\(P\\) is just a transformation of the test statistic random variable \\(S\\). Assume that \\(S\\) is continuous and assume that \\(H_0\\) holds, hence \\(P(S &lt; u) = F(u)\\). we now have\n\\[\n\\begin{align}\nP(P &gt; x) &= P(1 - F(S) &gt; x) \\\\\n&= P(F(S) &lt; 1 - x) \\\\\n&= P(S &lt; F^{-1}(1-x)) \\\\\n&= F(F^{-1}(1-x)) \\\\\n&= 1 - x\n\\end{align}\n\\]\nObviously, the CDF of the random variable \\(P\\) is \\(F(x) = P(P &lt; x) = x, x \\in [0, 1]\\), so the distribution of the \\(p\\)-value is \\(U(0, 1)\\) under \\(H_0\\).\nIf \\(H_0\\) does not hold, then \\(P(S &lt; u) \\ne F(u)\\) and the derivation above fails. In such a case, the distribution of the \\(p\\)-value is no longer uniform. In fact, in such a case, if the setting is such that the power of the test statistic increases, then we expect the distribution of the \\(p\\)-value to be more concentrated around \\(0\\) than a uniform distribution.\n\nusing Random, Distributions, KernelDensity, CairoMakie\n\nRandom.seed!(1)\n\nfunction pval(mu0, mu, sig, n)\n    sample = rand(Normal(mu, sig), n)\n    xBar = mean(sample)\n    s = std(sample)\n    tStatistics = (xBar - mu0) / (s / sqrt(n))\n    # under H0, t ∼ T(n - 1)\n    ccdf(TDist(n - 1), tStatistics)\nend\n\nmu0, mu1A, mu1B = 20, 23, 26\nsig, n, N = 7, 5, 10^6\n\npValsH0 = [pval(mu0, mu0, sig, n) for _ in 1:N]\npValsH1A = [pval(mu0, mu1A, sig, n) for _ in 1:N]\npValsH1B = [pval(mu0, mu1B, sig, n) for _ in 1:N]\n\nalpha = 0.05\nestPwr(pVals) = sum(pVals .&lt; alpha) / N\n\nprintln(\"Power under H0: \", estPwr(pValsH0))\nprintln(\"Power under H1A: \", estPwr(pValsH1A))\nprintln(\"Power under H1B: \", estPwr(pValsH1B))\n\nfig, ax = stephist(pValsH0; bins=100, normalization=:pdf, color=:blue, label=\"Under H0\")\nstephist!(ax, pValsH1A; bins=100, normalization=:pdf, color=:red, label=\"Under H1A\")\nstephist!(ax, pValsH1B; bins=100, normalization=:pdf, color=:green, label=\"Under H1B\")\nvlines!(ax, [alpha]; color=:black, label=\"α\", linestyle=:dash)\naxislegend(ax)\nax.xlabel = \"p-value\"\nax.ylabel = \"Density\"\nfig\n\nPower under H0: 0.050195\nPower under H1A: 0.199417\nPower under H1B: 0.477365"
  },
  {
    "objectID": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#appendices",
    "href": "posts/Probability and Statistics/probability_and_statistics_with_julia/index.html#appendices",
    "title": "Probability and statistics with Julia",
    "section": "11 Appendices",
    "text": "11 Appendices\n\n11.1 Base conversions\n\nBase \\(10\\) to base \\(k\\):\n\n\n整数部分：除 \\(k\\) 取余，逆序写出，直到商为 \\(0\\)。\n小数部分：乘 \\(k\\) 取整，顺序写出，直到小数部分为 \\(0\\) 或达到指定的精度为止。\n\nNote: \\(\\frac{1}{2} \\frac{1}{1} \\frac{0}{0} \\frac{.}{} \\frac{1}{-1} \\frac{0}{-2} \\frac{1}{-3}\\).\n\n\n11.2 Misc\n\nThe largest integer which can be represented by Int32 is \\(2^{31} - 1\\).\n\n对于 Int32 来说，最高位为符号位，因此最大的二进制数为 \\(\\underbrace{1...1}_{\\text{31 1's}}\\)，即所能表示的最大整数为 \\(1\\cdot 2^0 + 1\\cdot 2^1 + ... + 1\\cdot 2^{30}\\)，为了表示方便，我们将其加 \\(1\\)，变为 \\(1\\underbrace{0...0}_{\\text{31 0's}}\\)，再减 \\(1\\)，即 \\(2^{31} - 1\\)。"
  },
  {
    "objectID": "posts/Probability and Statistics/trigonometric_functions/index.html",
    "href": "posts/Probability and Statistics/trigonometric_functions/index.html",
    "title": "Trigonometric functions",
    "section": "",
    "text": "To be learned."
  },
  {
    "objectID": "posts/Probability and Statistics/logistic_function/index.html",
    "href": "posts/Probability and Statistics/logistic_function/index.html",
    "title": "Logistic function",
    "section": "",
    "text": "It appears you don't have a PDF plugin for this browser. No biggie. You can click here to download the PDF file."
  },
  {
    "objectID": "posts/Probability and Statistics/logistic_function/index.html#introduction",
    "href": "posts/Probability and Statistics/logistic_function/index.html#introduction",
    "title": "Logistic function",
    "section": "",
    "text": "It appears you don't have a PDF plugin for this browser. No biggie. You can click here to download the PDF file."
  },
  {
    "objectID": "posts/Probability and Statistics/p-p_plot_and_q-q_plot/index.html",
    "href": "posts/Probability and Statistics/p-p_plot_and_q-q_plot/index.html",
    "title": "P-P plot and Q-Q plot",
    "section": "",
    "text": "In statistics, a P-P plot (probability-probability plot or percent-percent plot or P value plot) is a probability plot for assessing how closely two datasets agree, or for assessing how closely a dataset fits a particular model.\nIt works by plotting the two cumulative distribution functions against each other; if they are similar, the data will appear to be nearly a straight line.\nA P-P plot plots two cumulative distribution functions (CDFs) against each other: given two probability distributions with CDFs F and G, it plots \\((F(z), G(z))\\) as \\(z\\) ranges from \\(-\\infty\\) to \\(\\infty\\). As a CDF has range \\([0, 1]\\), the domain of this parametric graph is \\((-\\infty, \\infty)\\), and the range is the unit square \\([0,1] \\times [0,1]\\).\nThus for input \\(z\\), the output is the pair of numbers giving what percentage of \\(F\\) and what percentage of \\(G\\) fall at or below \\(z\\)."
  },
  {
    "objectID": "posts/Probability and Statistics/p-p_plot_and_q-q_plot/index.html#p-p-plot",
    "href": "posts/Probability and Statistics/p-p_plot_and_q-q_plot/index.html#p-p-plot",
    "title": "P-P plot and Q-Q plot",
    "section": "",
    "text": "In statistics, a P-P plot (probability-probability plot or percent-percent plot or P value plot) is a probability plot for assessing how closely two datasets agree, or for assessing how closely a dataset fits a particular model.\nIt works by plotting the two cumulative distribution functions against each other; if they are similar, the data will appear to be nearly a straight line.\nA P-P plot plots two cumulative distribution functions (CDFs) against each other: given two probability distributions with CDFs F and G, it plots \\((F(z), G(z))\\) as \\(z\\) ranges from \\(-\\infty\\) to \\(\\infty\\). As a CDF has range \\([0, 1]\\), the domain of this parametric graph is \\((-\\infty, \\infty)\\), and the range is the unit square \\([0,1] \\times [0,1]\\).\nThus for input \\(z\\), the output is the pair of numbers giving what percentage of \\(F\\) and what percentage of \\(G\\) fall at or below \\(z\\)."
  },
  {
    "objectID": "posts/Probability and Statistics/p-p_plot_and_q-q_plot/index.html#q-q-plot",
    "href": "posts/Probability and Statistics/p-p_plot_and_q-q_plot/index.html#q-q-plot",
    "title": "P-P plot and Q-Q plot",
    "section": "2 Q-Q plot",
    "text": "2 Q-Q plot\nIn statistics, a Q-Q plot (quantile-quantile plot) is a probability plot, a graphical method for comparing two probability distributions by plotting their quantiles against each other. A point \\((x, y)\\) on the plot corresponds to one of the quantiles of the second distribution (\\(y\\)-coordinate) plotted against the same quantile of the first distribution (\\(x\\)-coordinate). This defines a parametric curve where the parameter is the index of the quantile interval.\n\nIf the two distributions being compared are similar, the points in the Q-Q plot will approximately lie on the identity line \\(y = x\\).\nIf the distributions are linearly related, the points in the Q-Q plot will approximately lie on a line, but not necessarily on the line \\(y = x\\).\n\n\nusing Random, Distributions, CairoMakie, StatsBase\n\nRandom.seed!(1234)\n\n# assume that we have a sample of size n\nn = 10\n# observations are sampled from the standard normal distribution and i.i.d\n# this process is quite similar with the process\n# where we repeat an experiment n times and get n i.i.d observations\n# subjected to some unknown distribution\ndist = Normal()\n\n# we divide the standard normal distribution into n equal parts\n# which are denoted by their middle points\n# e.g. the k-th middle point is (k - 0.5) / n\n# this means that the probability of sampling any of the n middle points is 1/n in a single experiment\n# i.e. in a single experiment, we have the same chance to sample any of the n middle points\nmiddle_quantiles = [(k - 0.5) / n for k in 1:n]\nequal_intervals = [(quantile(dist, q - 0.5 / n), quantile(dist, q + 0.5 / n)) for q in middle_quantiles]\n\nN = 10^6\nd = Array{Float64}(undef, N)\n\nfor i in 1:N\n    r = rand(dist, 1)\n    d[i] = middle_quantiles[@. (r &gt; first(equal_intervals)) && (r &lt; last(equal_intervals))][1]\nend\nmiddle_quantiles_count_dict = countmap(d)\nmiddle_quantiles_count = [middle_quantiles_count_dict[k] for k in middle_quantiles]\nmiddle_quantiles_count = middle_quantiles_count ./ sum(middle_quantiles_count)\nstem(middle_quantiles, middle_quantiles_count)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Mathematics",
    "section": "",
    "text": "Here is a collection of blogs related to mathematics, such as calculus, linear algebra, probability and statistics, etc.\nEmail: 2413667864@qq.com"
  }
]